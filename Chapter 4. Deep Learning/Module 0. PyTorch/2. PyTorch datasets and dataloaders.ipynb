{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# PyTorch datasets and dataloaders\n",
    "\n",
    "PyTorch provides a bunch of datasets that you can access through the library. Some of them are contained in the **torchvision** library - PyTorch's computer vision library.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision import datasets, transforms\n",
    "\n",
    "# GET THE TRAINING DATASET\n",
    "train_data = datasets.MNIST(root='MNIST-data',                        # where is the data (going to be) stored\n",
    "                            transform=transforms.ToTensor(),          # transform the data from a PIL image to a tensor\n",
    "                            train=True,                               # is this training data?\n",
    "                            download=True                             # should i download it if it's not already here?\n",
    "                           )\n",
    "\n",
    "# GET THE TEST DATASET\n",
    "test_data = datasets.MNIST(root='MNIST-data',\n",
    "                           transform=transforms.ToTensor(),\n",
    "                           train=False,\n",
    "                          )\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# PRINT THEIR LENGTHS AND VISUALISE AN EXAMPLE\n",
    "x = train_data[np.random.randint(0, 300)][0]    # get a random example image\n",
    "plt.imshow(x[0].numpy(),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Splitting our data in PyTorch\n",
    "\n",
    "Like SKLearn, PyTorch provides a utility for splitting datasets which we can use to split the data into training, testing and validation sets."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FURTHER SPLIT THE TRAINING INTO TRAINING AND VALIDATION\n",
    "train_data, val_data = torch.utils.data.random_split(train_data, [50000, 10000])    # split into 50K training & 10K validation"
   ]
  },
  {
   "source": [
    "## Data Loaders\n",
    "\n",
    "PyTorch provides a ```DataLoader``` class which prepares our data to be passed through a PyTorch model by doing a few useful things. These include:\n",
    "- batching our data into minibatches\n",
    "- shuffling the data\n",
    "- applying transforms to the data such as converting it from an image (which PyTorch models cannot process) to a torch tensor (which PyTorch models can process)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "# MAKE TRAINING DATALOADER\n",
    "train_loader = torch.utils.data.DataLoader( # create a data loader\n",
    "    train_data, # what dataset should it sample from?\n",
    "    shuffle=True, # should it shuffle the examples?\n",
    "    batch_size=batch_size # how large should the batches that it samples be?\n",
    ")\n",
    "\n",
    "# MAKE VALIDATION DATALOADER\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_data,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# MAKE TEST DATALOADER\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  }
 ]
}