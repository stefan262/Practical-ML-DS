{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional NLP - Topic Modelling\n",
    "\n",
    "## Learning Objectives\n",
    "- What is NLP and what can we do with it?\n",
    "- Topic modelling\n",
    "- Cleaning text data\n",
    "- Tokenization\n",
    "- Stemming\n",
    "- Lemmatization\n",
    "- Stop Words\n",
    "- Bag of Words\n",
    "- LSA (or LSI)\n",
    "- TF-IDF\n",
    "- LDA\n",
    "\n",
    "**Natural Language Processing** (NLP), is a branch of AI which, as the name suggests, focuses on processing natural language (English, French, Chinese etc.). Recently, there has a been a massive surge in popularity of NLP due to the expressiveness of deep learning models. Prior to this rise in popularity however, statistical methods were commonly used to parse and gain insights from languages. Here, we'll be focusing on these more traditional/'simpler' techniques. It is a completely valid question to be asking *why* are we focusing on doing this when more modern and more powerful technologies exist. This is rationalised as understanding *how* you're going to use NLP. If your task is inherently requiring you to build an expressive model of language, then the deep learning approach is favoured. However, if you just need to use NLP as a tool in part of a larger project, then traditional NLP may be ample. Saying this, due to the use of 'clean' datasets we'll be using in the subsquent NLP chapter, we'll demonstrate effective EDA techniques for NLP in this module.\n",
    "\n",
    "Concretely, NLP, despite being an interdisciplinary field, is best thought of as applying algorithms to text to extract insights. With the current state of NLP, almost every problem language problem imaginablable has research and methodologies behind it. On the traditional NLP front, common problems include: \n",
    "- **Topic Modelling:** An unsupervised methodology to group documents into potential topic groups\n",
    "- **Sentiment Analysis:** Given some text data, what is the sentiment of this data? Good, bad?\n",
    "- **Named Entity Recognition:** Given some data, extract out named entities (e.g. John, Apple, GSK etc)\n",
    "- **Parts of Speech:** Given a sentence, what is it's parts of speech (based on the use of the word in that sentence). Common parts of speech are nouns, adjectives, verbs etc\n",
    "- **Dependancy Parsing:** Given a sentence, analyse the grammatical structure of it. What are the relationships between the words. Phrase structure trees are heavily related. \n",
    "\n",
    "Ambiguity in language: \n",
    "- Scientists study whales from space\n",
    "- She killed the man with the tie\n",
    "\n",
    "In this chapter, we'll be focusing on the first two problems. These problems provide great introductions to NLP and can also be tackled with deep learning methodologies. Parts of Speech and Dependancy Parsing, on the other hand, have fallen out of favour now due to the power of deep learning. Practioners have realised that deep learning models perform better without having text augmented by the syntactic information the aforementioned concepts provide. If it helps, you can think of the differences between traditional and neural NLP as such: Neural NLP aims to *understand* what the language the model sees means, whereas traditional NLP attempts to just find patterns between words.\n",
    "\n",
    "In this notebook, we won't so much focus on EDA of text data. The next notebook will cover that. Rather, we'll introduce important and relevant techniques to deal with text data, and how to represent text data to a model.\n",
    "\n",
    "## Topic Modelling\n",
    "\n",
    "As (very) briefly mentioned, **topic modelling** is the unsupervised act of assigning *documents* into potential topic groups. While the above sentence is seemingly straightforward, let's break it down slightly. There are two components here: \"documents\", and \"potential topic groups\". The first thing to note, however, is that topic modelling is an unsupervised methodology, and we will be looking at two techniques here to assign us the potential topic groups. I highligted the term *document* because it is an common term in NLP. Let's have a very brief discussion about some NLP terminology before discussing what I mean by \"potential topic groups\".\n",
    "\n",
    "Regarding the terminology, there are three main abstraction terms you'll come across:\n",
    "- **Corpus:** Your entire collection of text data for the problem (i.e. your dataset)\n",
    "- **Document:** An item from your corpus (e.g. a single tweet or a single email)\n",
    "- **Token:** The atomic unit of a piece of language (usually a word)\n",
    "\n",
    "Putting the pieces together, this means that we'll be dealing with a corpus (i.e. dataset). In topic modelling, we'll be assigning each individual element in our corpus (i.e. a document) into a group. Let's look at the second component I mentioned earlier on: potential topic groups. I specifically used the word potential because:\n",
    "1) We will be unsure how many topics we may have\n",
    "2) The computer will be unsure how many topics to model\n",
    "\n",
    "What?? How can we be unsure of how many topics we have? Well.. remember that topic modelling is an unsupervised problem. We're only given a corpus: a collection of documents; and we need to categorise each document into a topic (or into multiple topics - which we'll look at later). We don't know how many topics will exist in this corpus, so we need to choose a hyperparameter which will dictate how many topics we want the computer to create. Our job as humans is then to look at the output of the algorithm and label each of the topics that have been output. Let's look at this visually.\n",
    "\n",
    "# Image of topic modelling\n",
    "\n",
    "So we see this pre-processing step that is required before we feed the documents into a model. In the case of NLP, what does this involve?:\n",
    "- Text cleaning\n",
    "- Tokenization\n",
    "- Stemming/Lemmatization\n",
    "- Stop word removal\n",
    "- Representing our text data (Bag of Words or TF-IDF)\n",
    "\n",
    "Now that we understand what topic modelling is trying to do, let's load and preprocess some data before looking at the algorithms we can use for topic modelling! The above list is roughly the order we should be tackling these NLP problems in, so let's get started.\n",
    "\n",
    "In this notebook, we'll be working with an sklearn dataset called 20newsgroups. I've chosen this because this NLP module is in two parts. We'll look at some simpler variants of some of the above concepts here, and in the next notebook, look at a slightly more complicated challenge which builds on the concepts outlined here.\n",
    "\n",
    "The 20newsgroups dataset contains around 18000 posts from (what can be thought of as) a forum board. These posts are split into 20 different topics. We'll work with 4 of those topics here just so it's more managable as an introduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: zeno@ccwf.cc.utexas.edu (S. Hsieh)\n",
      "Subject: Video/Audio/Computer equipment for sale..\n",
      "Organization: The University of Texas at Austin, Austin TX\n",
      "Lines: 49\n",
      "Distribution: na\n",
      "Reply-To: zeno@ccwf.cc.utexas.edu (S. Hsieh)\n",
      "NNTP-Posting-Host: mickey.cc.utexas.edu\n",
      "Originator: zeno@mickey.cc.utexas.edu\n",
      "\n",
      "Time for some spring cleaning, so the following items are up\n",
      "for sale:\n",
      "\n",
      "Roland MT-32 Multi-Timbre Sound module.  \n",
      "  LA synthesis, upto 32 simultaneous voices, 128 preset timbres,\n",
      "  20-char backlit LCD display, MIDI in/out/thru, reference card,\n",
      "  stereo output, etc\n",
      "\n",
      "  Great for games that support it (music on the MT32 is far\n",
      "  superior to any sound card), experimenting with MIDI, or\n",
      "  for adding additional sounds to your MIDI setup.\n",
      "\n",
      "  $235 + shipping\n",
      "\n",
      "Canon RC-250 Xapshot still video camera system.\n",
      "  Includes: camera, carrying pouch, battery pack, battery charger,\n",
      "  ac adapter, video cables, two 2.5\" floppies (each disk holds\n",
      "  50 pictures for 100 pics total), manuals, etc\n",
      "\n",
      "  Video output is standard NTSC composite and can be sent to any\n",
      "  NTSC device (e.g. to a television for direct viewing of your\n",
      "  pictures, to a VCR to record a slideshow, to a computer video\n",
      "  digitizer to save/manipulate the pictures on a computer system)\n",
      "\n",
      "  $295 + shipping\n",
      "\n",
      "Ambico Video Enhancer/Audio Mixer\n",
      "  Three-line stereo audio mixer with microphone input and master\n",
      "  volume slider w/video enhancer to boost & sharpen video images\n",
      "  when dubbing from VCR->VCR, camcorder->VCR, etc\n",
      "\n",
      "  $38 + shipping\n",
      "\n",
      "2400 baud PC internal modem\n",
      "\n",
      "  $25 + shipping\n",
      "\n",
      "Quantum 105MB 3.5\" internal ProDrive hard disk\n",
      "  This unit has recently turned unreliable and erratic in usage.\n",
      "  Could be a simple easily fixed problem or a major problem,\n",
      "  but at any rate I don't have the time to find out where the\n",
      "  problem lies.  If you want to take a risk on it, you can have\n",
      "  it for $45 + shipping.\n",
      "\n",
      "If interested in any of the above items, please Email me.\n",
      "\n",
      "-S. Hsieh\n",
      "zeno@ccwf.cc.utexas.edu\n",
      "\n",
      "\n",
      "From: oauld@ponder.csci.unt.edu (Orion Auld)\n",
      "Subject: 386-40 for $500!\n",
      "Organization: University of North Texas\n",
      "Lines: 18\n",
      "\n",
      "\n",
      "\n",
      "FOR SALE: ****************************************************************\n",
      "\n",
      "386-40 with VGA Color Monitor, dual floppy, VGA card with 1MB on board, joystick,\n",
      "mouse, 2 MB RAM, no hard drive.\n",
      "\n",
      "\n",
      "FOR ONLY $500!  Respond quickly!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-- \n",
      "***** Orion Auld *****     *----------------------------------------------*\n",
      "\"We are only fabulous      |     If you're not part of the solution,      |\n",
      " beasts, after all.\"       |       You're part of the precipitate.        |\n",
      " -- John Ashberry          *----------------------------------------------*\n",
      "\n",
      "From: craig@toontown.ColumbiaSC.NCR.COM (Craig S. Williamson)\n",
      "Subject: Video in/out\n",
      "Reply-To: craig@toontown.ColumbiaSC.NCR.COM (Craig S. Williamson)\n",
      "Distribution: na\n",
      "Organization: NCR E&M Columbia, SC\n",
      "Lines: 14\n",
      "\n",
      "\n",
      "I'm getting ready to buy a multimedia workstation and would like a little\n",
      "advice.  I need a graphics card that will do video in and out under windows.\n",
      "I was originally thinking of a Targa+ but that doesn't work under Windows.\n",
      "What cards should I be looking into?\n",
      "\n",
      "Thanks,\n",
      "Craig\n",
      "\n",
      "-- \n",
      "                                             \"To forgive is divine, to be\n",
      "-Craig Williamson                              an airhead is human.\"\n",
      " Craig.Williamson@ColumbiaSC.NCR.COM                -Balki Bartokomas\n",
      " craig@toontown.ColumbiaSC.NCR.COM (home)                  Perfect Strangers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = [\"alt.atheism\", \"misc.forsale\", \"sci.space\", \"comp.graphics\"]\n",
    "corpus = fetch_20newsgroups(subset='train', categories=categories)\n",
    "print(\"\\n\".join(corpus.data[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['misc.forsale', 'misc.forsale', 'comp.graphics'], dtype='<U13')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(corpus.target_names)[corpus.target[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2242,), (2242,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.filenames.shape, corpus.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning text data\n",
    "What we've printed above is easily consumable and understandable by humans. However, there exist many nuances of language that exist for our convinience - and providing this information to a computer is unnecessary, and perhaps even detrimental. Some examples of this include capitalisation of letters and puncutation. With the text data returned above, can you think of what else we might need to \"clean\"?\n",
    "\n",
    "This subsection provides an introduction into how we can clean text data. In previous notebooks, we've been introduced to some simple string manipulations on dataframes. Here, we'll be using similar methods (and then some). Let's create a function which takes in one document at a time, and cleans the document. From what I see, we'll need to do the following:\n",
    "- Lowercase everything\n",
    "- Remove emails\n",
    "- Remove puncuation\n",
    "- Remove numbers\n",
    "- Replace newline char (\\n) with normal whitespace (\\s or \" \")\n",
    "\n",
    "Different usecases and different practioners will recommend different strategies for cleaning text data. Some would argue that removing numbers isn't a requirement. Personally, I believe the same thing, but I've added it here to test your googling and/or regex knowledge ;).\n",
    "\n",
    "## Tokenization\n",
    "It's worth killing two birds with one stone and mentioning what a token is. A token is simply the atomic unit of text. In most cases, this'll be a word, but could also include puncutation or an emoji. When we say to \"tokenize\" something, we mean that we take in a continuous piece of text, and we split (hint 😉) it into a list of tokens. That is, `The quick brown fox jumped over the lazy dog` --> `[\"The\", \"quick\", \"brown\", \"fox\", \"jumped\", \"over\", \"the\", \"lazy\", \"dog\"]`.\n",
    "\n",
    "In the function we're defining below, clean the data and return it's tokens. You may find it easier to perform the regex over tokens as opposed to the whole document, but that's an implementation detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['from',\n",
       " 's',\n",
       " 'hsieh',\n",
       " 'subject',\n",
       " 'videoaudiocomputer',\n",
       " 'equipment',\n",
       " 'for',\n",
       " 'sale',\n",
       " 'organization',\n",
       " 'the',\n",
       " 'university',\n",
       " 'of',\n",
       " 'texas',\n",
       " 'at',\n",
       " 'austin',\n",
       " 'austin',\n",
       " 'tx',\n",
       " 'lines',\n",
       " 'distribution',\n",
       " 'na',\n",
       " 'replyto',\n",
       " 's',\n",
       " 'hsieh',\n",
       " 'nntppostinghost',\n",
       " 'mickeyccutexasedu',\n",
       " 'originator',\n",
       " 'time',\n",
       " 'for',\n",
       " 'some',\n",
       " 'spring',\n",
       " 'cleaning',\n",
       " 'so',\n",
       " 'the',\n",
       " 'following',\n",
       " 'items',\n",
       " 'are',\n",
       " 'up',\n",
       " 'for',\n",
       " 'sale',\n",
       " 'roland',\n",
       " 'mt',\n",
       " 'multitimbre',\n",
       " 'sound',\n",
       " 'module',\n",
       " 'la',\n",
       " 'synthesis',\n",
       " 'upto',\n",
       " 'simultaneous',\n",
       " 'voices',\n",
       " 'preset',\n",
       " 'timbres',\n",
       " 'char',\n",
       " 'backlit',\n",
       " 'lcd',\n",
       " 'display',\n",
       " 'midi',\n",
       " 'inoutthru',\n",
       " 'reference',\n",
       " 'card',\n",
       " 'stereo',\n",
       " 'output',\n",
       " 'etc',\n",
       " 'great',\n",
       " 'for',\n",
       " 'games',\n",
       " 'that',\n",
       " 'support',\n",
       " 'it',\n",
       " 'music',\n",
       " 'on',\n",
       " 'the',\n",
       " 'mt',\n",
       " 'is',\n",
       " 'far',\n",
       " 'superior',\n",
       " 'to',\n",
       " 'any',\n",
       " 'sound',\n",
       " 'card',\n",
       " 'experimenting',\n",
       " 'with',\n",
       " 'midi',\n",
       " 'or',\n",
       " 'for',\n",
       " 'adding',\n",
       " 'additional',\n",
       " 'sounds',\n",
       " 'to',\n",
       " 'your',\n",
       " 'midi',\n",
       " 'setup',\n",
       " 'shipping',\n",
       " 'canon',\n",
       " 'rc',\n",
       " 'xapshot',\n",
       " 'still',\n",
       " 'video',\n",
       " 'camera',\n",
       " 'system',\n",
       " 'includes',\n",
       " 'camera',\n",
       " 'carrying',\n",
       " 'pouch',\n",
       " 'battery',\n",
       " 'pack',\n",
       " 'battery',\n",
       " 'charger',\n",
       " 'ac',\n",
       " 'adapter',\n",
       " 'video',\n",
       " 'cables',\n",
       " 'two',\n",
       " 'floppies',\n",
       " 'each',\n",
       " 'disk',\n",
       " 'holds',\n",
       " 'pictures',\n",
       " 'for',\n",
       " 'pics',\n",
       " 'total',\n",
       " 'manuals',\n",
       " 'etc',\n",
       " 'video',\n",
       " 'output',\n",
       " 'is',\n",
       " 'standard',\n",
       " 'ntsc',\n",
       " 'composite',\n",
       " 'and',\n",
       " 'can',\n",
       " 'be',\n",
       " 'sent',\n",
       " 'to',\n",
       " 'any',\n",
       " 'ntsc',\n",
       " 'device',\n",
       " 'eg',\n",
       " 'to',\n",
       " 'a',\n",
       " 'television',\n",
       " 'for',\n",
       " 'direct',\n",
       " 'viewing',\n",
       " 'of',\n",
       " 'your',\n",
       " 'pictures',\n",
       " 'to',\n",
       " 'a',\n",
       " 'vcr',\n",
       " 'to',\n",
       " 'record',\n",
       " 'a',\n",
       " 'slideshow',\n",
       " 'to',\n",
       " 'a',\n",
       " 'computer',\n",
       " 'video',\n",
       " 'digitizer',\n",
       " 'to',\n",
       " 'savemanipulate',\n",
       " 'the',\n",
       " 'pictures',\n",
       " 'on',\n",
       " 'a',\n",
       " 'computer',\n",
       " 'system',\n",
       " 'shipping',\n",
       " 'ambico',\n",
       " 'video',\n",
       " 'enhanceraudio',\n",
       " 'mixer',\n",
       " 'threeline',\n",
       " 'stereo',\n",
       " 'audio',\n",
       " 'mixer',\n",
       " 'with',\n",
       " 'microphone',\n",
       " 'input',\n",
       " 'and',\n",
       " 'master',\n",
       " 'volume',\n",
       " 'slider',\n",
       " 'wvideo',\n",
       " 'enhancer',\n",
       " 'to',\n",
       " 'boost',\n",
       " 'sharpen',\n",
       " 'video',\n",
       " 'images',\n",
       " 'when',\n",
       " 'dubbing',\n",
       " 'from',\n",
       " 'vcrvcr',\n",
       " 'camcordervcr',\n",
       " 'etc',\n",
       " 'shipping',\n",
       " 'baud',\n",
       " 'pc',\n",
       " 'internal',\n",
       " 'modem',\n",
       " 'shipping',\n",
       " 'quantum',\n",
       " 'mb',\n",
       " 'internal',\n",
       " 'prodrive',\n",
       " 'hard',\n",
       " 'disk',\n",
       " 'this',\n",
       " 'unit',\n",
       " 'has',\n",
       " 'recently',\n",
       " 'turned',\n",
       " 'unreliable',\n",
       " 'and',\n",
       " 'erratic',\n",
       " 'in',\n",
       " 'usage',\n",
       " 'could',\n",
       " 'be',\n",
       " 'a',\n",
       " 'simple',\n",
       " 'easily',\n",
       " 'fixed',\n",
       " 'problem',\n",
       " 'or',\n",
       " 'a',\n",
       " 'major',\n",
       " 'problem',\n",
       " 'but',\n",
       " 'at',\n",
       " 'any',\n",
       " 'rate',\n",
       " 'i',\n",
       " 'dont',\n",
       " 'have',\n",
       " 'the',\n",
       " 'time',\n",
       " 'to',\n",
       " 'find',\n",
       " 'out',\n",
       " 'where',\n",
       " 'the',\n",
       " 'problem',\n",
       " 'lies',\n",
       " 'if',\n",
       " 'you',\n",
       " 'want',\n",
       " 'to',\n",
       " 'take',\n",
       " 'a',\n",
       " 'risk',\n",
       " 'on',\n",
       " 'it',\n",
       " 'you',\n",
       " 'can',\n",
       " 'have',\n",
       " 'it',\n",
       " 'for',\n",
       " 'shipping',\n",
       " 'if',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'any',\n",
       " 'of',\n",
       " 'the',\n",
       " 'above',\n",
       " 'items',\n",
       " 'please',\n",
       " 'email',\n",
       " 'me',\n",
       " 's',\n",
       " 'hsieh']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "## Create a function which takes in a document and fulfills the above operations\n",
    "# Feel free to Google around\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clean_data(corpus.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['from',\n",
       "  's',\n",
       "  'hsieh',\n",
       "  'subject',\n",
       "  'videoaudiocomputer',\n",
       "  'equipment',\n",
       "  'for',\n",
       "  'sale',\n",
       "  'organization',\n",
       "  'the',\n",
       "  'university',\n",
       "  'of',\n",
       "  'texas',\n",
       "  'at',\n",
       "  'austin',\n",
       "  'austin',\n",
       "  'tx',\n",
       "  'lines',\n",
       "  'distribution',\n",
       "  'na',\n",
       "  'replyto',\n",
       "  's',\n",
       "  'hsieh',\n",
       "  'nntppostinghost',\n",
       "  'mickeyccutexasedu',\n",
       "  'originator',\n",
       "  'time',\n",
       "  'for',\n",
       "  'some',\n",
       "  'spring',\n",
       "  'cleaning',\n",
       "  'so',\n",
       "  'the',\n",
       "  'following',\n",
       "  'items',\n",
       "  'are',\n",
       "  'up',\n",
       "  'for',\n",
       "  'sale',\n",
       "  'roland',\n",
       "  'mt',\n",
       "  'multitimbre',\n",
       "  'sound',\n",
       "  'module',\n",
       "  'la',\n",
       "  'synthesis',\n",
       "  'upto',\n",
       "  'simultaneous',\n",
       "  'voices',\n",
       "  'preset',\n",
       "  'timbres',\n",
       "  'char',\n",
       "  'backlit',\n",
       "  'lcd',\n",
       "  'display',\n",
       "  'midi',\n",
       "  'inoutthru',\n",
       "  'reference',\n",
       "  'card',\n",
       "  'stereo',\n",
       "  'output',\n",
       "  'etc',\n",
       "  'great',\n",
       "  'for',\n",
       "  'games',\n",
       "  'that',\n",
       "  'support',\n",
       "  'it',\n",
       "  'music',\n",
       "  'on',\n",
       "  'the',\n",
       "  'mt',\n",
       "  'is',\n",
       "  'far',\n",
       "  'superior',\n",
       "  'to',\n",
       "  'any',\n",
       "  'sound',\n",
       "  'card',\n",
       "  'experimenting',\n",
       "  'with',\n",
       "  'midi',\n",
       "  'or',\n",
       "  'for',\n",
       "  'adding',\n",
       "  'additional',\n",
       "  'sounds',\n",
       "  'to',\n",
       "  'your',\n",
       "  'midi',\n",
       "  'setup',\n",
       "  'shipping',\n",
       "  'canon',\n",
       "  'rc',\n",
       "  'xapshot',\n",
       "  'still',\n",
       "  'video',\n",
       "  'camera',\n",
       "  'system',\n",
       "  'includes',\n",
       "  'camera',\n",
       "  'carrying',\n",
       "  'pouch',\n",
       "  'battery',\n",
       "  'pack',\n",
       "  'battery',\n",
       "  'charger',\n",
       "  'ac',\n",
       "  'adapter',\n",
       "  'video',\n",
       "  'cables',\n",
       "  'two',\n",
       "  'floppies',\n",
       "  'each',\n",
       "  'disk',\n",
       "  'holds',\n",
       "  'pictures',\n",
       "  'for',\n",
       "  'pics',\n",
       "  'total',\n",
       "  'manuals',\n",
       "  'etc',\n",
       "  'video',\n",
       "  'output',\n",
       "  'is',\n",
       "  'standard',\n",
       "  'ntsc',\n",
       "  'composite',\n",
       "  'and',\n",
       "  'can',\n",
       "  'be',\n",
       "  'sent',\n",
       "  'to',\n",
       "  'any',\n",
       "  'ntsc',\n",
       "  'device',\n",
       "  'eg',\n",
       "  'to',\n",
       "  'a',\n",
       "  'television',\n",
       "  'for',\n",
       "  'direct',\n",
       "  'viewing',\n",
       "  'of',\n",
       "  'your',\n",
       "  'pictures',\n",
       "  'to',\n",
       "  'a',\n",
       "  'vcr',\n",
       "  'to',\n",
       "  'record',\n",
       "  'a',\n",
       "  'slideshow',\n",
       "  'to',\n",
       "  'a',\n",
       "  'computer',\n",
       "  'video',\n",
       "  'digitizer',\n",
       "  'to',\n",
       "  'savemanipulate',\n",
       "  'the',\n",
       "  'pictures',\n",
       "  'on',\n",
       "  'a',\n",
       "  'computer',\n",
       "  'system',\n",
       "  'shipping',\n",
       "  'ambico',\n",
       "  'video',\n",
       "  'enhanceraudio',\n",
       "  'mixer',\n",
       "  'threeline',\n",
       "  'stereo',\n",
       "  'audio',\n",
       "  'mixer',\n",
       "  'with',\n",
       "  'microphone',\n",
       "  'input',\n",
       "  'and',\n",
       "  'master',\n",
       "  'volume',\n",
       "  'slider',\n",
       "  'wvideo',\n",
       "  'enhancer',\n",
       "  'to',\n",
       "  'boost',\n",
       "  'sharpen',\n",
       "  'video',\n",
       "  'images',\n",
       "  'when',\n",
       "  'dubbing',\n",
       "  'from',\n",
       "  'vcrvcr',\n",
       "  'camcordervcr',\n",
       "  'etc',\n",
       "  'shipping',\n",
       "  'baud',\n",
       "  'pc',\n",
       "  'internal',\n",
       "  'modem',\n",
       "  'shipping',\n",
       "  'quantum',\n",
       "  'mb',\n",
       "  'internal',\n",
       "  'prodrive',\n",
       "  'hard',\n",
       "  'disk',\n",
       "  'this',\n",
       "  'unit',\n",
       "  'has',\n",
       "  'recently',\n",
       "  'turned',\n",
       "  'unreliable',\n",
       "  'and',\n",
       "  'erratic',\n",
       "  'in',\n",
       "  'usage',\n",
       "  'could',\n",
       "  'be',\n",
       "  'a',\n",
       "  'simple',\n",
       "  'easily',\n",
       "  'fixed',\n",
       "  'problem',\n",
       "  'or',\n",
       "  'a',\n",
       "  'major',\n",
       "  'problem',\n",
       "  'but',\n",
       "  'at',\n",
       "  'any',\n",
       "  'rate',\n",
       "  'i',\n",
       "  'dont',\n",
       "  'have',\n",
       "  'the',\n",
       "  'time',\n",
       "  'to',\n",
       "  'find',\n",
       "  'out',\n",
       "  'where',\n",
       "  'the',\n",
       "  'problem',\n",
       "  'lies',\n",
       "  'if',\n",
       "  'you',\n",
       "  'want',\n",
       "  'to',\n",
       "  'take',\n",
       "  'a',\n",
       "  'risk',\n",
       "  'on',\n",
       "  'it',\n",
       "  'you',\n",
       "  'can',\n",
       "  'have',\n",
       "  'it',\n",
       "  'for',\n",
       "  'shipping',\n",
       "  'if',\n",
       "  'interested',\n",
       "  'in',\n",
       "  'any',\n",
       "  'of',\n",
       "  'the',\n",
       "  'above',\n",
       "  'items',\n",
       "  'please',\n",
       "  'email',\n",
       "  'me',\n",
       "  's',\n",
       "  'hsieh'],\n",
       " ['from',\n",
       "  'orion',\n",
       "  'auld',\n",
       "  'subject',\n",
       "  'for',\n",
       "  'organization',\n",
       "  'university',\n",
       "  'of',\n",
       "  'north',\n",
       "  'texas',\n",
       "  'lines',\n",
       "  'for',\n",
       "  'sale',\n",
       "  'with',\n",
       "  'vga',\n",
       "  'color',\n",
       "  'monitor',\n",
       "  'dual',\n",
       "  'floppy',\n",
       "  'vga',\n",
       "  'card',\n",
       "  'with',\n",
       "  'mb',\n",
       "  'on',\n",
       "  'board',\n",
       "  'joystick',\n",
       "  'mouse',\n",
       "  'mb',\n",
       "  'ram',\n",
       "  'no',\n",
       "  'hard',\n",
       "  'drive',\n",
       "  'for',\n",
       "  'only',\n",
       "  'respond',\n",
       "  'quickly',\n",
       "  'orion',\n",
       "  'auld',\n",
       "  'we',\n",
       "  'are',\n",
       "  'only',\n",
       "  'fabulous',\n",
       "  'if',\n",
       "  'youre',\n",
       "  'not',\n",
       "  'part',\n",
       "  'of',\n",
       "  'the',\n",
       "  'solution',\n",
       "  'beasts',\n",
       "  'after',\n",
       "  'all',\n",
       "  'youre',\n",
       "  'part',\n",
       "  'of',\n",
       "  'the',\n",
       "  'precipitate',\n",
       "  'john',\n",
       "  'ashberry'],\n",
       " ['from',\n",
       "  'craig',\n",
       "  's',\n",
       "  'williamson',\n",
       "  'subject',\n",
       "  'video',\n",
       "  'inout',\n",
       "  'replyto',\n",
       "  'craig',\n",
       "  's',\n",
       "  'williamson',\n",
       "  'distribution',\n",
       "  'na',\n",
       "  'organization',\n",
       "  'ncr',\n",
       "  'em',\n",
       "  'columbia',\n",
       "  'sc',\n",
       "  'lines',\n",
       "  'im',\n",
       "  'getting',\n",
       "  'ready',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'a',\n",
       "  'multimedia',\n",
       "  'workstation',\n",
       "  'and',\n",
       "  'would',\n",
       "  'like',\n",
       "  'a',\n",
       "  'little',\n",
       "  'advice',\n",
       "  'i',\n",
       "  'need',\n",
       "  'a',\n",
       "  'graphics',\n",
       "  'card',\n",
       "  'that',\n",
       "  'will',\n",
       "  'do',\n",
       "  'video',\n",
       "  'in',\n",
       "  'and',\n",
       "  'out',\n",
       "  'under',\n",
       "  'windows',\n",
       "  'i',\n",
       "  'was',\n",
       "  'originally',\n",
       "  'thinking',\n",
       "  'of',\n",
       "  'a',\n",
       "  'targa',\n",
       "  'but',\n",
       "  'that',\n",
       "  'doesnt',\n",
       "  'work',\n",
       "  'under',\n",
       "  'windows',\n",
       "  'what',\n",
       "  'cards',\n",
       "  'should',\n",
       "  'i',\n",
       "  'be',\n",
       "  'looking',\n",
       "  'into',\n",
       "  'thanks',\n",
       "  'craig',\n",
       "  'to',\n",
       "  'forgive',\n",
       "  'is',\n",
       "  'divine',\n",
       "  'to',\n",
       "  'be',\n",
       "  'craig',\n",
       "  'williamson',\n",
       "  'an',\n",
       "  'airhead',\n",
       "  'is',\n",
       "  'human',\n",
       "  'balki',\n",
       "  'bartokomas',\n",
       "  'home',\n",
       "  'perfect',\n",
       "  'strangers']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Apply this function over our corpus\n",
    "\n",
    "\n",
    "corpus.data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are some issues with the way that we've processed the text (generally speaking). A major issue that I see is that quotes/replies of previous messages were shown in the document string as \">\" or \">>\" etc. With the removal of this signal, a model wouldn't be able to distinguish between an authors post or a reply. In the case of sentiment classifcation, it may classify an authors opinion as negative when infact the authors opinion was positive, but the messages he/she was replying to were of negative sentiment. In such a situation, perhaps removing the quotes/replies are necessary. Here, however, we just want to find topics, and quotes/replies are most likely in the same domain as the post itself due to the post being part of a message thread. \n",
    "\n",
    "Another issue comes from our preprocessing strategy. We removed puncuation, so some substrings are just some characters with punctuation removed from it. For example \"rutgersremusrutgersedukaldis\". Also, due to the loose structure of the email, we have some potential redundant words which may be detrimental to a model (e.g. \"subject\", \"organization\"). We'll continue as is for now, and if we see such words causing an issue, we'll know to remove them 👍.\n",
    "\n",
    "## Stop Word removal\n",
    "Stop words are words which are common to a natural language but provide very little information towards the meaning of a sentence. Obvious examples are \"the, and, a, is\" etc. With traditional NLP, a stop list is typically defined (i.e. a set of stop words), and document tokens which are present in this stop list are removed. If we wanted to, we could also add domain specific stop words to our stop list (e.g. \"subject\", \"organization\"). It used to be that large stop lists were defined (e.g. 200-300 words), however stop lists (within traditional NLP) are now typically just the super common words (e.g. 7-12 words). Neural NLP does not consider stop words. However, even within traditional NLP, there has been debate about whether stop word removal is necessary or not. Different practioners will say different things, and I am of the opinion of that just the super common and domain specific stop words should be removed. Here, we'll define a stop list and subsequently remove the tokens from all our documents if the token appears in this stop list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hsieh',\n",
       "  'videoaudiocomputer',\n",
       "  'equipment',\n",
       "  'sale',\n",
       "  'university',\n",
       "  'texas',\n",
       "  'austin',\n",
       "  'austin',\n",
       "  'hsieh',\n",
       "  'mickeyccutexasedu',\n",
       "  'time',\n",
       "  'spring',\n",
       "  'cleaning',\n",
       "  'items',\n",
       "  'sale',\n",
       "  'roland',\n",
       "  'multitimbre',\n",
       "  'sound',\n",
       "  'module',\n",
       "  'synthesis',\n",
       "  'upto',\n",
       "  'simultaneous',\n",
       "  'voices',\n",
       "  'preset',\n",
       "  'timbres',\n",
       "  'char',\n",
       "  'backlit',\n",
       "  'lcd',\n",
       "  'display',\n",
       "  'midi',\n",
       "  'inoutthru',\n",
       "  'reference',\n",
       "  'card',\n",
       "  'stereo',\n",
       "  'output',\n",
       "  'great',\n",
       "  'games',\n",
       "  'support',\n",
       "  'music',\n",
       "  'superior',\n",
       "  'sound',\n",
       "  'card',\n",
       "  'experimenting',\n",
       "  'midi',\n",
       "  'adding',\n",
       "  'additional',\n",
       "  'sounds',\n",
       "  'midi',\n",
       "  'setup',\n",
       "  'shipping',\n",
       "  'canon',\n",
       "  'xapshot',\n",
       "  'video',\n",
       "  'camera',\n",
       "  'includes',\n",
       "  'camera',\n",
       "  'carrying',\n",
       "  'pouch',\n",
       "  'battery',\n",
       "  'pack',\n",
       "  'battery',\n",
       "  'charger',\n",
       "  'adapter',\n",
       "  'video',\n",
       "  'cables',\n",
       "  'floppies',\n",
       "  'disk',\n",
       "  'holds',\n",
       "  'pictures',\n",
       "  'pics',\n",
       "  'total',\n",
       "  'manuals',\n",
       "  'video',\n",
       "  'output',\n",
       "  'standard',\n",
       "  'ntsc',\n",
       "  'composite',\n",
       "  'ntsc',\n",
       "  'device',\n",
       "  'television',\n",
       "  'direct',\n",
       "  'viewing',\n",
       "  'pictures',\n",
       "  'vcr',\n",
       "  'record',\n",
       "  'slideshow',\n",
       "  'computer',\n",
       "  'video',\n",
       "  'digitizer',\n",
       "  'savemanipulate',\n",
       "  'pictures',\n",
       "  'computer',\n",
       "  'shipping',\n",
       "  'ambico',\n",
       "  'video',\n",
       "  'enhanceraudio',\n",
       "  'mixer',\n",
       "  'threeline',\n",
       "  'stereo',\n",
       "  'audio',\n",
       "  'mixer',\n",
       "  'microphone',\n",
       "  'input',\n",
       "  'master',\n",
       "  'volume',\n",
       "  'slider',\n",
       "  'wvideo',\n",
       "  'enhancer',\n",
       "  'boost',\n",
       "  'sharpen',\n",
       "  'video',\n",
       "  'images',\n",
       "  'dubbing',\n",
       "  'vcrvcr',\n",
       "  'camcordervcr',\n",
       "  'shipping',\n",
       "  'baud',\n",
       "  'internal',\n",
       "  'modem',\n",
       "  'shipping',\n",
       "  'quantum',\n",
       "  'mb',\n",
       "  'internal',\n",
       "  'prodrive',\n",
       "  'hard',\n",
       "  'disk',\n",
       "  'unit',\n",
       "  'turned',\n",
       "  'unreliable',\n",
       "  'erratic',\n",
       "  'usage',\n",
       "  'simple',\n",
       "  'easily',\n",
       "  'fixed',\n",
       "  'problem',\n",
       "  'major',\n",
       "  'problem',\n",
       "  'rate',\n",
       "  'dont',\n",
       "  'time',\n",
       "  'problem',\n",
       "  'lies',\n",
       "  'risk',\n",
       "  'shipping',\n",
       "  'interested',\n",
       "  'items',\n",
       "  'email',\n",
       "  'hsieh'],\n",
       " ['orion',\n",
       "  'auld',\n",
       "  'university',\n",
       "  'north',\n",
       "  'texas',\n",
       "  'sale',\n",
       "  'vga',\n",
       "  'color',\n",
       "  'monitor',\n",
       "  'dual',\n",
       "  'floppy',\n",
       "  'vga',\n",
       "  'card',\n",
       "  'mb',\n",
       "  'board',\n",
       "  'joystick',\n",
       "  'mouse',\n",
       "  'mb',\n",
       "  'ram',\n",
       "  'hard',\n",
       "  'drive',\n",
       "  'respond',\n",
       "  'orion',\n",
       "  'auld',\n",
       "  'fabulous',\n",
       "  'solution',\n",
       "  'beasts',\n",
       "  'precipitate',\n",
       "  'john',\n",
       "  'ashberry'],\n",
       " ['craig',\n",
       "  'williamson',\n",
       "  'video',\n",
       "  'inout',\n",
       "  'craig',\n",
       "  'williamson',\n",
       "  'ncr',\n",
       "  'columbia',\n",
       "  'ready',\n",
       "  'buy',\n",
       "  'multimedia',\n",
       "  'workstation',\n",
       "  'advice',\n",
       "  'graphics',\n",
       "  'card',\n",
       "  'video',\n",
       "  'windows',\n",
       "  'originally',\n",
       "  'thinking',\n",
       "  'targa',\n",
       "  'doesnt',\n",
       "  'work',\n",
       "  'windows',\n",
       "  'cards',\n",
       "  'craig',\n",
       "  'forgive',\n",
       "  'divine',\n",
       "  'craig',\n",
       "  'williamson',\n",
       "  'airhead',\n",
       "  'human',\n",
       "  'balki',\n",
       "  'bartokomas',\n",
       "  'perfect',\n",
       "  'strangers']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stop_list obtained from: https://gist.github.com/sebleier/554280#gistcomment-2892081\n",
    "stop_list = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"ain\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"aren\", \"aren't\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"can\", \"couldn\", \"couldn't\", \"d\", \"did\", \"didn\", \"didn't\", \"do\", \"does\", \"doesn\", \"doesn't\", \"doing\", \"don\", \"don't\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"hadn\", \"hadn't\", \"has\", \"hasn\", \"hasn't\", \"have\", \"haven\", \"haven't\", \"having\", \"he\", \"her\", \"here\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"i\", \"if\", \"in\", \"into\", \"is\", \"isn\", \"isn't\", \"it\", \"it's\", \"its\", \"itself\", \"just\", \"ll\", \"m\", \"ma\", \"me\", \"mightn\", \"mightn't\", \"more\", \"most\", \"mustn\", \"mustn't\", \"my\", \"myself\", \"needn\", \"needn't\", \"no\", \"nor\", \"not\", \"now\", \"o\", \"of\", \"off\", \"on\", \"once\", \"only\", \"or\", \"other\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"re\", \"s\", \"same\", \"shan\", \"shan't\", \"she\", \"she's\", \"should\", \"should've\", \"shouldn\", \"shouldn't\", \"so\", \"some\", \"such\", \"t\", \"than\", \"that\", \"that'll\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"these\", \"they\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"ve\", \"very\", \"was\", \"wasn\", \"wasn't\", \"we\", \"were\", \"weren\", \"weren't\", \"what\", \"when\", \"where\", \"which\", \"while\", \"who\", \"whom\", \"why\", \"will\", \"with\", \"won\", \"won't\", \"wouldn\", \"wouldn't\", \"y\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"could\", \"he'd\", \"he'll\", \"he's\", \"here's\", \"how's\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"let's\", \"ought\", \"she'd\", \"she'll\", \"that's\", \"there's\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"what's\", \"when's\", \"where's\", \"who's\", \"why's\", \"would\", \"able\", \"abst\", \"accordance\", \"according\", \"accordingly\", \"across\", \"act\", \"actually\", \"added\", \"adj\", \"affected\", \"affecting\", \"affects\", \"afterwards\", \"ah\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\", \"among\", \"amongst\", \"announce\", \"another\", \"anybody\", \"anyhow\", \"anymore\", \"anyone\", \"anything\", \"anyway\", \"anyways\", \"anywhere\", \"apparently\", \"approximately\", \"arent\", \"arise\", \"around\", \"aside\", \"ask\", \"asking\", \"auth\", \"available\", \"away\", \"awfully\", \"b\", \"back\", \"became\", \"become\", \"becomes\", \"becoming\", \"beforehand\", \"begin\", \"beginning\", \"beginnings\", \"begins\", \"behind\", \"believe\", \"beside\", \"besides\", \"beyond\", \"biol\", \"brief\", \"briefly\", \"c\", \"ca\", \"came\", \"cannot\", \"can't\", \"cause\", \"causes\", \"certain\", \"certainly\", \"co\", \"com\", \"come\", \"comes\", \"contain\", \"containing\", \"contains\", \"couldnt\", \"date\", \"different\", \"done\", \"downwards\", \"due\", \"e\", \"ed\", \"edu\", \"effect\", \"eg\", \"eight\", \"eighty\", \"either\", \"else\", \"elsewhere\", \"end\", \"ending\", \"enough\", \"especially\", \"et\", \"etc\", \"even\", \"ever\", \"every\", \"everybody\", \"everyone\", \"everything\", \"everywhere\", \"ex\", \"except\", \"f\", \"far\", \"ff\", \"fifth\", \"first\", \"five\", \"fix\", \"followed\", \"following\", \"follows\", \"former\", \"formerly\", \"forth\", \"found\", \"four\", \"furthermore\", \"g\", \"gave\", \"get\", \"gets\", \"getting\", \"give\", \"given\", \"gives\", \"giving\", \"go\", \"goes\", \"gone\", \"got\", \"gotten\", \"h\", \"happens\", \"hardly\", \"hed\", \"hence\", \"hereafter\", \"hereby\", \"herein\", \"heres\", \"hereupon\", \"hes\", \"hi\", \"hid\", \"hither\", \"home\", \"howbeit\", \"however\", \"hundred\", \"id\", \"ie\", \"im\", \"immediate\", \"immediately\", \"importance\", \"important\", \"inc\", \"indeed\", \"index\", \"information\", \"instead\", \"invention\", \"inward\", \"itd\", \"it'll\", \"j\", \"k\", \"keep\", \"keeps\", \"kept\", \"kg\", \"km\", \"know\", \"known\", \"knows\", \"l\", \"largely\", \"last\", \"lately\", \"later\", \"latter\", \"latterly\", \"least\", \"less\", \"lest\", \"let\", \"lets\", \"like\", \"liked\", \"likely\", \"line\", \"little\", \"'ll\", \"look\", \"looking\", \"looks\", \"ltd\", \"made\", \"mainly\", \"make\", \"makes\", \"many\", \"may\", \"maybe\", \"mean\", \"means\", \"meantime\", \"meanwhile\", \"merely\", \"mg\", \"might\", \"million\", \"miss\", \"ml\", \"moreover\", \"mostly\", \"mr\", \"mrs\", \"much\", \"mug\", \"must\", \"n\", \"na\", \"name\", \"namely\", \"nay\", \"nd\", \"near\", \"nearly\", \"necessarily\", \"necessary\", \"need\", \"needs\", \"neither\", \"never\", \"nevertheless\", \"new\", \"next\", \"nine\", \"ninety\", \"nobody\", \"non\", \"none\", \"nonetheless\", \"noone\", \"normally\", \"nos\", \"noted\", \"nothing\", \"nowhere\", \"obtain\", \"obtained\", \"obviously\", \"often\", \"oh\", \"ok\", \"okay\", \"old\", \"omitted\", \"one\", \"ones\", \"onto\", \"ord\", \"others\", \"otherwise\", \"outside\", \"overall\", \"owing\", \"p\", \"page\", \"pages\", \"part\", \"particular\", \"particularly\", \"past\", \"per\", \"perhaps\", \"placed\", \"please\", \"plus\", \"poorly\", \"possible\", \"possibly\", \"potentially\", \"pp\", \"predominantly\", \"present\", \"previously\", \"primarily\", \"probably\", \"promptly\", \"proud\", \"provides\", \"put\", \"q\", \"que\", \"quickly\", \"quite\", \"qv\", \"r\", \"ran\", \"rather\", \"rd\", \"readily\", \"really\", \"recent\", \"recently\", \"ref\", \"refs\", \"regarding\", \"regardless\", \"regards\", \"related\", \"relatively\", \"research\", \"respectively\", \"resulted\", \"resulting\", \"results\", \"right\", \"run\", \"said\", \"saw\", \"say\", \"saying\", \"says\", \"sec\", \"section\", \"see\", \"seeing\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"seen\", \"self\", \"selves\", \"sent\", \"seven\", \"several\", \"shall\", \"shed\", \"shes\", \"show\", \"showed\", \"shown\", \"showns\", \"shows\", \"significant\", \"significantly\", \"similar\", \"similarly\", \"since\", \"six\", \"slightly\", \"somebody\", \"somehow\", \"someone\", \"somethan\", \"something\", \"sometime\", \"sometimes\", \"somewhat\", \"somewhere\", \"soon\", \"sorry\", \"specifically\", \"specified\", \"specify\", \"specifying\", \"still\", \"stop\", \"strongly\", \"sub\", \"substantially\", \"successfully\", \"sufficiently\", \"suggest\", \"sup\", \"sure\", \"take\", \"taken\", \"taking\", \"tell\", \"tends\", \"th\", \"thank\", \"thanks\", \"thanx\", \"thats\", \"that've\", \"thence\", \"thereafter\", \"thereby\", \"thered\", \"therefore\", \"therein\", \"there'll\", \"thereof\", \"therere\", \"theres\", \"thereto\", \"thereupon\", \"there've\", \"theyd\", \"theyre\", \"think\", \"thou\", \"though\", \"thoughh\", \"thousand\", \"throug\", \"throughout\", \"thru\", \"thus\", \"til\", \"tip\", \"together\", \"took\", \"toward\", \"towards\", \"tried\", \"tries\", \"truly\", \"try\", \"trying\", \"ts\", \"twice\", \"two\", \"u\", \"un\", \"unfortunately\", \"unless\", \"unlike\", \"unlikely\", \"unto\", \"upon\", \"ups\", \"us\", \"use\", \"used\", \"useful\", \"usefully\", \"usefulness\", \"uses\", \"using\", \"usually\", \"v\", \"value\", \"various\", \"'ve\", \"via\", \"viz\", \"vol\", \"vols\", \"vs\", \"w\", \"want\", \"wants\", \"wasnt\", \"way\", \"wed\", \"welcome\", \"went\", \"werent\", \"whatever\", \"what'll\", \"whats\", \"whence\", \"whenever\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"wheres\", \"whereupon\", \"wherever\", \"whether\", \"whim\", \"whither\", \"whod\", \"whoever\", \"whole\", \"who'll\", \"whomever\", \"whos\", \"whose\", \"widely\", \"willing\", \"wish\", \"within\", \"without\", \"wont\", \"words\", \"world\", \"wouldnt\", \"www\", \"x\", \"yes\", \"yet\", \"youd\", \"youre\", \"z\", \"zero\", \"a's\", \"ain't\", \"allow\", \"allows\", \"apart\", \"appear\", \"appreciate\", \"appropriate\", \"associated\", \"best\", \"better\", \"c'mon\", \"c's\", \"cant\", \"changes\", \"clearly\", \"concerning\", \"consequently\", \"consider\", \"considering\", \"corresponding\", \"course\", \"currently\", \"definitely\", \"described\", \"despite\", \"entirely\", \"exactly\", \"example\", \"going\", \"greetings\", \"hello\", \"help\", \"hopefully\", \"ignored\", \"inasmuch\", \"indicate\", \"indicated\", \"indicates\", \"inner\", \"insofar\", \"it'd\", \"keep\", \"keeps\", \"novel\", \"presumably\", \"reasonably\", \"second\", \"secondly\", \"sensible\", \"serious\", \"seriously\", \"sure\", \"t's\", \"third\", \"thorough\", \"thoroughly\", \"three\", \"well\", \"wonder\", \"a\", \"about\", \"above\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\", \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\", \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\", \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\", \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\", \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\", \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\", \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\", \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\", \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\", \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fify\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\", \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\", \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"however\", \"hundred\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\", \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\", \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\", \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\", \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\", \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\", \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\", \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\", \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\", \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\", \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thickv\", \"thin\", \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\", \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\", \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\", \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\", \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \n",
    "             \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\", \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\", \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"the\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\", \"co\", \"op\", \"research-articl\", \"pagecount\", \"cit\", \"ibid\", \"les\", \"le\", \"au\", \"que\", \"est\", \"pas\", \"vol\", \"el\", \"los\", \"pp\", \"u201d\", \"well-b\", \"http\", \"volumtype\", \"par\", \"0o\", \"0s\", \"3a\", \"3b\", \"3d\", \"6b\", \"6o\", \"a1\", \"a2\", \"a3\", \"a4\", \"ab\", \"ac\", \"ad\", \"ae\", \"af\", \"ag\", \"aj\", \"al\", \"an\", \"ao\", \"ap\", \"ar\", \"av\", \"aw\", \"ax\", \"ay\", \"az\", \"b1\", \"b2\", \"b3\", \"ba\", \"bc\", \"bd\", \"be\", \"bi\", \"bj\", \"bk\", \"bl\", \"bn\", \"bp\", \"br\", \"bs\", \"bt\", \"bu\", \"bx\", \"c1\", \"c2\", \"c3\", \"cc\", \"cd\", \"ce\", \"cf\", \"cg\", \"ch\", \"ci\", \"cj\", \"cl\", \"cm\", \"cn\", \"cp\", \"cq\", \"cr\", \"cs\", \"ct\", \"cu\", \"cv\", \"cx\", \"cy\", \"cz\", \"d2\", \"da\", \"dc\", \"dd\", \"de\", \"df\", \"di\", \"dj\", \"dk\", \"dl\", \"do\", \"dp\", \"dr\", \"ds\", \"dt\", \"du\", \"dx\", \"dy\", \"e2\", \"e3\", \"ea\", \"ec\", \"ed\", \"ee\", \"ef\", \"ei\", \"ej\", \"el\", \"em\", \"en\", \"eo\", \"ep\", \"eq\", \"er\", \"es\", \"et\", \"eu\", \"ev\", \"ex\", \"ey\", \"f2\", \"fa\", \"fc\", \"ff\", \"fi\", \"fj\", \"fl\", \"fn\", \"fo\", \"fr\", \"fs\", \"ft\", \"fu\", \"fy\", \"ga\", \"ge\", \"gi\", \"gj\", \"gl\", \"go\", \"gr\", \"gs\", \"gy\", \"h2\", \"h3\", \"hh\", \"hi\", \"hj\", \"ho\", \"hr\", \"hs\", \"hu\", \"hy\", \"i\", \"i2\", \"i3\", \"i4\", \"i6\", \"i7\", \"i8\", \"ia\", \"ib\", \"ic\", \"ie\", \"ig\", \"ih\", \"ii\", \"ij\", \"il\", \"in\", \"io\", \"ip\", \"iq\", \"ir\", \"iv\", \"ix\", \"iy\", \"iz\", \"jj\", \"jr\", \"js\", \"jt\", \"ju\", \"ke\", \"kg\", \"kj\", \"km\", \"ko\", \"l2\", \"la\", \"lb\", \"lc\", \"lf\", \"lj\", \"ln\", \"lo\", \"lr\", \"ls\", \"lt\", \"m2\", \"ml\", \"mn\", \"mo\", \"ms\", \"mt\", \"mu\", \"n2\", \"nc\", \"nd\", \"ne\", \"ng\", \"ni\", \"nj\", \"nl\", \"nn\", \"nr\", \"ns\", \"nt\", \"ny\", \"oa\", \"ob\", \"oc\", \"od\", \"of\", \"og\", \"oi\", \"oj\", \"ol\", \"om\", \"on\", \"oo\", \"oq\", \"or\", \"os\", \"ot\", \"ou\", \"ow\", \"ox\", \"oz\", \"p1\", \"p2\", \"p3\", \"pc\", \"pd\", \"pe\", \"pf\", \"ph\", \"pi\", \"pj\", \"pk\", \"pl\", \"pm\", \"pn\", \"po\", \"pq\", \"pr\", \"ps\", \"pt\", \"pu\", \"py\", \"qj\", \"qu\", \"r2\", \"ra\", \"rc\", \"rd\", \"rf\", \"rh\", \"ri\", \"rj\", \"rl\", \"rm\", \"rn\", \"ro\", \"rq\", \"rr\", \"rs\", \"rt\", \"ru\", \"rv\", \"ry\", \"s2\", \"sa\", \"sc\", \"sd\", \"se\", \"sf\", \"si\", \"sj\", \"sl\", \"sm\", \"sn\", \"sp\", \"sq\", \"sr\", \"ss\", \"st\", \"sy\", \"sz\", \"t1\", \"t2\", \"t3\", \"tb\", \"tc\", \"td\", \"te\", \"tf\", \"th\", \"ti\", \"tj\", \"tl\", \"tm\", \"tn\", \"tp\", \"tq\", \"tr\", \"ts\", \"tt\", \"tv\", \"tx\", \"ue\", \"ui\", \"uj\", \"uk\", \"um\", \"un\", \"uo\", \"ur\", \"ut\", \"va\", \"wa\", \"vd\", \"wi\", \"vj\", \"vo\", \"wo\", \"vq\", \"vt\", \"vu\", \"x1\", \"x2\", \"x3\", \"xf\", \"xi\", \"xj\", \"xk\", \"xl\", \"xn\", \"xo\", \"xs\", \"xt\", \"xv\", \"xx\", \"y2\", \"yj\", \"yl\", \"yr\", \"ys\", \"yt\", \"zi\", \"zz\"]\n",
    "stop_list.extend([\"from\", \"subject\", \"organization\", \"lines\", \"distribution\", \"replyto\", \"nntppostinghost\", \"originator\", \"_\"])\n",
    "    \n",
    "## Remove the tokens in a document if the token is present in stop_list\n",
    "documents = []\n",
    "\n",
    "\n",
    "corpus.data = documents\n",
    "corpus.data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming and Lemmatization\n",
    "**Stemming** and **Lemmatization** are two distinct word normalization techniques. Essentially this means that, given our corpora, we wish to have variants of a word in a 'normal' form. For example, [playing, plays, played] may be normalised to \"Play\". The sentence \"the boy's cars are different colours\" may be normalised to \"the boy car be differ colour\"\n",
    "\n",
    "### Stemming\n",
    "In the case of stemming, we want to normalise all words to their stem (or root). The stem is the part of the word to which affixes (suffixes or prefixes) are assigned. Stemming a word may result in the word not actually being a word. For example, some stemming algorithms may stem [trouble, troubling, troubled] as \"troubl\".\n",
    "\n",
    "### Lemmatization\n",
    "Lemmatization attempts to properly reduce unnormalized tokens to a word that belongs in the language. The root word is called a lemma, and is the canonical form of a set of words. For example, [runs, running, ran] are all forms of the word \"run\".\n",
    "\n",
    "Before we get round to implementing this, it's worth talking about two popular NLP libraries: `nltk` and `SpaCy`. `nltk` is a general purpose library which provides many functions applicable to natural language. `SpaCy` is a more modern NLP library and is opinionated about the way language should be processed. Where possible, I recommend `SpaCy` to be used (especially when working with neural based NLP). However, because of it's opinionated nature, it doesn't provide a stemmer. A linguist has been quoted saying: \"Stemming is the poor-man's lemmatization\" (Noah Smith, 2011). \n",
    "\n",
    "Here we will use `nltk` to demonstrate stemming and lemmatizing, and then we will load in SpaCy and use its lemmatizer to lemmatize our corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Nihir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import stem\n",
    "\n",
    "porter = stem.porter.PorterStemmer()\n",
    "wnl = stem.WordNetLemmatizer()\n",
    "\n",
    "word_list = [\"feet\", \"foot\", \"foots\", \"footing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feet', 'foot', 'foot', 'foot']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[porter.stem(word) for word in word_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foot', 'foot', 'foot', 'footing']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[wnl.lemmatize(word) for word in word_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try stemming and lemmatizing the following words. What do you notice?\n",
    "- \"fly\", \"flies\", \"flying\"\n",
    "- \"organize\", \"organizes\", \"organizing\"\n",
    "- \"universe\", \"university\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list1 = [\"fly\", \"flies\", \"flying\"]\n",
    "word_list2 = [\"organize\", \"organizes\", \"organizing\"]\n",
    "word_list3 = [\"universe\", \"university\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['univers', 'univers']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[porter.stem(word) for word in word_list3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fly', 'fly', 'flying']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[wnl.lemmatize(word) for word in word_list1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, stem and lemmatize the following sentence:\n",
    "\n",
    "`sentence = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He',\n",
       " 'wa',\n",
       " 'run',\n",
       " 'and',\n",
       " 'eat',\n",
       " 'at',\n",
       " 'same',\n",
       " 'time.',\n",
       " 'He',\n",
       " 'ha',\n",
       " 'bad',\n",
       " 'habit',\n",
       " 'of',\n",
       " 'swim',\n",
       " 'after',\n",
       " 'play',\n",
       " 'long',\n",
       " 'hour',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sun.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Stem the sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He',\n",
       " 'wa',\n",
       " 'running',\n",
       " 'and',\n",
       " 'eating',\n",
       " 'at',\n",
       " 'same',\n",
       " 'time.',\n",
       " 'He',\n",
       " 'ha',\n",
       " 'bad',\n",
       " 'habit',\n",
       " 'of',\n",
       " 'swimming',\n",
       " 'after',\n",
       " 'playing',\n",
       " 'long',\n",
       " 'hour',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Sun.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lemmatize the sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah! Why did the above barely do anything? It's because the lemmatizer requires parts of speech (POS) context about the word it is currently parsing. We would need to use a POS model to identify what the POS for a token in its context is. We will use `nltk`'s built in POS tagger to tag the parts of speech, and then feed the word and POS to the lemmatizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Nihir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('He', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('running', 'VBG'),\n",
       " ('and', 'CC'),\n",
       " ('eating', 'VBG'),\n",
       " ('at', 'IN'),\n",
       " ('same', 'JJ'),\n",
       " ('time.', 'NN'),\n",
       " ('He', 'PRP'),\n",
       " ('has', 'VBZ'),\n",
       " ('bad', 'JJ'),\n",
       " ('habit', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('swimming', 'NN'),\n",
       " ('after', 'IN'),\n",
       " ('playing', 'VBG'),\n",
       " ('long', 'JJ'),\n",
       " ('hours', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Sun.', 'NNP')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "words_with_pos = nltk.pos_tag(sentence.split())\n",
    "words_with_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: https://stackoverflow.com/a/15590384/3297011\n",
    "from nltk.corpus import wordnet\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He',\n",
       " 'be',\n",
       " 'run',\n",
       " 'and',\n",
       " 'eat',\n",
       " 'at',\n",
       " 'same',\n",
       " 'time.',\n",
       " 'He',\n",
       " 'have',\n",
       " 'bad',\n",
       " 'habit',\n",
       " 'of',\n",
       " 'swimming',\n",
       " 'after',\n",
       " 'play',\n",
       " 'long',\n",
       " 'hour',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Sun.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[wnl.lemmatize(word, pos=get_wordnet_pos(pos)) for word, pos in words_with_pos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can just use `SpaCy` and save ourself the headache of doing this :). We need to install a language model for SpaCy though.\n",
    "\n",
    "```\n",
    "pip install spacy\n",
    "sudo python -m spacy download en\n",
    "```\n",
    "\n",
    "(If you're on windows, don't sudo, but run your shell as an admin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He \t\t -PRON-\n",
      "was \t\t be\n",
      "running \t\t run\n",
      "and \t\t and\n",
      "eating \t\t eat\n",
      "at \t\t at\n",
      "same \t\t same\n",
      "time \t\t time\n",
      ". \t\t .\n",
      "He \t\t -PRON-\n",
      "has \t\t have\n",
      "bad \t\t bad\n",
      "habit \t\t habit\n",
      "of \t\t of\n",
      "swimming \t\t swimming\n",
      "after \t\t after\n",
      "playing \t\t play\n",
      "long \t\t long\n",
      "hours \t\t hour\n",
      "in \t\t in\n",
      "the \t\t the\n",
      "Sun \t\t Sun\n",
      ". \t\t .\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "doc = nlp(sentence)\n",
    "for token in doc:\n",
    "    print(token.text, \"\\t\\t\", token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>\n",
    "        <b>> What is \"-PRON-\"?</b>\n",
    "    </summary>\n",
    "    Source: <a href=\"https://spacy.io/api/annotation\">https://spacy.io/api/annotation</a>\n",
    "\n",
    "spaCy adds a special case for English pronouns: all English pronouns are lemmatized to the special token -PRON-. Unlike verbs and common nouns, there’s no clear base form of a personal pronoun. Should the lemma of “me” be “I”, or should we normalize person as well, giving “it” — or maybe “he”? spaCy’s solution is to introduce a novel symbol, -PRON-, which is used as the lemma for all personal pronouns.\n",
    "</details>\n",
    "\n",
    "Great! Now using the `SpaCy` lemmatizer, lemmatize our corpus. Let's keep pronouns in their original form, and not have them replaced with \"-PRON-\". Represent the new corpus.data as a list of documents, where each document is a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2242/2242 [00:41<00:00, 53.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hsieh videoaudiocomputer equipment sale university texas austin austin hsieh mickeyccutexasedu time spring cleaning items sale roland multitimbre sound module synthesis upto simultaneous voice preset timbre char backlit lcd display midi inoutthru reference card stereo output great games support music superior sound card experimenting midi add additional sound midi setup ship canon xapshot video camera include camera carry pouch battery pack battery charger adapter video cable floppy disk hold picture pic total manual video output standard ntsc composite ntsc device television direct view picture vcr record slideshow computer video digitizer savemanipulate picture computer shipping ambico video enhanceraudio mixer threeline stereo audio mixer microphone input master volume slider wvideo enhancer boost sharpen video image dub vcrvcr camcordervcr shipping baud internal modem ship quantum mb internal prodrive hard disk unit turn unreliable erratic usage simple easily fix problem major problem rate do not time problem lie risk ship interested item email hsieh',\n",
       " 'orion auld university north texas sale vga color monitor dual floppy vga card mb board joystick mouse mb ram hard drive respond orion auld fabulous solution beast precipitate john ashberry',\n",
       " 'craig williamson video inout craig williamson ncr columbia ready buy multimedia workstation advice graphic card video window originally think targa do not work window card craig forgive divine craig williamson airhead human balki bartokomas perfect stranger']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "## Lemmatize the corpus\n",
    "documents = []\n",
    "\n",
    "    \n",
    "corpus.data = documents\n",
    "corpus.data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Of Words\n",
    "Taking stock, we currently have some processed data. We can't feed straight text into a model, so we face a challenge of how can we represent this data to a computer. In traditional NLP, two common techniques are used: **Bag of Words** (BoW) and **TF-IDF** (which we'll look at later in this notebook). BoW is an extremely simple approach which works surprisingly well for representing language. Essentially, we create a **document-term matrix**. This is simply a matrix with as many rows as documents, and as many columns as unique words/tokens/terms in the whole corpus. For every document-term pair, a count of how many times a word has appeared in that document is added to the matrix. Visually,\n",
    "\n",
    "# BoW image\n",
    "\n",
    "The vector for one document is thus just the row of that document! We could imagine building this ourselves relatively trivially (and we'll do that in a bit). For now, however, we'll use a helper function provided to us by sklearn - the CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2242, 27067)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "## Create a document-term matrix using CountVectorizer.\n",
    "\n",
    "dt_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 10739)\t3\n",
      "  (0, 25631)\t1\n",
      "  (0, 7548)\t1\n",
      "  (0, 20640)\t2\n",
      "  (0, 24977)\t1\n",
      "  (0, 23727)\t1\n",
      "  (0, 1749)\t2\n",
      "  (0, 14645)\t1\n",
      "  (0, 24014)\t2\n",
      "  (0, 22390)\t1\n",
      "  (0, 4060)\t1\n",
      "  (0, 11984)\t1\n",
      "  (0, 20356)\t1\n",
      "  (0, 15432)\t1\n",
      "  (0, 22085)\t3\n",
      "  (0, 15044)\t1\n",
      "  (0, 23315)\t1\n",
      "  (0, 25163)\t1\n",
      "  (0, 21663)\t1\n",
      "  (0, 25786)\t1\n",
      "  (0, 18417)\t1\n",
      "  (0, 24013)\t1\n",
      "  (0, 3734)\t1\n",
      "  (0, 1914)\t1\n",
      "  (0, 13100)\t1\n",
      "  :\t:\n",
      "  (1, 24977)\t1\n",
      "  (1, 23727)\t1\n",
      "  (1, 3374)\t1\n",
      "  (1, 8494)\t1\n",
      "  (1, 14277)\t2\n",
      "  (1, 10055)\t1\n",
      "  (1, 16798)\t2\n",
      "  (1, 1735)\t2\n",
      "  (1, 16182)\t1\n",
      "  (1, 25586)\t2\n",
      "  (1, 4317)\t1\n",
      "  (1, 15108)\t1\n",
      "  (1, 6829)\t1\n",
      "  (1, 2626)\t1\n",
      "  (1, 12295)\t1\n",
      "  (1, 15272)\t1\n",
      "  (1, 19331)\t1\n",
      "  (1, 6764)\t1\n",
      "  (1, 20047)\t1\n",
      "  (1, 8001)\t1\n",
      "  (1, 22026)\t1\n",
      "  (1, 2165)\t1\n",
      "  (1, 18314)\t1\n",
      "  (1, 12229)\t1\n",
      "  (1, 1475)\t1\n"
     ]
    }
   ],
   "source": [
    "print(dt_matrix[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA\n",
    "**Latent Semantic Analysis**, otherwise known as LSA or LSI, is a methodolgy for finding 'hidden' meanings between a set of documents and terms. Mathematically, it's given by:\n",
    "$$\n",
    "X \\approx USV^T\n",
    "$$\n",
    "\n",
    "Seem familiar...? Yes! LSA is actually SVD applied to NLP! As a quick recap of shapes:\n",
    "- $U \\in \\mathbb{R}^{m \\times k}$\n",
    "- $S \\in \\mathbb{R}^{k \\times k}$\n",
    "- $V \\in \\mathbb{R}^{n \\times k}$\n",
    "\n",
    "$k$ is the 'hyperparameter' we choose to represent our desired number of topics. $m$ is the number of documents in our matrix while $n$ is the number of terms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2242, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "lsa = TruncatedSVD(n_components=6, n_iter=200)\n",
    "fitted = lsa.fit_transform(dt_matrix)\n",
    "fitted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about what this shape means. What is represented as the number of rows? What about the number of columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27067\n",
      "(6, 27067)\n"
     ]
    }
   ],
   "source": [
    "print(len(vectorizer.get_feature_names()))\n",
    "print(lsa.components_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can gather that 27429 is the number of unique terms/tokens we have in our corpus (after all the pre-processing steps). With this knowledge, what does `lsa.components_.shape` imply? Obviously we interpret the matrix as having `n_components` numbers of rows and 27429 columns. Every row represents a topic and every column, the weighting of that term for that topic.\n",
    "\n",
    "So if we wanted to get the most influential terms per topic, we would need to loop over all of the rows in `lsa.components_`. What would be the `len` of one row then? We need some way of 'combining' the terms and the components together in order to sort the component values from highest to lowest. This obviously will give us a  list of the most influential words, and then we just need to extract out however many we want and print them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept 0\n",
      "image\n",
      "jpeg\n",
      "file\n",
      "format\n",
      "gif\n",
      "program\n",
      "color\n",
      "version\n",
      "display\n",
      "software\n",
      "\n",
      "Concept 1\n",
      "space\n",
      "launch\n",
      "satellite\n",
      "year\n",
      "god\n",
      "mission\n",
      "nasa\n",
      "market\n",
      "include\n",
      "commercial\n",
      "\n",
      "Concept 2\n",
      "god\n",
      "atheist\n",
      "not\n",
      "people\n",
      "jesus\n",
      "do\n",
      "religion\n",
      "atheism\n",
      "exist\n",
      "religious\n",
      "\n",
      "Concept 3\n",
      "jpeg\n",
      "launch\n",
      "space\n",
      "satellite\n",
      "gif\n",
      "commercial\n",
      "quality\n",
      "market\n",
      "year\n",
      "venture\n",
      "\n",
      "Concept 4\n",
      "jesus\n",
      "matthew\n",
      "prophecy\n",
      "gd\n",
      "day\n",
      "psalm\n",
      "speak\n",
      "isaiah\n",
      "prophet\n",
      "messiah\n",
      "\n",
      "Concept 5\n",
      "launch\n",
      "image\n",
      "satellite\n",
      "tool\n",
      "market\n",
      "commercial\n",
      "processing\n",
      "plot\n",
      "analysis\n",
      "venture\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Find the top 10 most influential words for a concept\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i, comp in enumerate(lsa.components_):\n",
    "    # Zip the components and terms together\n",
    "    # Sort the zipped terms (on what?), and only consider the top 10 highest value terms\n",
    "\n",
    "    \n",
    "    print(\"Concept {}\".format(i))\n",
    "    for term in sorted_terms:\n",
    "        print(term[0])\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok... loosely we can distinguish between some of the topics, but we can tell its not entirely perfect. There are two methods we'll use in attempt to improve on this: **TF-IDF** and **Latent Dirichlet Allocation** (LDA). TF-IDF is a way we can represent our data to a computer (instead of Bag of Words), whereas LDA is the algorithm we'll use to allocate our topics. Despite the acronym having only a one letter difference, the mathematical formulation is ridiculously more complex. We'll discuss this in a bit, but let's talk about TF-IDF.\n",
    "\n",
    "## TF-IDF\n",
    "TF-IDF stands for Term Frequency - Inverse Document Frequency. It is a measure of how important a word/term is to document, but is offset by the frequency of the term in the corpus. A [survey](http://nbn-resolving.de/urn:nbn:de:bsz:352-0-311312) conducted in 2015 showed that 83% of text-based recommender systems in digital libraries use tf–idf. Intuitively, if a word appears many times in a corpus, it is probably not an important word. However, if a word appears many times in a document, but *not* in the corpus, it probably is an important word.\n",
    "\n",
    "TF-IDF is composed of two terms:\n",
    "1) **Term Frequency:** The normalised number of times a word appears in a document. Normalised because a term would appear more times in a longer document than a shorter.\n",
    "\n",
    "$$\n",
    "\\text{TF(t)} = \\frac{\\text{Number of times term appears in a document}}{\\text{Total number of terms in document}}\n",
    "$$\n",
    "\n",
    "2) **Inverse Document Frequency:** Measures how important a term is relative to the *corpus*. Common words (e.g. stop words) appear a lot of time but provide little information about the topic of a document. We therefore scale down the importance of words which occur frequently in the corpus while scaling up the words which occur frequently in the document\n",
    "\n",
    "$$\n",
    "\\text{IDF(t)} = \\log\\left(\\frac{\\text{Total number of documents}}{\\text{Number of documents which contain term}}\\right)\n",
    "$$\n",
    "\n",
    "TF-IDF is then just:\n",
    "$$\n",
    "\\text{TF-IDF(t)} = \\text{TF(t)} * \\text{IDF(t)}\n",
    "$$\n",
    "\n",
    "Note that we end up with a document-term matrix, similar to what we had with BoW - the rows are the document and the columns are the terms. Each entry in this matrix will be the tf-idf score for a given token for a given document.\n",
    "\n",
    "As an example (we'll implement this below), assume we have a corpus with 1000 documents, and we're trying to find the tf-idf score for a document for the word \"dog\" in the first document. Let's say the word dog appears 3 times and the document length is 150. The TF score is thus $3/150 = 0.02$. Now let's say the word dog appears in 400 of our documents. Our IDF score is then $1000/400 = 2.5$. For our first document, the TF-IDF score for the word dog is therefore $0.02 * 2.5 = 0.05$.\n",
    "\n",
    "Below, we'll implement this from scratch. Feel free to implement it however you think appropiate, but purely for explicitness (and not efficiency), I would implement this as follows. The first step would be to create a document term matrix/dataframe (remember to lower-case everything!). As a reminder, the shape of this will be document x unique_terms. The entries will be the number of times the term has appeared in the document. I would also create a list of length number_of_documents, where each entry is the length of the document. Then, I would loop over every row in the matrix, and for each term in that row, work out the TF score for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 6, 5]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>second</th>\n",
       "      <th>is</th>\n",
       "      <th>first</th>\n",
       "      <th>this</th>\n",
       "      <th>and</th>\n",
       "      <th>one</th>\n",
       "      <th>third</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>this is the first document</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this document is the second document</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and this is the third one</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is this the first document</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      document  second   is  first  this  and  \\\n",
       "this is the first document                 0.0     0.0  0.0    0.0   0.0  0.0   \n",
       "this document is the second document       0.0     0.0  0.0    0.0   0.0  0.0   \n",
       "and this is the third one                  0.0     0.0  0.0    0.0   0.0  0.0   \n",
       "is this the first document                 0.0     0.0  0.0    0.0   0.0  0.0   \n",
       "\n",
       "                                      one  third  the  \n",
       "this is the first document            0.0    0.0  0.0  \n",
       "this document is the second document  0.0    0.0  0.0  \n",
       "and this is the third one             0.0    0.0  0.0  \n",
       "is this the first document            0.0    0.0  0.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "toy_corpus = ['This is the first document', \n",
    "              'This document is the second document', \n",
    "              'And this is the third one', \n",
    "              'Is this the first document']\n",
    "\n",
    "## Lowercase the toy_corpus\n",
    "\n",
    "\n",
    "## Create a document-term dataframe with entries as zeros. Rows should be the document and columns the terms\n",
    "\n",
    "print(doc_lens)\n",
    "dt_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>second</th>\n",
       "      <th>is</th>\n",
       "      <th>first</th>\n",
       "      <th>this</th>\n",
       "      <th>and</th>\n",
       "      <th>one</th>\n",
       "      <th>third</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>this is the first document</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this document is the second document</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and this is the third one</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is this the first document</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      document  second   is  first  this  and  \\\n",
       "this is the first document                 1.0     0.0  1.0    1.0   1.0  0.0   \n",
       "this document is the second document       2.0     1.0  1.0    0.0   1.0  0.0   \n",
       "and this is the third one                  0.0     0.0  1.0    0.0   1.0  1.0   \n",
       "is this the first document                 1.0     0.0  1.0    1.0   1.0  0.0   \n",
       "\n",
       "                                      one  third  the  \n",
       "this is the first document            0.0    0.0  1.0  \n",
       "this document is the second document  0.0    0.0  1.0  \n",
       "and this is the third one             1.0    1.0  1.0  \n",
       "is this the first document            0.0    0.0  1.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Populate the document term matrix with the counts of each word\n",
    "\n",
    "\n",
    "dt_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>second</th>\n",
       "      <th>is</th>\n",
       "      <th>first</th>\n",
       "      <th>this</th>\n",
       "      <th>and</th>\n",
       "      <th>one</th>\n",
       "      <th>third</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>this is the first document</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this document is the second document</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and this is the third one</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is this the first document</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      document    second        is  first  \\\n",
       "this is the first document            0.200000  0.000000  0.200000    0.2   \n",
       "this document is the second document  0.333333  0.166667  0.166667    0.0   \n",
       "and this is the third one             0.000000  0.000000  0.166667    0.0   \n",
       "is this the first document            0.200000  0.000000  0.200000    0.2   \n",
       "\n",
       "                                          this       and       one     third  \\\n",
       "this is the first document            0.200000  0.000000  0.000000  0.000000   \n",
       "this document is the second document  0.166667  0.000000  0.000000  0.000000   \n",
       "and this is the third one             0.166667  0.166667  0.166667  0.166667   \n",
       "is this the first document            0.200000  0.000000  0.000000  0.000000   \n",
       "\n",
       "                                           the  \n",
       "this is the first document            0.200000  \n",
       "this document is the second document  0.166667  \n",
       "and this is the third one             0.166667  \n",
       "is this the first document            0.200000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Populate the matrix with TF scores\n",
    "\n",
    "        \n",
    "dt_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>second</th>\n",
       "      <th>is</th>\n",
       "      <th>first</th>\n",
       "      <th>this</th>\n",
       "      <th>and</th>\n",
       "      <th>one</th>\n",
       "      <th>third</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>this is the first document</th>\n",
       "      <td>0.057536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this document is the second document</th>\n",
       "      <td>0.095894</td>\n",
       "      <td>0.231049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and this is the third one</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.231049</td>\n",
       "      <td>0.231049</td>\n",
       "      <td>0.231049</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is this the first document</th>\n",
       "      <td>0.057536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      document    second   is     first  this  \\\n",
       "this is the first document            0.057536  0.000000  0.0  0.138629   0.0   \n",
       "this document is the second document  0.095894  0.231049  0.0  0.000000   0.0   \n",
       "and this is the third one             0.000000  0.000000  0.0  0.000000   0.0   \n",
       "is this the first document            0.057536  0.000000  0.0  0.138629   0.0   \n",
       "\n",
       "                                           and       one     third  the  \n",
       "this is the first document            0.000000  0.000000  0.000000  0.0  \n",
       "this document is the second document  0.000000  0.000000  0.000000  0.0  \n",
       "and this is the third one             0.231049  0.231049  0.231049  0.0  \n",
       "is this the first document            0.000000  0.000000  0.000000  0.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Populate the matrix with TF-IDF scores. This can be done in one pass or multiple passes\n",
    "        \n",
    "dt_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are variations of the tf-idf forumla that I demonstrated above, and different variations will provide different results. A comprehensive list can be found [here](https://en.wikipedia.org/wiki/Tf%E2%80%93idf). Sklearn's implementation uses a variant, hence their returned matrix shows different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>0.580286</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538648</td>\n",
       "      <td>0.281089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267104</td>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267104</td>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.267104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>0.580286</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
       "1  0.000000  0.687624  0.000000  0.281089  0.000000  0.538648  0.281089   \n",
       "2  0.511849  0.000000  0.000000  0.267104  0.511849  0.000000  0.267104   \n",
       "3  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
       "\n",
       "          7         8  \n",
       "0  0.000000  0.384085  \n",
       "1  0.000000  0.281089  \n",
       "2  0.511849  0.267104  \n",
       "3  0.000000  0.384085  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "pd.DataFrame(csr_matrix.todense(vectorizer.fit_transform(toy_corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit an LSA model to a tf-idf vectorized corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept 0\n",
      "not\n",
      "do\n",
      "write\n",
      "space\n",
      "god\n",
      "article\n",
      "people\n",
      "university\n",
      "thing\n",
      "time\n",
      "\n",
      "Concept 1\n",
      "god\n",
      "keith\n",
      "atheist\n",
      "morality\n",
      "not\n",
      "moral\n",
      "people\n",
      "do\n",
      "schneider\n",
      "atheism\n",
      "\n",
      "Concept 2\n",
      "space\n",
      "moon\n",
      "launch\n",
      "nasa\n",
      "orbit\n",
      "lunar\n",
      "billion\n",
      "shuttle\n",
      "henry\n",
      "spencer\n",
      "\n",
      "Concept 3\n",
      "keith\n",
      "morality\n",
      "moral\n",
      "objective\n",
      "schneider\n",
      "sale\n",
      "allan\n",
      "political\n",
      "jon\n",
      "goal\n",
      "\n",
      "Concept 4\n",
      "file\n",
      "image\n",
      "keith\n",
      "format\n",
      "polygon\n",
      "graphic\n",
      "program\n",
      "morality\n",
      "color\n",
      "tiff\n",
      "\n",
      "Concept 5\n",
      "polygon\n",
      "routine\n",
      "group\n",
      "split\n",
      "newsgroup\n",
      "islamic\n",
      "algorithm\n",
      "islam\n",
      "aspect\n",
      "fast\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Implement an LSA model on a tf-idf'd corpus with 6 topics. Return the top 10 words for each of the topics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We can also see that this has loosely categorised our documents into some topics. These topics are still a bit 'mixed' - although we can see some general trends within some of the displayed concepts. We'll look at a slightly more powerful algorithm now known as LDA.\n",
    "\n",
    "## LDA\n",
    "LDA stands for Latent Dirichlet Allocation and is actually a generative model which we can use to assign a document to a collection of topics. That is, one document could contain multiple topics. For example, \"The government has increased their space exploration budget by £500 million\" could be assigned to the topics of [politics, space, money]. LDA works under the notion that every document could be a mixture of topics, and words within a document are the reason a document has been attributed to the aforementioned mixture.\n",
    "\n",
    "My personal opinion is that understanding how the underlying LDA model works is not really relevant to effectively use this algorithm - because the concepts behind it are not really going to come up in a ML or DS related job. To effectively teach this requires knowledge of concepts outside of the scope of this course. However, I can understand that this might not be satisfactory for some people, and for those who are interested in learning more, this video provides an awesome intuitive and comprehensive description: https://www.youtube.com/watch?v=T05t-SqKArY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept 0\n",
      "image\n",
      "file\n",
      "program\n",
      "format\n",
      "write\n",
      "color\n",
      "university\n",
      "jpeg\n",
      "software\n",
      "not\n",
      "\n",
      "Concept 1\n",
      "not\n",
      "write\n",
      "do\n",
      "god\n",
      "people\n",
      "article\n",
      "atheist\n",
      "thing\n",
      "time\n",
      "religion\n",
      "\n",
      "Concept 2\n",
      "sale\n",
      "university\n",
      "offer\n",
      "sell\n",
      "computer\n",
      "include\n",
      "price\n",
      "not\n",
      "do\n",
      "software\n",
      "\n",
      "Concept 3\n",
      "write\n",
      "article\n",
      "university\n",
      "good\n",
      "polygon\n",
      "orbit\n",
      "earth\n",
      "group\n",
      "graphic\n",
      "not\n",
      "\n",
      "Concept 4\n",
      "space\n",
      "launch\n",
      "nasa\n",
      "year\n",
      "satellite\n",
      "mission\n",
      "write\n",
      "orbit\n",
      "article\n",
      "moon\n",
      "\n",
      "Concept 5\n",
      "university\n",
      "do\n",
      "dos\n",
      "space\n",
      "email\n",
      "high\n",
      "usa\n",
      "war\n",
      "not\n",
      "offer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "# vectorizer = TfidfVectorizer()\n",
    "dt_matrix = vectorizer.fit_transform(corpus.data)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=6)\n",
    "fitted = lda.fit_transform(dt_matrix)\n",
    "\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i, comp in enumerate(lda.components_):\n",
    "    comp_terms = zip(terms, comp)\n",
    "    sorted_terms = sorted(comp_terms, key=lambda x: x[1], reverse=True)[:10]\n",
    "    \n",
    "    print(\"Concept {}\".format(i))\n",
    "    for term in sorted_terms:\n",
    "        print(term[0])\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1819221110106628563837773642\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1819221110106628563837773642_data = {\"mdsDat\": {\"x\": [0.24757642724239204, -0.009352360245791008, -0.07253741445583954, -0.07348731350372296, -0.013583332214541761, -0.07861600682249685], \"y\": [0.034684880641445, -0.14632861636258487, 0.13140224295600847, 0.08001533186222445, -0.03671703274079805, -0.0630568063562952], \"topics\": [1, 2, 3, 4, 5, 6], \"cluster\": [1, 1, 1, 1, 1, 1], \"Freq\": [26.625204168484217, 24.91481352884467, 20.035298258676594, 13.469317978122803, 8.55524450670257, 6.4001215591691345]}, \"tinfo\": {\"Term\": [\"god\", \"space\", \"image\", \"sale\", \"file\", \"launch\", \"atheist\", \"format\", \"jpeg\", \"orbit\", \"color\", \"university\", \"offer\", \"people\", \"religion\", \"nasa\", \"graphic\", \"do\", \"sell\", \"argument\", \"software\", \"mission\", \"satellite\", \"atheism\", \"price\", \"write\", \"email\", \"program\", \"keith\", \"dos\", \"atheism\", \"islam\", \"morality\", \"belief\", \"islamic\", \"religious\", \"god\", \"faith\", \"schneider\", \"rushdie\", \"muslim\", \"quran\", \"livesey\", \"jesus\", \"religion\", \"gregg\", \"benedikt\", \"motto\", \"muslims\", \"theist\", \"christianity\", \"punishment\", \"beauchaine\", \"liar\", \"false\", \"christian\", \"satan\", \"moral\", \"atheist\", \"altatheism\", \"argument\", \"evidence\", \"bible\", \"allan\", \"truth\", \"existence\", \"law\", \"keith\", \"murder\", \"claim\", \"kill\", \"people\", \"statement\", \"exist\", \"not\", \"objective\", \"do\", \"true\", \"write\", \"thing\", \"article\", \"human\", \"time\", \"question\", \"point\", \"post\", \"read\", \"good\", \"have\", \"man\", \"university\", \"astronaut\", \"dcx\", \"ssto\", \"larson\", \"ssf\", \"launcher\", \"orbiter\", \"physicist\", \"sherzer\", \"higgins\", \"funding\", \"jockey\", \"launch\", \"redesign\", \"otis\", \"argumentum\", \"martian\", \"spacecraft\", \"mcdonnell\", \"ariane\", \"ssrt\", \"een\", \"dewey\", \"coverage\", \"sdio\", \"payload\", \"griffin\", \"venture\", \"unify\", \"fermi\", \"mission\", \"lunar\", \"probe\", \"russian\", \"titan\", \"satellite\", \"shuttle\", \"rocket\", \"aerospace\", \"space\", \"exploration\", \"solar\", \"flight\", \"vehicle\", \"nasa\", \"station\", \"moon\", \"development\", \"orbit\", \"project\", \"pat\", \"fund\", \"mars\", \"henry\", \"cost\", \"billion\", \"commercial\", \"year\", \"propulsion\", \"earth\", \"report\", \"design\", \"april\", \"technology\", \"science\", \"article\", \"program\", \"work\", \"write\", \"time\", \"university\", \"not\", \"power\", \"include\", \"jpeg\", \"cview\", \"directory\", \"quicktime\", \"pov\", \"wolverine\", \"rayshade\", \"gif\", \"archie\", \"tracer\", \"rgb\", \"liefeld\", \"hobgoblin\", \"sabretooth\", \"client\", \"jfif\", \"temp\", \"scene\", \"fps\", \"simtel\", \"raster\", \"xforce\", \"hulk\", \"punisher\", \"spline\", \"renderer\", \"digitize\", \"palette\", \"format\", \"keown\", \"animation\", \"pixel\", \"file\", \"color\", \"viewer\", \"image\", \"shareware\", \"ftp\", \"display\", \"screen\", \"graphics\", \"postscript\", \"tiff\", \"convert\", \"package\", \"art\", \"graphic\", \"processing\", \"server\", \"bit\", \"video\", \"program\", \"code\", \"version\", \"software\", \"library\", \"user\", \"data\", \"object\", \"email\", \"university\", \"send\", \"write\", \"support\", \"computer\", \"do\", \"not\", \"include\", \"work\", \"article\", \"den\", \"px\", \"pz\", \"obo\", \"brand\", \"linux\", \"slot\", \"cassette\", \"hiram\", \"sphinx\", \"kou\", \"laptop\", \"scodal\", \"ide\", \"packaging\", \"typewriter\", \"dong\", \"graeme\", \"coplanar\", \"toner\", \"bo\", \"sony\", \"rimsat\", \"ltm\", \"retail\", \"forsale\", \"motherboard\", \"vinge\", \"cellular\", \"adaptor\", \"norton\", \"sale\", \"stereo\", \"shipping\", \"watt\", \"deck\", \"sell\", \"keyboard\", \"upgrade\", \"price\", \"offer\", \"condition\", \"buy\", \"drive\", \"car\", \"ship\", \"disk\", \"speaker\", \"manual\", \"card\", \"printer\", \"sphere\", \"computer\", \"pay\", \"interested\", \"software\", \"include\", \"hard\", \"original\", \"university\", \"email\", \"item\", \"work\", \"list\", \"usa\", \"do\", \"not\", \"year\", \"point\", \"write\", \"state\", \"sunrise\", \"tnde\", \"uccxkvb\", \"enviroleague\", \"egalon\", \"oliveira\", \"claudio\", \"enzo\", \"boesel\", \"liguori\", \"hideous\", \"gre\", \"wate\", \"diablouucpcboesel\", \"lucas\", \"improper\", \"wrench\", \"wn\", \"arff\", \"wetstein\", \"shoemakerlevy\", \"televison\", \"mayans\", \"repo\", \"pexlib\", \"autotrace\", \"batty\", \"farley\", \"hijaak\", \"assassin\", \"sirtf\", \"sunset\", \"geoffrey\", \"polygon\", \"pollution\", \"milelong\", \"ozone\", \"billboard\", \"split\", \"detach\", \"inflatable\", \"spherical\", \"sky\", \"algorithm\", \"face\", \"usgs\", \"times\", \"comet\", \"routine\", \"aspect\", \"orbit\", \"earth\", \"write\", \"good\", \"article\", \"university\", \"fast\", \"group\", \"newsgroup\", \"graphic\", \"excellent\", \"miss\", \"nasa\", \"book\", \"stuff\", \"game\", \"david\", \"point\", \"post\", \"time\", \"center\", \"moon\", \"not\", \"thing\", \"do\", \"image\", \"include\", \"program\", \"email\", \"space\", \"mpc\", \"acadalaskaedu\", \"op_col\", \"jacked\", \"fairbank\", \"xxxx\", \"auroraapr\", \"op_row\", \"compass_op\", \"olympus\", \"iraqi\", \"gulf\", \"ww\", \"burster\", \"input_image\", \"rowcol\", \"dosmpc\", \"beacon\", \"lung\", \"compass\", \"op_rowscol\", \"knoxs\", \"bursters\", \"verdict\", \"bombing\", \"lps\", \"developable\", \"iraqis\", \"nikon\", \"uhf\", \"invade\", \"alaska\", \"int\", \"grafsys\", \"dos\", \"hussein\", \"miner\", \"liquid\", \"kuwait\", \"lens\", \"mining\", \"adams\", \"hst\", \"civilian\", \"war\", \"gamma\", \"modem\", \"university\", \"do\", \"high\", \"email\", \"space\", \"usa\", \"national\", \"offer\", \"michael\", \"telescope\", \"good\", \"book\", \"sale\", \"not\", \"include\", \"write\", \"power\", \"star\", \"pat\", \"source\", \"center\"], \"Freq\": [741.0, 1199.0, 818.0, 530.0, 592.0, 444.0, 417.0, 305.0, 223.0, 320.0, 282.0, 1011.0, 318.0, 808.0, 250.0, 373.0, 312.0, 1363.0, 256.0, 238.0, 439.0, 257.0, 293.0, 204.0, 259.0, 1617.0, 511.0, 561.0, 238.0, 140.0, 204.23838546132154, 180.0096969409857, 179.07759299776419, 165.09756937676033, 148.32527206026543, 139.00619392947263, 737.2806875995526, 100.79833931146555, 96.13967459455485, 90.54808461500691, 86.82070045873287, 86.82059542739897, 82.1611261381152, 179.03177649838509, 247.93367657835466, 74.70484082379194, 70.04677704224585, 69.11497007113215, 64.45544827144826, 64.45497285865035, 61.65898909279897, 59.79612071147667, 58.86412410155635, 58.86385940230704, 57.93191533460356, 148.8723733216223, 57.00002206565476, 198.38458090127983, 412.2776751813087, 55.13540546782921, 234.7095153470397, 201.42453774562335, 161.96953624797192, 84.95502849878213, 82.9483591999, 97.16912371087459, 171.00100393695433, 225.05326930134444, 85.84043574599772, 231.18847821617072, 142.68575916482712, 633.4848267598273, 127.39777517713834, 233.52638696847683, 962.5047457182554, 131.65841012430306, 737.6394909568014, 183.77976465789706, 773.8071439375485, 350.9930409092816, 459.1701711826112, 162.0685981964043, 269.41870740727876, 205.04935518858284, 210.96564595888088, 208.57919115351285, 181.8116732282677, 197.4007322238043, 176.61006217278594, 167.07841197698974, 165.23511024274643, 67.66548338313298, 69.4098412763139, 48.91178543501084, 47.038280286131, 45.15982618165725, 43.286743467525206, 60.73073597532559, 30.160512399483817, 31.0655092907035, 29.222463486014576, 61.83389539585604, 24.533961623869736, 431.96371816458213, 53.58644467853933, 22.657461964570473, 22.654774637793007, 21.72089913489563, 149.42806888960354, 20.784057881105326, 27.952178451451797, 19.84667042824227, 18.909117870872695, 18.90733863401595, 18.89930798405303, 26.042842068662395, 64.65868698132363, 17.971014896955012, 41.39225610839672, 17.03372663138403, 17.03327625621274, 246.1490420534671, 198.73613794756116, 112.17176836348858, 60.751081383075515, 63.94200541082969, 267.8232153134414, 193.98665149989966, 139.42638073577686, 49.396920903411996, 1024.6616913869611, 64.16696346067273, 118.47070642443998, 163.65219574669652, 107.34552123680459, 288.8282495115247, 146.80704451711557, 210.77749457384914, 118.26661225334384, 241.89123167887638, 179.93797667655969, 124.20868949958985, 91.99162866428561, 101.17417507627489, 86.99226875475689, 180.8614206190037, 107.69799927739545, 123.37716104219999, 270.2567556538105, 88.66369753368251, 176.08441914862, 102.61094626447273, 137.3462257135025, 97.497849226407, 159.81398040694813, 156.03460837840638, 237.86232839145558, 182.6388545156053, 177.1513756546572, 242.15817228846825, 162.52834858132502, 153.91201508132426, 162.983931988054, 122.42315863815071, 127.30873233232495, 223.1895195346725, 67.7943076296888, 120.18637229833358, 57.73912224770245, 49.512328161500406, 44.94238215914888, 40.371782449325394, 151.19013238005203, 30.316535631267563, 28.488936067467062, 27.573682502221587, 26.660869399776026, 25.746782451174038, 25.746782446650613, 25.744608336767005, 24.832695532606312, 23.918445534019337, 23.91486915269292, 23.004460832634305, 23.004450585723195, 23.003926919172162, 22.992369113661123, 41.579174183843925, 25.61100304004786, 20.261895087857955, 20.261685160400695, 19.346562918607372, 18.433172810884688, 294.03624421912156, 17.51999988478923, 75.21285603724785, 62.84243281416641, 548.7214669001371, 262.242763088852, 75.8418867311124, 720.7434779260074, 49.49389572042626, 179.04275004666823, 188.9984651910202, 87.99302507280915, 123.54130341544402, 64.32052364044554, 78.82140322415233, 104.5068541196304, 197.94771610496431, 78.97730692984663, 212.8940813086602, 82.40694194146661, 62.27133112458872, 209.89167628462803, 122.34190987299515, 298.91647634080584, 131.17238400619004, 192.53413302968073, 218.50339393475286, 98.71336562022196, 122.92287746786926, 136.92505768277118, 112.32991055090795, 196.0658478712525, 259.22429765425886, 141.43043827188953, 287.3995554932206, 140.67473700755286, 146.54192492834292, 212.94306805525247, 217.29907226496073, 144.79402207166518, 137.87373221220508, 140.14718834545496, 36.84025824944522, 33.34548948656782, 28.10284898279972, 51.02896535012414, 62.80906941142677, 29.68517020137332, 26.243634044140844, 21.97231221433419, 16.744726241795036, 16.742923591267115, 17.52495548228115, 14.997722478253614, 17.50315296551637, 20.76008784634935, 13.250321697810636, 12.376852126626252, 12.375515008849625, 11.503402198380751, 11.503323696275341, 11.503184946571075, 11.502686418082622, 38.38263776792917, 10.62893910030435, 10.628398006992908, 12.252823547204995, 61.614050149007184, 34.86913991975963, 9.756089615405541, 9.755463968559368, 9.755240436402017, 21.04207878453983, 437.9989671714702, 51.03325862347275, 108.45548735498292, 19.016148786031188, 27.634571546800565, 190.6773190495392, 34.46805695783467, 49.524076095808674, 175.84504714296466, 206.04948815967822, 113.76485316629704, 96.86984966639753, 140.28088306011907, 74.12365964136353, 61.1263414855473, 105.47715024227864, 39.606410081629996, 81.44037795964155, 118.68830430612446, 62.09508713537178, 44.34035194613875, 183.51069759766622, 89.30552135139492, 100.08656919219435, 156.5223839324461, 179.08310376849974, 85.24481050525489, 91.9779267793105, 221.5361569605877, 137.38607499632374, 58.14191220378139, 133.6135405101837, 97.28433911329499, 91.81454624900138, 167.69142454356577, 171.19334134482284, 113.43121915498506, 100.5693648829374, 109.20648270185202, 75.03390188036398, 22.53803529183723, 20.138171140395887, 16.93740221560787, 16.93514402703706, 15.336372786654042, 15.336372786649774, 15.33637278664821, 13.736195966132435, 13.735950299422203, 12.135789740944128, 11.335781892000535, 10.534611079860186, 9.735589559084367, 9.73478330713543, 8.935182097105892, 8.934795910237872, 8.93480932654815, 8.93359878001477, 8.135254272095121, 8.135221410331674, 8.135051716875179, 8.124637204332018, 8.124040913017302, 8.123554920445306, 7.3346900946637525, 7.334627053180517, 7.334629360993959, 7.334450732834872, 7.334042621927067, 7.333868240563614, 12.935318660793536, 23.119513558148967, 17.721777738295426, 82.80067965288, 15.111347577644459, 10.489388792038774, 28.09121510395156, 28.06524282951801, 30.12053652711513, 10.527780815557408, 21.97480845883414, 12.066902438552644, 41.91376241698457, 48.94641797958317, 42.10447858074985, 12.749508696103154, 22.794849885793905, 34.754549699278115, 37.200569543621874, 23.565785277711225, 72.7970665532916, 70.7811752302864, 177.08632111004425, 93.69437182352759, 124.03100428060871, 121.22658739982731, 38.81925612630603, 59.25660078490952, 34.43164009543657, 56.885338395809, 37.50682624056911, 29.024696812462434, 53.107858706178405, 50.22427111807764, 37.49216756781368, 35.66480349113138, 37.859899788688814, 47.36760639056427, 47.46884256000331, 50.54673379167353, 39.129018615698044, 38.52601299875396, 56.13919738941253, 41.70460434249861, 45.09305844460112, 41.93267441385234, 40.172072769596106, 39.423509635925136, 38.82176943788505, 39.31350500373842, 24.204528221437684, 21.190360961207922, 19.68984722929149, 18.936054480737162, 18.924142405873766, 18.18448598500497, 15.918339754926544, 14.42249955753535, 12.165064841043245, 11.411711953552341, 10.659687161147872, 9.907288778625356, 9.906189890445946, 8.401776854221355, 7.650195407939724, 7.650195407939724, 7.650195406938145, 7.649821646387174, 7.644040738140115, 26.46396787680664, 6.897717169056114, 6.897500798048765, 6.897353248180135, 6.897337182252467, 6.897242955198304, 6.897218801070894, 6.879951783790199, 6.1448359682530596, 6.143470085201008, 6.143327774629745, 12.164867321132538, 28.470062418507258, 21.19412442732908, 11.984540971357031, 81.74480094248372, 15.113823248268115, 13.280338966306507, 22.428151147486563, 8.922825377102672, 17.04046278794944, 21.747437127869016, 21.999546517559505, 21.037693520177775, 17.898099926838682, 35.835126551828644, 16.796982757725935, 25.160452208989426, 90.21380676246784, 88.89857346235749, 41.817210263018566, 50.27970733864296, 68.89051447162439, 35.844960025998915, 27.979874539518814, 33.537033585813205, 24.639466313304048, 21.529221139906078, 32.30833558354254, 29.461651602606516, 29.776550042467107, 35.74211617561057, 29.63289807716275, 27.586714235823568, 22.970389675537895, 21.825067404272634, 21.73152476979229, 21.75945902091223, 21.569234365186944], \"Total\": [741.0, 1199.0, 818.0, 530.0, 592.0, 444.0, 417.0, 305.0, 223.0, 320.0, 282.0, 1011.0, 318.0, 808.0, 250.0, 373.0, 312.0, 1363.0, 256.0, 238.0, 439.0, 257.0, 293.0, 204.0, 259.0, 1617.0, 511.0, 561.0, 238.0, 140.0, 204.95196541597247, 180.72291928373497, 179.79097831022517, 165.81251348990665, 149.03867328845382, 139.71974816841328, 741.3180106784713, 101.51230477549737, 96.85288100607497, 91.26154760192485, 87.53399312932117, 87.53399392347022, 82.87452298390582, 180.66194237546694, 250.2358115560929, 75.41932582491697, 70.75999682206283, 69.82810592995433, 65.16866073709245, 65.16861429313916, 62.37288312033262, 60.509224113872655, 59.57733227869828, 59.577301779636024, 58.64543934760436, 150.71641317162454, 57.7135268638439, 200.92397301636692, 417.5966946628351, 55.849686425842336, 238.4483384566083, 205.91524683242807, 165.9626232983424, 86.60784083344879, 84.58661697654392, 99.57930088595657, 178.63862554599223, 238.29102205336568, 88.2694357685268, 261.72897723402974, 154.20142783458635, 808.6597000696015, 139.32254679373204, 291.4598212494024, 1605.862404881116, 149.02373630822726, 1363.9010573575374, 234.8080892030512, 1617.2443897669573, 588.8447030353552, 1021.5454086762849, 213.4255188464619, 673.7933132158764, 398.7340726620365, 494.2972501425112, 510.88193176510896, 361.3825278190176, 538.6618152420496, 399.91898823197454, 308.1135272152265, 1011.3479741012123, 68.37845959250521, 70.24478612266533, 49.625464385048645, 47.75043840493517, 45.87478495216184, 43.999760017304176, 61.7416058504943, 30.87286467787813, 31.808235313478203, 29.935172055042415, 63.522597395328745, 25.246933274137156, 444.9966667891402, 55.245688769994516, 23.37168564462576, 23.371711400657688, 22.43399835255292, 154.51552641698436, 21.496418514761704, 28.93177758258879, 20.558811359925294, 19.62117269189602, 19.621154724623608, 19.620798504352614, 27.04977210576409, 67.16477036377653, 18.68348973995578, 43.05628778658129, 17.7458876182691, 17.74583646016378, 257.19205156942144, 209.2148203156831, 117.8128270475206, 64.00309938893393, 67.71760634619542, 293.7912604650943, 212.97503028767107, 152.20524618073463, 52.27967343751014, 1199.4801788260895, 69.02662061964361, 132.12185913012064, 188.52467302603532, 120.48046485860688, 373.0658642556504, 176.80017142114608, 264.4171646358784, 140.6492531401956, 320.70253356125704, 234.85823684095726, 152.74060621287492, 109.13008705806539, 123.38359107849473, 102.50143670694548, 283.4362848835451, 139.74580196173045, 168.64355758187818, 531.822688674291, 107.59049732526016, 307.76299638276026, 135.2681566630378, 216.68071971202392, 126.97268911061342, 307.8784124432692, 334.98792463284155, 1021.5454086762849, 561.2017387941167, 580.0585716743647, 1617.2443897669573, 673.7933132158764, 1011.3479741012123, 1605.862404881116, 252.28318690466728, 579.0131650486329, 223.90554045885332, 68.51074017268257, 121.49225628974675, 58.45572830371008, 50.22898672785136, 45.65859495166449, 41.088120737519766, 154.26514201779446, 31.03311075199115, 29.205019676249975, 28.290868862395353, 27.376850076667104, 26.462763124692493, 26.462763124263734, 26.462780917868095, 25.548676175562687, 24.634589309840802, 24.634518536090134, 23.720491533435993, 23.72049567473318, 23.720431041498358, 23.720810709349664, 42.93233435248648, 26.466255190737485, 20.978248906308544, 20.978170321321727, 20.064132864080257, 19.149932381906076, 305.9464790627411, 18.235980554175352, 78.34762616679356, 65.49312452866555, 592.8849367374727, 282.0804870945818, 79.91606571781927, 818.4990979295997, 51.919225310821034, 202.53289718717846, 221.14155431383597, 100.57596924377695, 146.49177262702602, 72.07886466767947, 91.48994794539126, 125.74639700626443, 280.3684564674247, 96.43988976285667, 312.5823522006735, 103.19263933322043, 74.32979640909188, 327.4081549666663, 173.27156852141383, 561.2017387941167, 205.81313625526653, 361.5750912148417, 439.8544085285174, 144.5286697518461, 204.8302305369905, 244.1877243003621, 181.90520188169685, 511.52777834081894, 1011.3479741012123, 312.7402183063604, 1617.2443897669573, 360.29763815381693, 461.4359595831212, 1363.9010573575374, 1605.862404881116, 579.0131650486329, 580.0585716743647, 1021.5454086762849, 37.56297307834421, 34.06824159723887, 28.82619352447764, 52.37980379867007, 64.55752351887779, 30.550899136167615, 27.06597800303372, 22.709623983387434, 17.468294001177053, 17.46842026834361, 18.346298784072683, 15.720910942515443, 18.349678586410995, 21.787626073573588, 13.973523004396043, 13.099855807943522, 13.099881477542006, 12.22619823175077, 12.226184336309887, 12.22615376065531, 12.226125222052945, 40.93234142396681, 11.352575385104299, 11.352610346596109, 13.089516022837273, 65.83452485215938, 37.399717654071786, 10.478832368071124, 10.478825361058803, 10.47874759054181, 22.753952823207637, 530.3534191065569, 57.96174154492815, 129.3698433326275, 21.05190101233911, 31.40798674143268, 256.24378208773516, 40.43253062238726, 60.34671902551457, 259.7192489548671, 318.13151330985147, 163.0902945267302, 141.9494224514368, 228.32449531677685, 107.49568396787974, 85.94228086465478, 174.12662625877667, 51.36226021353567, 130.05985534104187, 217.94565872203626, 94.63517141706453, 60.34891752573313, 461.4359595831212, 171.6904673450641, 218.20798416141614, 439.8544085285174, 579.0131650486329, 179.42554760454172, 213.06960433533249, 1011.3479741012123, 511.52777834081894, 97.94447542167022, 580.0585716743647, 302.59044576508734, 274.27383213870064, 1363.9010573575374, 1605.862404881116, 531.822688674291, 494.2972501425112, 1617.2443897669573, 314.0513677100153, 23.273798044787824, 20.873134243680532, 17.672365318922868, 17.672752276158302, 16.072067387344575, 16.072067387345307, 16.07206738734558, 14.47163823894131, 14.471695504476804, 12.87125712815756, 12.071064049657446, 11.270944015961774, 10.470642448483737, 10.470764331079481, 9.670471086070256, 9.670526010863783, 9.670550952282222, 9.670759344567514, 8.870255523071124, 8.870261746481043, 8.870290890261629, 8.872038146030567, 8.872140559128786, 8.872224028757678, 8.070116231567535, 8.07012771764067, 8.070138396976802, 8.07015632186033, 8.070201513386353, 8.070206382624553, 14.424146401213909, 26.90565776088175, 21.21706966015508, 118.90224987993182, 17.973297447509573, 12.020654864681024, 37.160545718243306, 39.719836834061894, 44.67801436593896, 12.20955246882215, 30.871664391652626, 14.62506645385326, 81.70762479273957, 112.46369680805603, 96.73337388185988, 16.440273937670785, 41.662209380465306, 82.91321598661953, 92.56925352059618, 44.605943403531604, 320.70253356125704, 307.76299638276026, 1617.2443897669573, 538.6618152420496, 1021.5454086762849, 1011.3479741012123, 116.16494595363373, 296.66386780889343, 98.94489542605274, 312.5823522006735, 124.67719709730628, 73.84723948385775, 373.0658642556504, 395.13163108204265, 173.4276542457387, 159.29967326190163, 199.210379210371, 494.2972501425112, 510.88193176510896, 673.7933132158764, 277.95856008098076, 264.4171646358784, 1605.862404881116, 588.8447030353552, 1363.9010573575374, 818.4990979295997, 579.0131650486329, 561.2017387941167, 511.52777834081894, 1199.4801788260895, 24.947663105498172, 21.93874813298405, 20.43276267540671, 19.68054539757152, 19.68348476660468, 18.927894925729756, 16.67254997622474, 15.165415003758241, 12.907980287341486, 12.155702189911992, 11.40312423558684, 10.650626956111678, 10.650896030723572, 9.145806518249215, 8.393110854527002, 8.393110854527002, 8.393110854689262, 8.393202811983242, 8.394580171230366, 29.078677042321257, 7.640632615729853, 7.640684935923761, 7.640715559316173, 7.64072321488683, 7.640745681317939, 7.640748848314766, 7.644448047690637, 6.888250453840657, 6.888440286448576, 6.888456181279493, 13.78172578712547, 33.177757085286785, 24.558907954722674, 13.719996596990782, 140.02842877011858, 19.660030026994193, 16.838350115948934, 32.88589190611725, 10.885349288013183, 26.8630541439895, 38.65254279922689, 39.49874039393217, 39.843822739404736, 33.99177514183843, 108.21192859880935, 31.423904813562174, 65.44022296275455, 1011.3479741012123, 1363.9010573575374, 279.4225194891292, 511.52777834081894, 1199.4801788260895, 274.27383213870064, 160.40027131725282, 318.13151330985147, 128.05989466209687, 85.44583471859252, 538.6618152420496, 395.13163108204265, 530.3534191065569, 1605.862404881116, 579.0131650486329, 1617.2443897669573, 252.28318690466728, 122.6945335265947, 152.74060621287492, 205.7400635584701, 277.95856008098076], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.7112, -5.8375, -5.8427, -5.9239, -6.0311, -6.096, -4.4275, -6.4174, -6.4647, -6.5246, -6.5666, -6.5666, -6.6218, -5.8429, -5.5173, -6.7169, -6.7813, -6.7947, -6.8645, -6.8645, -6.9089, -6.9395, -6.9553, -6.9553, -6.9712, -6.0274, -6.9874, -5.7403, -5.0088, -7.0207, -5.5721, -5.7251, -5.9431, -6.5884, -6.6123, -6.454, -5.8888, -5.6141, -6.578, -5.5872, -6.0698, -4.5792, -6.1832, -5.5772, -4.1609, -6.1503, -4.427, -5.8167, -4.3792, -5.1697, -4.9011, -5.9425, -5.4342, -5.7072, -5.6788, -5.6902, -5.8275, -5.7452, -5.8565, -5.912, -5.9231, -6.7495, -6.7241, -7.0741, -7.1131, -7.1539, -7.1962, -6.8576, -7.5576, -7.528, -7.5891, -6.8396, -7.764, -4.8957, -6.9828, -7.8436, -7.8437, -7.8858, -5.9573, -7.9299, -7.6336, -7.9761, -8.0244, -8.0245, -8.025, -7.7043, -6.795, -8.0753, -7.241, -8.1289, -8.1289, -5.4581, -5.6721, -6.2441, -6.8573, -6.8061, -5.3738, -5.6963, -6.0265, -7.0642, -4.032, -6.8026, -6.1894, -5.8663, -6.288, -5.2983, -5.975, -5.6133, -6.1911, -5.4756, -5.7715, -6.1421, -6.4424, -6.3472, -6.4983, -5.7664, -6.2848, -6.1488, -5.3647, -6.4792, -5.7931, -6.3331, -6.0416, -6.3843, -5.8901, -5.914, -5.4924, -5.7566, -5.7871, -5.4745, -5.8732, -5.9277, -5.8704, -6.1566, -6.1175, -5.3381, -6.5296, -5.9571, -6.6902, -6.8439, -6.9407, -7.048, -5.7276, -7.3344, -7.3966, -7.4293, -7.4629, -7.4978, -7.4978, -7.4979, -7.534, -7.5715, -7.5716, -7.6104, -7.6104, -7.6105, -7.611, -7.0185, -7.5031, -7.7374, -7.7374, -7.7836, -7.832, -5.0624, -7.8828, -6.4258, -6.6055, -4.4385, -5.1768, -6.4175, -4.1658, -6.8443, -5.5585, -5.5044, -6.2689, -5.9295, -6.5822, -6.3789, -6.0969, -5.4581, -6.377, -5.3853, -6.3344, -6.6146, -5.3995, -5.9393, -5.046, -5.8696, -5.4858, -5.3593, -6.1539, -5.9346, -5.8267, -6.0247, -5.4677, -5.1884, -5.7943, -5.0852, -5.7997, -5.7588, -5.3851, -5.3648, -5.7708, -5.8198, -5.8034, -6.7424, -6.8421, -7.0132, -6.4166, -6.2089, -6.9584, -7.0816, -7.2593, -7.531, -7.5311, -7.4854, -7.6411, -7.4867, -7.316, -7.765, -7.8332, -7.8333, -7.9064, -7.9064, -7.9064, -7.9065, -6.7014, -7.9855, -7.9855, -7.8433, -6.2281, -6.7974, -8.0711, -8.0712, -8.0712, -7.3025, -4.2668, -6.4166, -5.6627, -7.4037, -7.03, -5.0985, -6.809, -6.4466, -5.1794, -5.0209, -5.6149, -5.7757, -5.4054, -6.0433, -6.2361, -5.6905, -6.67, -5.9492, -5.5725, -6.2204, -6.5571, -5.1368, -5.857, -5.743, -5.2958, -5.1612, -5.9035, -5.8275, -4.9485, -5.4262, -6.2862, -5.4541, -5.7714, -5.8293, -5.2269, -5.2062, -5.6178, -5.7382, -5.6558, -6.0311, -6.78, -6.8926, -7.0656, -7.0658, -7.1649, -7.1649, -7.1649, -7.2751, -7.2752, -7.399, -7.4672, -7.5405, -7.6194, -7.6195, -7.7052, -7.7052, -7.7052, -7.7053, -7.799, -7.799, -7.799, -7.8003, -7.8003, -7.8004, -7.9026, -7.9026, -7.9026, -7.9026, -7.9026, -7.9027, -7.3352, -6.7545, -7.0204, -5.4787, -7.1797, -7.5448, -6.5597, -6.5606, -6.49, -7.5412, -6.8053, -7.4047, -6.1596, -6.0044, -6.155, -7.3497, -6.7686, -6.3469, -6.2788, -6.7354, -5.6075, -5.6356, -4.7185, -5.3551, -5.0746, -5.0975, -6.2363, -5.8133, -6.3562, -5.8541, -6.2706, -6.527, -5.9228, -5.9787, -6.271, -6.321, -6.2613, -6.0372, -6.0351, -5.9723, -6.2283, -6.2438, -5.8673, -6.1646, -6.0864, -6.1591, -6.202, -6.2208, -6.2362, -6.2236, -6.4184, -6.5514, -6.6248, -6.6639, -6.6645, -6.7044, -6.8375, -6.9362, -7.1064, -7.1703, -7.2385, -7.3117, -7.3118, -7.4765, -7.5702, -7.5702, -7.5702, -7.5703, -7.571, -6.3292, -7.6738, -7.6738, -7.6738, -7.6738, -7.6738, -7.6738, -7.6763, -7.7893, -7.7896, -7.7896, -7.1064, -6.2561, -6.5512, -7.1213, -5.2013, -6.8893, -7.0187, -6.4946, -7.4163, -6.7694, -6.5254, -6.5139, -6.5586, -6.7202, -6.026, -6.7837, -6.3797, -5.1028, -5.1174, -5.8716, -5.6873, -5.3724, -6.0257, -6.2735, -6.0923, -6.4006, -6.5355, -6.1296, -6.2219, -6.2112, -6.0286, -6.2161, -6.2876, -6.4707, -6.5219, -6.5262, -6.5249, -6.5337], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.3198, 1.3194, 1.3193, 1.319, 1.3185, 1.3182, 1.3179, 1.3163, 1.3159, 1.3155, 1.3151, 1.3151, 1.3147, 1.3142, 1.3141, 1.3138, 1.3132, 1.313, 1.3123, 1.3123, 1.3118, 1.3115, 1.3113, 1.3113, 1.3111, 1.311, 1.3109, 1.3106, 1.3105, 1.3104, 1.3075, 1.3013, 1.299, 1.304, 1.3038, 1.2988, 1.2796, 1.2662, 1.2954, 1.1992, 1.2457, 1.0792, 1.2338, 1.1017, 0.8114, 1.1994, 0.7087, 1.0783, 0.5862, 0.8059, 0.5237, 1.048, 0.4067, 0.6583, 0.4719, 0.4275, 0.6363, 0.3195, 0.506, 0.7113, -0.4884, 1.3792, 1.3778, 1.3752, 1.3747, 1.374, 1.3734, 1.3732, 1.3664, 1.3661, 1.3656, 1.3628, 1.3611, 1.36, 1.3592, 1.3587, 1.3586, 1.3574, 1.3562, 1.356, 1.3553, 1.3545, 1.3527, 1.3526, 1.3522, 1.3518, 1.3517, 1.3508, 1.3503, 1.3487, 1.3487, 1.3458, 1.3383, 1.3406, 1.3376, 1.3323, 1.2972, 1.2963, 1.302, 1.333, 1.2322, 1.3167, 1.2806, 1.2482, 1.2743, 1.1338, 1.2038, 1.163, 1.2164, 1.1077, 1.1233, 1.1829, 1.2189, 1.1913, 1.2257, 0.9405, 1.1292, 1.0772, 0.7128, 1.1962, 0.8313, 1.1134, 0.9338, 1.1256, 0.734, 0.6257, -0.0677, 0.2671, 0.2036, -0.5092, -0.0324, -0.493, -0.8981, 0.6666, -0.125, 1.6045, 1.5972, 1.5969, 1.5953, 1.5933, 1.5919, 1.5901, 1.5875, 1.5843, 1.5828, 1.582, 1.5812, 1.5802, 1.5802, 1.5802, 1.5793, 1.5782, 1.578, 1.577, 1.577, 1.577, 1.5765, 1.5756, 1.5748, 1.5729, 1.5729, 1.5713, 1.5695, 1.568, 1.5676, 1.5668, 1.5664, 1.5303, 1.5348, 1.5553, 1.4805, 1.5598, 1.4844, 1.4506, 1.474, 1.4373, 1.4938, 1.4586, 1.4227, 1.2596, 1.4079, 1.2236, 1.3827, 1.4307, 1.1631, 1.2596, 0.9778, 1.1572, 0.9775, 0.908, 1.2264, 1.0971, 1.0292, 1.1256, 0.6487, 0.2463, 0.8141, -0.1199, 0.6672, 0.4606, -0.2494, -0.3925, 0.2217, 0.1709, -0.3787, 1.9853, 1.9833, 1.9793, 1.9786, 1.9773, 1.976, 1.9739, 1.9718, 1.9625, 1.9623, 1.959, 1.9577, 1.9575, 1.9564, 1.9516, 1.948, 1.9479, 1.9438, 1.9438, 1.9438, 1.9438, 1.9404, 1.9389, 1.9388, 1.9387, 1.9385, 1.9347, 1.9333, 1.9332, 1.9332, 1.9265, 1.8134, 1.8775, 1.8284, 1.9031, 1.8768, 1.7092, 1.8452, 1.8071, 1.6148, 1.5704, 1.6446, 1.6227, 1.5176, 1.633, 1.664, 1.5035, 1.7448, 1.5366, 1.397, 1.5834, 1.6965, 1.0827, 1.3511, 1.2253, 0.9715, 0.8313, 1.2605, 1.1647, 0.4863, 0.6901, 1.4832, 0.5366, 0.87, 0.9104, -0.0912, -0.2339, 0.4596, 0.4125, -0.6905, 0.5731, 2.4265, 2.4228, 2.4161, 2.416, 2.4118, 2.4118, 2.4118, 2.4065, 2.4064, 2.3998, 2.3958, 2.3911, 2.3858, 2.3857, 2.3795, 2.3795, 2.3795, 2.3793, 2.3721, 2.3721, 2.3721, 2.3706, 2.3705, 2.3705, 2.3631, 2.3631, 2.3631, 2.363, 2.363, 2.3629, 2.3497, 2.307, 2.2786, 2.0968, 2.2852, 2.3224, 2.1788, 2.1113, 2.0644, 2.3104, 2.1187, 2.2664, 1.7911, 1.6267, 1.6268, 2.2044, 1.8556, 1.5891, 1.547, 1.8206, 0.9758, 0.9889, 0.2468, 0.7096, 0.3501, 0.3372, 1.3625, 0.8479, 1.403, 0.7548, 1.2574, 1.5248, 0.5092, 0.3959, 0.927, 0.962, 0.7982, 0.1134, 0.0826, -0.1314, 0.498, 0.5324, -0.895, -0.1889, -0.9508, -0.5128, -0.2095, -0.1971, -0.1198, -0.9594, 2.7186, 2.7141, 2.7118, 2.7103, 2.7095, 2.7088, 2.7026, 2.6986, 2.6896, 2.6857, 2.6814, 2.6765, 2.6764, 2.664, 2.6562, 2.6562, 2.6562, 2.6561, 2.6552, 2.6546, 2.6466, 2.6465, 2.6465, 2.6465, 2.6465, 2.6465, 2.6435, 2.6346, 2.6344, 2.6344, 2.6241, 2.5958, 2.6015, 2.6136, 2.2106, 2.4859, 2.5115, 2.3661, 2.55, 2.2937, 2.1737, 2.1636, 2.1102, 2.1074, 1.6437, 2.1225, 1.793, 0.332, 0.0182, 0.8494, 0.4291, -0.1083, 0.7139, 1.0027, 0.499, 1.1007, 1.3704, -0.0649, 0.1527, -0.131, -1.0562, -0.2236, -1.3223, 0.3525, 1.0222, 0.7989, 0.5023, 0.1926]}, \"token.table\": {\"Topic\": [6, 1, 2, 5, 6, 4, 2, 4, 2, 3, 4, 6, 2, 3, 4, 5, 6, 1, 2, 1, 3, 4, 5, 1, 2, 3, 5, 3, 5, 1, 3, 2, 2, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 5, 5, 2, 1, 1, 5, 6, 5, 5, 6, 1, 1, 1, 1, 6, 2, 5, 6, 1, 2, 4, 5, 1, 2, 3, 4, 5, 6, 4, 5, 6, 1, 2, 3, 4, 5, 6, 4, 6, 6, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 4, 4, 2, 3, 4, 5, 6, 1, 5, 1, 1, 2, 6, 1, 2, 3, 4, 5, 6, 5, 3, 1, 2, 3, 4, 5, 6, 3, 4, 5, 2, 5, 6, 2, 3, 4, 5, 6, 2, 6, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 6, 2, 3, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 2, 4, 5, 4, 1, 2, 3, 4, 5, 6, 2, 5, 6, 2, 3, 4, 5, 6, 2, 5, 3, 3, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 4, 3, 4, 5, 6, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 5, 1, 2, 3, 4, 5, 6, 5, 5, 1, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 3, 4, 2, 3, 5, 1, 2, 3, 4, 5, 6, 6, 1, 1, 5, 1, 2, 3, 4, 5, 6, 2, 1, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 3, 4, 5, 6, 4, 6, 3, 2, 3, 4, 5, 6, 1, 2, 4, 5, 2, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 6, 3, 5, 2, 3, 6, 1, 3, 5, 1, 2, 3, 4, 5, 6, 4, 5, 6, 3, 4, 5, 3, 4, 5, 6, 5, 1, 2, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 4, 5, 6, 5, 2, 1, 2, 3, 4, 5, 6, 5, 4, 3, 2, 3, 4, 5, 6, 2, 3, 1, 2, 3, 4, 5, 6, 1, 6, 4, 1, 2, 3, 4, 5, 6, 5, 1, 2, 3, 4, 5, 6, 2, 5, 6, 4, 6, 1, 2, 3, 4, 5, 6, 4, 6, 6, 6, 1, 1, 1, 2, 3, 4, 5, 6, 6, 1, 4, 3, 2, 3, 1, 2, 3, 3, 1, 3, 4, 1, 2, 5, 6, 6, 4, 1, 6, 4, 2, 1, 2, 3, 5, 2, 1, 4, 5, 6, 4, 5, 6, 1, 1, 2, 3, 4, 5, 6, 3, 5, 4, 2, 6, 1, 2, 3, 4, 5, 6, 1, 6, 4, 5, 2, 5, 6, 1, 2, 3, 4, 5, 6, 3, 4, 5, 6, 2, 5, 6, 2, 5, 2, 1, 2, 3, 4, 5, 6, 5, 6, 5, 6, 2, 5, 6, 1, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 2, 3, 4, 6, 1, 2, 3, 5, 6, 1, 5, 1, 3, 4, 5, 6, 1, 6, 1, 4, 5, 1, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 6, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 5, 6, 1, 2, 3, 5, 4, 1, 2, 3, 4, 5, 6, 5, 6, 6, 6, 6, 1, 2, 5, 6, 2, 1, 2, 3, 4, 5, 6, 2, 5, 6, 2, 3, 4, 5, 6, 4, 3, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 2, 3, 6, 1, 2, 3, 4, 5, 6, 5, 2, 3, 5, 1, 2, 3, 4, 5, 6, 1, 2, 5, 3, 5, 1, 2, 3, 4, 5, 6, 3, 5, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 4, 6, 1, 2, 3, 5, 2, 3, 4, 6, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 3, 5, 3, 1, 4, 4, 1, 2, 3, 4, 5, 6, 3, 1, 3, 3, 1, 2, 3, 4, 5, 6, 1, 2, 1, 6, 1, 3, 5, 1, 2, 3, 5, 6, 4, 3, 4, 2, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 6, 3, 2, 3, 4, 5, 6, 1, 2, 3, 5, 6, 3, 1, 1, 2, 3, 4, 5, 6, 4, 3, 4, 5, 2, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 3, 4, 5, 3, 4, 5, 2, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 5, 2, 3, 4, 6, 3, 5, 6, 1, 2, 4, 5, 6, 4, 1, 2, 3, 4, 5, 6, 2, 3, 5, 6, 3, 4, 5, 6, 1, 2, 3, 5, 6, 1, 2, 3, 4, 5, 6, 2, 6, 1, 2, 3, 4, 2, 3, 4, 5, 6, 2, 5, 6, 4, 3, 1, 2, 3, 4, 5, 6, 2, 2, 2, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 4, 5, 2, 3, 4, 5, 6, 3, 4, 6, 1, 2, 3, 4, 5, 6, 5, 1, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 3, 6, 5, 3, 1, 1, 2, 3, 4, 5, 6, 3, 5, 1, 2, 3, 4, 5, 6, 1, 2, 5, 6, 2, 5, 6, 5, 4, 3, 1, 2, 3, 4, 5, 6, 1, 5, 4, 5, 6, 2, 1, 2, 3, 4, 5, 6, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 5, 2, 4, 5, 6, 1, 2, 6, 1, 2, 3, 4, 5, 2, 3, 4, 6, 3, 5, 4, 1, 2, 3, 4, 5, 6, 5, 2, 4, 5, 5, 3, 1, 2, 3, 4, 5, 6, 5, 1, 2, 3, 4, 5, 6, 6, 3, 6, 1, 2, 3, 4, 5, 6], \"Freq\": [0.9572104968207973, 0.050634526064715774, 0.25317263032357884, 0.15190357819414732, 0.5569797867118735, 0.9543125181320399, 0.9372667573864949, 0.038255786015775305, 0.06028135038962391, 0.030140675194811953, 0.030140675194811953, 0.8439389054547347, 0.00889175821515737, 0.3734538450366096, 0.16894340608799005, 0.43569615254271116, 0.01778351643031474, 0.9814353894754085, 0.011546298699710689, 0.9847861916472789, 0.9572721430044756, 0.012763628573393008, 0.012763628573393008, 0.05512996573540225, 0.7639438109048597, 0.0787570939077175, 0.094508512689261, 0.9667094040218039, 0.9018905914482813, 0.985538425308693, 0.012581341599685443, 0.9840956704331362, 0.9677939739468502, 0.08295322630160408, 0.8191631097283403, 0.07258407301390357, 0.02073830657540102, 0.4493192334883778, 0.23298034329026998, 0.13704726075898235, 0.04698763226022252, 0.1213847166722415, 0.01174690806505563, 0.20176683449065758, 0.2466039088219148, 0.5380448919750869, 0.8673879784625154, 0.994465222019323, 0.9953551779118568, 0.9865978473144913, 0.011973274846049651, 0.9596612409509161, 0.8673964334788092, 0.8673952856399969, 0.9531522327302929, 0.9903095312157053, 0.9950998059627381, 0.9892595130554632, 0.9761233992353868, 0.018076359245099757, 0.15105802234450968, 0.7049374376077118, 0.15105802234450968, 0.17174040052074285, 0.7728318023433428, 0.050090950151883334, 0.007155850021697619, 0.11300879174425879, 0.051922958368983765, 0.6414012504403876, 0.11606308341302253, 0.039705791693928766, 0.039705791693928766, 0.9815047516734844, 0.9674056502687688, 0.9161409490588597, 0.3543123075634795, 0.1391941208285098, 0.13666331863162778, 0.16956374719109374, 0.1265401098440998, 0.0733932637095779, 0.9758738651363796, 0.015490061351371105, 0.8747178265839198, 0.9161445607623803, 0.014089525448292914, 0.11271620358634331, 0.035223813620732285, 0.6833419842422063, 0.09158191541390394, 0.06340286451731811, 0.2511728750715958, 0.03721079630690308, 0.00930269907672577, 0.688399731677707, 0.00930269907672577, 0.009176599395130701, 0.004588299697565351, 0.3762405752003587, 0.5460076640102767, 0.036706397580522805, 0.027529798185392102, 0.9687522794782274, 0.954305435527325, 0.43531668880694924, 0.12591805048134894, 0.21945717369606532, 0.14030868482207454, 0.07914848887399077, 0.9886116373425765, 0.006634977431829373, 0.9940217110116069, 0.05883776271331945, 0.4118643389932361, 0.529539864419875, 0.8825923764392627, 0.019103731091758933, 0.08023567058538753, 0.0038207462183517866, 0.0038207462183517866, 0.007641492436703573, 0.9332962361650078, 0.9825120073621735, 0.1020343034564813, 0.043728987195634846, 0.6364997025142406, 0.07288164532605808, 0.13604573794197508, 0.0048587763550705385, 0.9288129168330285, 0.053176312032425295, 0.010635262406485059, 0.5668577613439192, 0.42212812014972706, 0.012060803432849345, 0.7293489402361678, 0.20160865014658297, 0.05336699562703667, 0.005929666180781852, 0.005929666180781852, 0.0687789199312331, 0.8941259591060303, 0.9296574470111394, 0.05201155111899496, 0.14086461761394467, 0.31857075060384415, 0.398755225245628, 0.07585017871520099, 0.015170035743040197, 0.06744729986490472, 0.0490525817199307, 0.03065786357495669, 0.6989992895090126, 0.0490525817199307, 0.10423673615485275, 0.11133519793257017, 0.015905028276081454, 0.8350139844942763, 0.015905028276081454, 0.03181005655216291, 0.9815000060453731, 0.056450076625065446, 0.6385914918210528, 0.09525950430479793, 0.15876584050799655, 0.02469690852346613, 0.028225038312532723, 0.9683601814566876, 0.9925451079437291, 0.3480928463686655, 0.5610437641471433, 0.02457125974367051, 0.0450473095300626, 0.02047604978639209, 0.3463674948740212, 0.1606342005212852, 0.11545583162467374, 0.15059456298870488, 0.19075311311902618, 0.0401585501303213, 0.9822793093783272, 0.06367807069154315, 0.8914929896816041, 0.06367807069154315, 0.9850125527292521, 0.02307542639993614, 0.6322666833582502, 0.17075815535952743, 0.11076204671969347, 0.03692068223989783, 0.02769051167992337, 0.08190308388072062, 0.9009339226879268, 0.9156972428002408, 0.838966417279021, 0.08531861870634111, 0.03554942446097546, 0.014219769784390185, 0.02843953956878037, 0.9683426009660844, 0.9550401177799264, 0.9469634261650391, 0.9877172723981036, 0.33883387777994217, 0.6030094435066767, 0.005742947081015969, 0.051686523729143716, 0.0135659713946955, 0.036175923719188, 0.8546561978658165, 0.09043980929797, 0.0045219904648985, 0.5410949687434242, 0.08211739363043837, 0.1561696861007444, 0.12317609044565755, 0.032993595655086846, 0.0652540002956162, 0.9160388222269334, 0.1856765817367243, 0.15711095377722825, 0.0642726629088661, 0.5855953731696689, 0.953162675735466, 0.11387302078091824, 0.0788351682329434, 0.11387302078091824, 0.6131624195895597, 0.004379731568496856, 0.07445543666444654, 0.1364686479324669, 0.5718686199074804, 0.02274477465541115, 0.012997014088806373, 0.23069700007631314, 0.025994028177612746, 0.9683417142466424, 0.9332962361650662, 0.009774640228176656, 0.16421395583336781, 0.3831658969445249, 0.26782514225204035, 0.07624219377977791, 0.09774640228176655, 0.9619327954330074, 0.9674094783773552, 0.97612975771324, 0.019425467815188852, 0.02406213862554676, 0.09624855450218704, 0.0882278416270048, 0.49728419826129977, 0.30478708925692566, 0.8028550864984096, 0.1029301392946679, 0.05146506964733395, 0.02058602785893358, 0.02401703250208918, 0.9740980217474059, 0.010042247646880473, 0.010042247646880473, 0.9271785207718378, 0.0434614931611799, 0.014487164387059966, 0.3204685079821592, 0.09303924425288493, 0.010337693805876102, 0.03101308141762831, 0.4341831398467963, 0.10337693805876103, 0.9652762315865792, 0.9949532741214933, 0.9889942107215073, 0.8673933590404557, 0.017216897779113876, 0.07747604000601244, 0.4562477911465177, 0.03443379555822775, 0.33572950669272056, 0.0688675911164555, 0.9579711859828051, 0.02530001872292793, 0.023613350808066067, 0.9259806852591622, 0.013493343318894896, 0.003373335829723724, 0.010120007489171173, 0.8699126611260668, 0.031826072968026836, 0.08486952791473822, 0.0053043454946711385, 0.0053043454946711385, 0.9609523891259059, 0.022879818788712043, 0.006537091082489155, 0.009805636623733733, 0.9417551070540824, 0.06075839400348919, 0.9696257755695997, 0.059249633845457436, 0.88380703819474, 0.004937469487121453, 0.03456228640985017, 0.014812408461364359, 0.06414363067698714, 0.843030574611831, 0.027490127432994487, 0.06414363067698714, 0.9760306181144804, 0.015742429324427105, 0.10671710526392993, 0.006277476780231172, 0.18832430340693518, 0.3452612229127145, 0.2259891640883222, 0.12554953560462345, 0.03182290698539833, 0.38187488382477996, 0.03182290698539833, 0.5409894187517716, 0.14139558610366898, 0.8483735166220138, 0.012964691659048292, 0.978834220258146, 0.006482345829524146, 0.9941752249152569, 0.0013489487447968208, 0.0026978974895936416, 0.3657211155973203, 0.12066940362348132, 0.15222909380193028, 0.12623876071379583, 0.17450652216318838, 0.05940647563002157, 0.9814988905411868, 0.07288631545428596, 0.8746357854514315, 0.681420427290332, 0.1343645912966852, 0.18235194533121563, 0.8464639192789961, 0.12287379473404782, 0.02047896578900797, 0.013652643859338646, 0.9759608409394931, 0.9944400746051427, 0.9634174477322565, 0.306744466968997, 0.29326119369563447, 0.1651700975986907, 0.033708183183406265, 0.19887828078209696, 0.9389118632365274, 0.2062136663032452, 0.12818687364796322, 0.08917347732032224, 0.4737340982642119, 0.027866711662600702, 0.07245345032276182, 0.4425896374225934, 0.10252076347077022, 0.2675541875944491, 0.11502329560135195, 0.060012154226792326, 0.012502532130581733, 0.8487685909099545, 0.019511921630113897, 0.11707152978068337, 0.009755960815056948, 0.9112701212377511, 0.9687600908615827, 0.13241595583508248, 0.3364081040134528, 0.15031000392090443, 0.13957357506941126, 0.08947024042910978, 0.15031000392090443, 0.8673885018098781, 0.9731917724108892, 0.9825126679889037, 0.22588194056739394, 0.07529398018913132, 0.07529398018913132, 0.10039197358550841, 0.5270578613239192, 0.02329246743933652, 0.9782836324521338, 0.7590470009190543, 0.07965308034335755, 0.1030804569149333, 0.03279832720020605, 0.02342737657157575, 0.00468547531431515, 0.2034584888480741, 0.7629693331802779, 0.9638498443605609, 0.0061087422242095835, 0.05009168623851858, 0.8808806287310219, 0.007330490669051499, 0.0513134346833605, 0.004886993779367667, 0.9306629225638274, 0.10017043394018238, 0.21933870880005452, 0.2504260848504559, 0.30914668405676976, 0.06908305788978095, 0.05181229341733571, 0.2591373078726237, 0.7126275966497151, 0.9531626757538929, 0.12215526869235652, 0.8550868808464956, 0.03207948612376096, 0.1420662956909414, 0.21997361913436086, 0.45827837319658515, 0.07332453971145363, 0.07332453971145363, 0.07255985320315791, 0.8707182384378949, 0.9646479133912467, 0.8710484672714828, 0.9959998472435033, 0.9930308471919664, 0.020419732622892785, 0.1531479946716959, 0.10209866311446393, 0.5921722460638907, 0.08167893049157114, 0.04083946524578557, 0.9654203994948485, 0.9908008164109464, 0.005535200091681265, 0.9785242815795092, 0.9902192764778243, 0.9959557032086049, 0.9442235719212739, 0.00839309841707799, 0.046162041293928945, 0.987059618018658, 0.024732560257959856, 0.09893024103183942, 0.840907048770635, 0.9273584687775897, 0.019455072771557825, 0.045395169800301595, 0.006485024257185942, 0.9161482326130881, 0.9811243244128717, 0.09186659734485397, 0.8267993761036858, 0.9541431825960021, 0.9842841567532581, 0.0022472078436350305, 0.9707937884503333, 0.011236039218175153, 0.015730454905445213, 0.9772780574959729, 0.9572397877410583, 0.01119578699112349, 0.016793680486685236, 0.01119578699112349, 0.29780679282106004, 0.037225849102632505, 0.6328394347447526, 0.9903100381791149, 0.027676169765264907, 0.04843329708921359, 0.6849852016903064, 0.013838084882632454, 0.15913797615027322, 0.06919042441316227, 0.9862347174488022, 0.9323098653470631, 0.9819678257680006, 0.3040817633454501, 0.6689798793599903, 0.07270553418953436, 0.2214213995772183, 0.29082213675813745, 0.3205653098356742, 0.04957195512922797, 0.042962361111997575, 0.9894476257308213, 0.9161405693296556, 0.9689401524556127, 0.930668208394105, 0.9511754458872941, 0.04779776109986403, 0.9529958421765202, 0.5420080108438261, 0.29859123950677846, 0.061665582072052076, 0.006491113902321271, 0.061665582072052076, 0.025964455609285085, 0.17684165448046665, 0.6227901744746869, 0.12302028137771592, 0.0691989082749652, 0.8185853492928842, 0.12967688701669453, 0.04052402719271704, 0.9806544359265529, 0.9016989695647443, 0.9769069198936181, 0.06247076823785517, 0.226456534862225, 0.17960345868383362, 0.1952211507432974, 0.14055922853517414, 0.1952211507432974, 0.8319014323738639, 0.0831901432373864, 0.17816472393922148, 0.7720471370699598, 0.2845867103009848, 0.15522911470962808, 0.5691734206019696, 0.20312201383341955, 0.13541467588894637, 0.04062440276668391, 0.18958054624452492, 0.39270256007794446, 0.027082935177789272, 0.9564836801871365, 0.015552580165644495, 0.0038881450414111236, 0.007776290082822247, 0.015552580165644495, 0.030562243058650712, 0.12224897223460285, 0.45843364587976065, 0.38202803823313386, 0.030255221936959273, 0.7979814785873008, 0.018909513710599544, 0.14749420694267645, 0.011345708226359727, 0.9854473661232613, 0.009954013799224861, 0.9956005672939809, 0.026738169770410766, 0.9358359419643767, 0.026738169770410766, 0.026738169770410766, 0.9881407934681056, 0.9620139529105105, 0.9742896762761908, 0.011328949724141753, 0.011328949724141753, 0.9938995913446761, 0.9820671358920948, 0.7746621379488028, 0.013402459134062333, 0.06701229567031167, 0.1420660668210607, 0.0026804918268124663, 0.018703210258705572, 0.5423930975024616, 0.19950090942619278, 0.012468806839137049, 0.049875227356548195, 0.17456329574791868, 0.3941587873944135, 0.060639813445294385, 0.1617061691874517, 0.030319906722647193, 0.3436256095233349, 0.010106635574215731, 0.8710244627951006, 0.043948407899486425, 0.922916565889215, 0.5996777787890814, 0.10150309235993796, 0.13512988369390513, 0.1064848392242294, 0.03487222805004003, 0.022417860889311452, 0.14293159146108014, 0.10445000914463548, 0.6157053170631144, 0.04947632012114312, 0.08246053353523854, 0.8857649342986751, 0.10065510617030399, 0.006710340411353599, 0.006710340411353599, 0.97365771349634, 0.031433541103676424, 0.08487056097992635, 0.11944745619397042, 0.6475309467357344, 0.01257341644147057, 0.10687403975249984, 0.9332962361650237, 0.9049250983730822, 0.978820158473842, 0.9231531083409565, 0.9161545060534679, 0.009354463049251131, 0.7545933526395913, 0.22762526753177753, 0.0062363086995007545, 0.987988555848546, 0.23466509996099288, 0.032853113994539, 0.20650528796567375, 0.4317837839282269, 0.065706227989078, 0.028159811995319146, 0.9840967549248538, 0.7534873199198983, 0.21528209140568522, 0.014266940191486019, 0.7062135394785579, 0.24253798325526232, 0.017833675239357524, 0.017833675239357524, 0.9303308833363086, 0.9399510996188897, 0.8118338867084298, 0.01964114242036524, 0.026188189893820317, 0.14403504441601175, 0.08736652786816025, 0.22715297245721666, 0.04659548152968547, 0.5183747320177509, 0.05241991672089615, 0.06406878710331752, 0.9677692583172437, 0.014888757820265289, 0.014888757820265289, 0.7827767353134051, 0.06801377637004309, 0.04699133640112069, 0.05317440698021551, 0.03462519524293103, 0.013602755274008619, 0.8673976680309007, 0.9717271239003752, 0.9619330342443146, 0.030537556642676655, 0.4268686502689757, 0.12745367282912545, 0.12947674700101633, 0.2043304913609789, 0.09508448607887136, 0.01618459337512704, 0.0556380932836875, 0.111276186567375, 0.8345713992553124, 0.30276971240117834, 0.6980523924804946, 0.40909648003776555, 0.21335653743596386, 0.1722511494895855, 0.08221077589275672, 0.0919977730228468, 0.033275790242306286, 0.8879163163164795, 0.09711584709711495, 0.9954411437942787, 0.15062438550199317, 0.4835835534537676, 0.06738459351404957, 0.20215378054214875, 0.003963799618473505, 0.0911673912248906, 0.023101868745364552, 0.16171308121755187, 0.08085654060877594, 0.6776548165306936, 0.015401245830243035, 0.04235342603316835, 0.19020412527888397, 0.6551475426272669, 0.1479365418835764, 0.025464120293029975, 0.9506604909397858, 0.008488040097676659, 0.008488040097676659, 0.06783429559734612, 0.794630319854626, 0.0969061365676373, 0.029071840970291193, 0.3260859461932915, 0.5327852344906785, 0.05345671249070353, 0.06949372623791458, 0.017818904163567843, 0.008515775417978516, 0.7664197876180664, 0.11922085585169921, 0.07238409105281739, 0.029805213962924803, 0.004257887708989258, 0.8272106014245975, 0.009294501139602219, 0.1580065193732377, 0.9823830312457403, 0.9915843555866071, 0.9686440641736718, 0.9713387921379185, 0.5141271189376289, 0.2232064077338974, 0.12288892111192105, 0.03761905748324114, 0.09279367512532814, 0.012539685827747046, 0.9922038726240426, 0.9938995823275574, 0.9696282483131111, 0.9735173885301076, 0.503621470297387, 0.1272889430421967, 0.2960851501198924, 0.01660290561419957, 0.052575867778298646, 0.005534301871399857, 0.018100959952971535, 0.9774518374604629, 0.9910651815094351, 0.007992461141205122, 0.9948486296472155, 0.9533719906770164, 0.9016904864067313, 0.09610539775731466, 0.7614504591541085, 0.05914178323527056, 0.05174906033086174, 0.02957089161763528, 0.9167642240602024, 0.9897186309897332, 0.968943136412297, 0.9132405320309774, 0.045990530390049224, 0.03285037885003516, 0.010802722955711263, 0.07561906068997884, 0.4753198100512956, 0.03240816886713379, 0.3997007493613167, 0.9531626757538929, 0.9971340875889406, 0.9530788443433855, 0.0468727300496747, 0.9825126680048227, 0.07730694009490757, 0.030168561988256612, 0.8258643844285247, 0.009427675621330192, 0.056566053727981146, 0.9876367482180177, 0.9122122951368099, 0.02042266332395843, 0.03063399498593765, 0.03744154942725712, 0.9742427060159284, 0.991194056416128, 0.20299239166465588, 0.4656884279365635, 0.14030356482704157, 0.08059992021978983, 0.06865919129833949, 0.04179255122507621, 0.9809436124581521, 0.8749604966441317, 0.0894845962476953, 0.029828198749231764, 0.9611910924180986, 0.08195320810871354, 0.06634307323086333, 0.7453839404173469, 0.04683040463355059, 0.062440539511400786, 0.041568046701512484, 0.20784023350756242, 0.45085342960871233, 0.19185252323774993, 0.04476558875547498, 0.06395084107924998, 0.06726777472228364, 0.8341204065563171, 0.04036066483337018, 0.05381421977782691, 0.9437737120817054, 0.019260688001667456, 0.019260688001667456, 0.9745903755580012, 0.06981429791756437, 0.034907148958782185, 0.7097786954952378, 0.0930857305567525, 0.0930857305567525, 0.015459553389561795, 0.06183821355824718, 0.8348158830363369, 0.03091910677912359, 0.04637866016868539, 0.9018869954741744, 0.9109049062604146, 0.009390772229488812, 0.014086158344233216, 0.061040019491677276, 0.9696256062852581, 0.9012665039857017, 0.06932819261428474, 0.012238759877509726, 0.29373023706023343, 0.048955039510038906, 0.5140279148554086, 0.134626358652607, 0.9606155741752898, 0.006820438631128324, 0.07275134539870212, 0.49789202007236766, 0.3569362883623823, 0.03182871361193218, 0.03637567269935106, 0.8931148923948105, 0.007568770274532292, 0.015137540549064583, 0.07568770274532292, 0.024430559435685676, 0.9283612585560557, 0.024430559435685676, 0.024430559435685676, 0.09721004093262622, 0.22844359619167165, 0.4617476944299746, 0.10693104502588885, 0.10693104502588885, 0.008336944767013013, 0.8545368386188338, 0.03334777906805205, 0.014172806103922122, 0.03251408459135075, 0.05752491889238979, 0.9643043871067051, 0.025887366096824297, 0.05840864454811122, 0.13628683727892618, 0.03893909636540748, 0.7787819273081495, 0.033140611000142435, 0.06628122200028487, 0.7290934420031336, 0.09942183300042731, 0.06628122200028487, 0.06837575768666203, 0.8205090922399444, 0.06837575768666203, 0.9731847378785313, 0.9533684193243428, 0.0895294935723345, 0.04476474678616725, 0.022382373393083625, 0.15667661375158537, 0.6714712017925087, 0.022382373393083625, 0.9809310288195561, 0.9728188877196194, 0.987396301620563, 0.03260128943831861, 0.6194244993280535, 0.09780386831495583, 0.03260128943831861, 0.03260128943831861, 0.17930709191075234, 0.36936632642565204, 0.2069725104971326, 0.11781512135990625, 0.23881443518899917, 0.04139450209942652, 0.025473539753493247, 0.9115538218521396, 0.014355178296884088, 0.02153276744532613, 0.050243124039094304, 0.8314471576491818, 0.06221713424585714, 0.0848415466988961, 0.00565610311325974, 0.01696830933977922, 0.034505519445956104, 0.8798907458718805, 0.06901103889191221, 0.1499184205257095, 0.08072530335999742, 0.3574977720228457, 0.10955576884571078, 0.2133454445942789, 0.08072530335999742, 0.9882357815316206, 0.1115007121053072, 0.8548387928073552, 0.2386915452476133, 0.24146702833188788, 0.39134311488271484, 0.09159094178106092, 0.03330579701129488, 0.005550966168549147, 0.24685069471703877, 0.5196856730885027, 0.14940963101294452, 0.029232319111228276, 0.009744106370409426, 0.042224460938440844, 0.6904959170252208, 0.058516603137730584, 0.25747305380601454, 0.9017093781973058, 0.9742399070729666, 0.9820678357854513, 0.59608246145491, 0.1273680473194252, 0.10019619722461448, 0.08151555028443212, 0.0713261064988781, 0.02377536883295937, 0.8634828390890954, 0.13116195024138158, 0.3992322196195722, 0.2419139472044248, 0.15731827241514743, 0.09646875195268474, 0.07569086691672187, 0.029682692908518382, 0.2640282443868114, 0.16801797370069815, 0.5520590564451511, 0.024002567671528308, 0.945101332625525, 0.014767208322273828, 0.029534416644547656, 0.9581694711734593, 0.9815024606198648, 0.9587392958605018, 0.7836186590696426, 0.029811579421127707, 0.09795233238370532, 0.046846767661772114, 0.03832917354144991, 0.004258797060161101, 0.9812426949645723, 0.011822201144151473, 0.9160406172351463, 0.9619538580835625, 0.8710224529417755, 0.9579684243294079, 0.16314859398085604, 0.15227202104879897, 0.256093853582071, 0.21950901735606085, 0.11964230225262776, 0.08899014217137602, 0.08285454587657039, 0.04971272752594223, 0.828545458765704, 0.033141818350628155, 0.05833586046192252, 0.23698943312656023, 0.1458396511548063, 0.33543119765605445, 0.09479577325062409, 0.13125568603932566, 0.10740602079255579, 0.1318164800635912, 0.600497298067471, 0.11717020450096996, 0.004882091854207082, 0.03417464297944957, 0.18247871120479833, 0.7907410818874595, 0.8881107831512167, 0.024900302331342525, 0.0332004031084567, 0.04980060466268505, 0.023225411465027768, 0.9522418700661385, 0.9161436428375688, 0.18806605225910203, 0.05531354478208883, 0.5337757071471573, 0.13828386195522208, 0.0857359944122377, 0.034627723701009194, 0.7040970485871869, 0.21930891677305822, 0.04039901098451072, 0.9509977664360161, 0.037539385517211164, 0.9543047973999355, 0.480538519859373, 0.08317012843719918, 0.05544675229146612, 0.01848225076382204, 0.02772337614573306, 0.3326805137487967, 0.955051234840715, 0.04750164839811245, 0.9025313195641367, 0.9018899586783571, 0.9306404677576524, 0.9855756631941543, 0.13791710683470546, 0.3051415988717858, 0.2379070092898669, 0.23101115394813163, 0.062062698075617456, 0.02758342136694109, 0.9306605222814143, 0.47859185964561135, 0.14963724810625056, 0.17746235622518147, 0.06739859522141038, 0.10944542526779484, 0.01731340060733478, 0.9388881434157278, 0.9696127287476919, 0.9509773839420244, 0.1692293351085657, 0.507688005325697, 0.03384586702171314, 0.21247683185853247, 0.039486844858665326, 0.035726192967363866], \"Term\": [\"acadalaskaedu\", \"adams\", \"adams\", \"adams\", \"adams\", \"adaptor\", \"aerospace\", \"aerospace\", \"alaska\", \"alaska\", \"alaska\", \"alaska\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"allan\", \"allan\", \"altatheism\", \"animation\", \"animation\", \"animation\", \"april\", \"april\", \"april\", \"april\", \"archie\", \"arff\", \"argument\", \"argument\", \"argumentum\", \"ariane\", \"art\", \"art\", \"art\", \"art\", \"article\", \"article\", \"article\", \"article\", \"article\", \"article\", \"aspect\", \"aspect\", \"aspect\", \"assassin\", \"astronaut\", \"atheism\", \"atheist\", \"atheist\", \"auroraapr\", \"autotrace\", \"batty\", \"beacon\", \"beauchaine\", \"belief\", \"benedikt\", \"bible\", \"bible\", \"billboard\", \"billboard\", \"billboard\", \"billion\", \"billion\", \"billion\", \"billion\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bo\", \"boesel\", \"bombing\", \"book\", \"book\", \"book\", \"book\", \"book\", \"book\", \"brand\", \"brand\", \"burster\", \"bursters\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"car\", \"car\", \"car\", \"car\", \"car\", \"card\", \"card\", \"card\", \"card\", \"card\", \"card\", \"cassette\", \"cellular\", \"center\", \"center\", \"center\", \"center\", \"center\", \"christian\", \"christian\", \"christianity\", \"civilian\", \"civilian\", \"civilian\", \"claim\", \"claim\", \"claim\", \"claim\", \"claim\", \"claim\", \"claudio\", \"client\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"color\", \"color\", \"color\", \"comet\", \"comet\", \"comet\", \"commercial\", \"commercial\", \"commercial\", \"commercial\", \"commercial\", \"compass\", \"compass\", \"compass_op\", \"computer\", \"computer\", \"computer\", \"computer\", \"computer\", \"computer\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"convert\", \"convert\", \"convert\", \"convert\", \"convert\", \"coplanar\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"coverage\", \"cview\", \"data\", \"data\", \"data\", \"data\", \"data\", \"david\", \"david\", \"david\", \"david\", \"david\", \"david\", \"dcx\", \"deck\", \"deck\", \"deck\", \"den\", \"design\", \"design\", \"design\", \"design\", \"design\", \"design\", \"detach\", \"detach\", \"developable\", \"development\", \"development\", \"development\", \"development\", \"development\", \"dewey\", \"diablouucpcboesel\", \"digitize\", \"directory\", \"disk\", \"disk\", \"disk\", \"disk\", \"display\", \"display\", \"display\", \"display\", \"display\", \"do\", \"do\", \"do\", \"do\", \"do\", \"do\", \"dong\", \"dos\", \"dos\", \"dos\", \"dos\", \"dosmpc\", \"drive\", \"drive\", \"drive\", \"drive\", \"drive\", \"drive\", \"earth\", \"earth\", \"earth\", \"earth\", \"earth\", \"earth\", \"een\", \"egalon\", \"email\", \"email\", \"email\", \"email\", \"email\", \"email\", \"enviroleague\", \"enzo\", \"evidence\", \"evidence\", \"excellent\", \"excellent\", \"excellent\", \"excellent\", \"excellent\", \"exist\", \"exist\", \"exist\", \"exist\", \"exist\", \"existence\", \"existence\", \"existence\", \"exploration\", \"exploration\", \"exploration\", \"face\", \"face\", \"face\", \"face\", \"face\", \"face\", \"fairbank\", \"faith\", \"false\", \"farley\", \"fast\", \"fast\", \"fast\", \"fast\", \"fast\", \"fast\", \"fermi\", \"file\", \"file\", \"file\", \"file\", \"file\", \"file\", \"flight\", \"flight\", \"flight\", \"flight\", \"flight\", \"format\", \"format\", \"format\", \"format\", \"forsale\", \"forsale\", \"fps\", \"ftp\", \"ftp\", \"ftp\", \"ftp\", \"ftp\", \"fund\", \"fund\", \"fund\", \"fund\", \"funding\", \"funding\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"gamma\", \"gamma\", \"gamma\", \"gamma\", \"geoffrey\", \"geoffrey\", \"gif\", \"gif\", \"gif\", \"god\", \"god\", \"god\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"graeme\", \"grafsys\", \"grafsys\", \"graphic\", \"graphic\", \"graphic\", \"graphics\", \"graphics\", \"graphics\", \"graphics\", \"gre\", \"gregg\", \"griffin\", \"group\", \"group\", \"group\", \"group\", \"group\", \"gulf\", \"hard\", \"hard\", \"hard\", \"hard\", \"hard\", \"hard\", \"have\", \"have\", \"have\", \"have\", \"have\", \"have\", \"henry\", \"henry\", \"henry\", \"henry\", \"hideous\", \"higgins\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"hijaak\", \"hiram\", \"hobgoblin\", \"hst\", \"hst\", \"hst\", \"hst\", \"hst\", \"hulk\", \"hulk\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"hussein\", \"hussein\", \"ide\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"improper\", \"include\", \"include\", \"include\", \"include\", \"include\", \"include\", \"inflatable\", \"inflatable\", \"input_image\", \"int\", \"int\", \"interested\", \"interested\", \"interested\", \"interested\", \"interested\", \"interested\", \"invade\", \"invade\", \"iraqi\", \"iraqis\", \"islam\", \"islamic\", \"item\", \"item\", \"item\", \"item\", \"item\", \"item\", \"jacked\", \"jesus\", \"jesus\", \"jfif\", \"jockey\", \"jpeg\", \"keith\", \"keith\", \"keith\", \"keown\", \"keyboard\", \"keyboard\", \"keyboard\", \"kill\", \"kill\", \"kill\", \"kill\", \"knoxs\", \"kou\", \"kuwait\", \"kuwait\", \"laptop\", \"larson\", \"launch\", \"launch\", \"launch\", \"launch\", \"launcher\", \"law\", \"law\", \"law\", \"law\", \"lens\", \"lens\", \"lens\", \"liar\", \"library\", \"library\", \"library\", \"library\", \"library\", \"library\", \"liefeld\", \"liguori\", \"linux\", \"liquid\", \"liquid\", \"list\", \"list\", \"list\", \"list\", \"list\", \"list\", \"livesey\", \"lps\", \"ltm\", \"lucas\", \"lunar\", \"lunar\", \"lung\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"manual\", \"manual\", \"manual\", \"manual\", \"mars\", \"mars\", \"mars\", \"martian\", \"mayans\", \"mcdonnell\", \"michael\", \"michael\", \"michael\", \"michael\", \"michael\", \"michael\", \"milelong\", \"milelong\", \"miner\", \"miner\", \"mining\", \"mining\", \"mining\", \"miss\", \"miss\", \"miss\", \"miss\", \"miss\", \"miss\", \"mission\", \"mission\", \"mission\", \"mission\", \"mission\", \"modem\", \"modem\", \"modem\", \"modem\", \"moon\", \"moon\", \"moon\", \"moon\", \"moon\", \"moral\", \"moral\", \"morality\", \"motherboard\", \"motherboard\", \"motherboard\", \"motherboard\", \"motto\", \"mpc\", \"murder\", \"murder\", \"murder\", \"muslim\", \"muslims\", \"nasa\", \"nasa\", \"nasa\", \"nasa\", \"nasa\", \"national\", \"national\", \"national\", \"national\", \"national\", \"national\", \"newsgroup\", \"newsgroup\", \"newsgroup\", \"newsgroup\", \"newsgroup\", \"newsgroup\", \"nikon\", \"norton\", \"norton\", \"not\", \"not\", \"not\", \"not\", \"not\", \"not\", \"object\", \"object\", \"object\", \"object\", \"object\", \"objective\", \"objective\", \"objective\", \"objective\", \"obo\", \"offer\", \"offer\", \"offer\", \"offer\", \"offer\", \"offer\", \"oliveira\", \"olympus\", \"op_col\", \"op_row\", \"op_rowscol\", \"orbit\", \"orbit\", \"orbit\", \"orbit\", \"orbiter\", \"original\", \"original\", \"original\", \"original\", \"original\", \"original\", \"otis\", \"ozone\", \"ozone\", \"package\", \"package\", \"package\", \"package\", \"package\", \"packaging\", \"palette\", \"pat\", \"pat\", \"pat\", \"pat\", \"pay\", \"pay\", \"pay\", \"pay\", \"pay\", \"pay\", \"payload\", \"payload\", \"payload\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"pexlib\", \"physicist\", \"pixel\", \"pixel\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"pollution\", \"pollution\", \"pollution\", \"polygon\", \"polygon\", \"post\", \"post\", \"post\", \"post\", \"post\", \"post\", \"postscript\", \"postscript\", \"pov\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"price\", \"price\", \"price\", \"price\", \"price\", \"price\", \"printer\", \"printer\", \"printer\", \"probe\", \"probe\", \"probe\", \"probe\", \"processing\", \"processing\", \"processing\", \"processing\", \"program\", \"program\", \"program\", \"program\", \"program\", \"project\", \"project\", \"project\", \"project\", \"project\", \"project\", \"propulsion\", \"propulsion\", \"propulsion\", \"punisher\", \"punishment\", \"px\", \"pz\", \"question\", \"question\", \"question\", \"question\", \"question\", \"question\", \"quicktime\", \"quran\", \"raster\", \"rayshade\", \"read\", \"read\", \"read\", \"read\", \"read\", \"read\", \"redesign\", \"redesign\", \"religion\", \"religion\", \"religious\", \"renderer\", \"repo\", \"report\", \"report\", \"report\", \"report\", \"report\", \"retail\", \"rgb\", \"rimsat\", \"rocket\", \"rocket\", \"rocket\", \"routine\", \"routine\", \"routine\", \"routine\", \"routine\", \"rowcol\", \"rushdie\", \"russian\", \"russian\", \"sabretooth\", \"sale\", \"sale\", \"sale\", \"sale\", \"sale\", \"satan\", \"satellite\", \"satellite\", \"satellite\", \"satellite\", \"scene\", \"schneider\", \"science\", \"science\", \"science\", \"science\", \"science\", \"science\", \"scodal\", \"screen\", \"screen\", \"screen\", \"sdio\", \"sell\", \"sell\", \"sell\", \"sell\", \"sell\", \"send\", \"send\", \"send\", \"send\", \"send\", \"send\", \"server\", \"server\", \"server\", \"server\", \"shareware\", \"shareware\", \"shareware\", \"sherzer\", \"ship\", \"ship\", \"ship\", \"ship\", \"ship\", \"shipping\", \"shipping\", \"shipping\", \"shipping\", \"shipping\", \"shoemakerlevy\", \"shuttle\", \"shuttle\", \"shuttle\", \"shuttle\", \"simtel\", \"sirtf\", \"sirtf\", \"sky\", \"sky\", \"sky\", \"sky\", \"sky\", \"slot\", \"software\", \"software\", \"software\", \"software\", \"software\", \"software\", \"solar\", \"solar\", \"solar\", \"solar\", \"sony\", \"sony\", \"sony\", \"sony\", \"source\", \"source\", \"source\", \"source\", \"source\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"spacecraft\", \"spacecraft\", \"speaker\", \"speaker\", \"speaker\", \"speaker\", \"sphere\", \"sphere\", \"sphere\", \"sphere\", \"sphere\", \"spherical\", \"spherical\", \"spherical\", \"sphinx\", \"spline\", \"split\", \"split\", \"split\", \"split\", \"split\", \"split\", \"ssf\", \"ssrt\", \"ssto\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"statement\", \"statement\", \"statement\", \"statement\", \"station\", \"station\", \"station\", \"station\", \"station\", \"stereo\", \"stereo\", \"stereo\", \"stuff\", \"stuff\", \"stuff\", \"stuff\", \"stuff\", \"stuff\", \"sunrise\", \"sunset\", \"sunset\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"technology\", \"technology\", \"technology\", \"technology\", \"technology\", \"technology\", \"telescope\", \"telescope\", \"telescope\", \"televison\", \"temp\", \"theist\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"tiff\", \"tiff\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"times\", \"times\", \"times\", \"times\", \"titan\", \"titan\", \"titan\", \"tnde\", \"toner\", \"tracer\", \"true\", \"true\", \"true\", \"true\", \"true\", \"true\", \"truth\", \"truth\", \"typewriter\", \"uccxkvb\", \"uhf\", \"unify\", \"university\", \"university\", \"university\", \"university\", \"university\", \"university\", \"upgrade\", \"upgrade\", \"upgrade\", \"upgrade\", \"usa\", \"usa\", \"usa\", \"usa\", \"usa\", \"usa\", \"user\", \"user\", \"user\", \"user\", \"user\", \"user\", \"usgs\", \"usgs\", \"vehicle\", \"vehicle\", \"vehicle\", \"vehicle\", \"venture\", \"venture\", \"verdict\", \"version\", \"version\", \"version\", \"version\", \"version\", \"video\", \"video\", \"video\", \"video\", \"viewer\", \"viewer\", \"vinge\", \"war\", \"war\", \"war\", \"war\", \"war\", \"war\", \"wate\", \"watt\", \"watt\", \"wetstein\", \"wn\", \"wolverine\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"wrench\", \"write\", \"write\", \"write\", \"write\", \"write\", \"write\", \"ww\", \"xforce\", \"xxxx\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 5, 1, 3, 4, 6]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1819221110106628563837773642\", ldavis_el1819221110106628563837773642_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1819221110106628563837773642\", ldavis_el1819221110106628563837773642_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1819221110106628563837773642\", ldavis_el1819221110106628563837773642_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "1      0.247576  0.034685       1        1  26.625204\n",
       "4     -0.009352 -0.146329       2        1  24.914814\n",
       "0     -0.072537  0.131402       3        1  20.035298\n",
       "2     -0.073487  0.080015       4        1  13.469318\n",
       "3     -0.013583 -0.036717       5        1   8.555245\n",
       "5     -0.078616 -0.063057       6        1   6.400122, topic_info=         Term         Freq        Total Category  logprob  loglift\n",
       "9493      god   741.000000   741.000000  Default  30.0000  30.0000\n",
       "22125   space  1199.000000  1199.000000  Default  29.0000  29.0000\n",
       "11076   image   818.000000   818.000000  Default  28.0000  28.0000\n",
       "20640    sale   530.000000   530.000000  Default  27.0000  27.0000\n",
       "8316     file   592.000000   592.000000  Default  26.0000  26.0000\n",
       "...       ...          ...          ...      ...      ...      ...\n",
       "18225   power    22.970390   252.283187   Topic6  -6.4707   0.3525\n",
       "22527    star    21.825067   122.694534   Topic6  -6.5219   1.0222\n",
       "17246     pat    21.731525   152.740606   Topic6  -6.5262   0.7989\n",
       "22096  source    21.759459   205.740064   Topic6  -6.5249   0.5023\n",
       "3614   center    21.569234   277.958560   Topic6  -6.5337   0.1926\n",
       "\n",
       "[454 rows x 6 columns], token_table=       Topic      Freq           Term\n",
       "term                                 \n",
       "102        6  0.957210  acadalaskaedu\n",
       "255        1  0.050635          adams\n",
       "255        2  0.253173          adams\n",
       "255        5  0.151904          adams\n",
       "255        6  0.556980          adams\n",
       "...      ...       ...            ...\n",
       "26857      2  0.507688           year\n",
       "26857      3  0.033846           year\n",
       "26857      4  0.212477           year\n",
       "26857      5  0.039487           year\n",
       "26857      6  0.035726           year\n",
       "\n",
       "[1032 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 5, 1, 3, 4, 6])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.sklearn.prepare(lda, dt_matrix, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Python37\\lib\\site-packages\\scipy\\sparse\\sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[([(0.035153322, 'space'),\n",
       "   (0.013273308, 'launch'),\n",
       "   (0.012037246, 'nasa'),\n",
       "   (0.011985789, 'orbit'),\n",
       "   (0.01145318, 'not'),\n",
       "   (0.011386162, 'article'),\n",
       "   (0.009257541, 'moon'),\n",
       "   (0.008314573, 'work'),\n",
       "   (0.008229328, 'cost'),\n",
       "   (0.007979864, 'do'),\n",
       "   (0.00795668, 'satellite'),\n",
       "   (0.0075671254, 'year'),\n",
       "   (0.007200616, 'earth'),\n",
       "   (0.0065132966, 'high'),\n",
       "   (0.006312601, 'station'),\n",
       "   (0.006093175, 'mission'),\n",
       "   (0.0058015073, 'shuttle'),\n",
       "   (0.0057993117, 'lunar'),\n",
       "   (0.005447027, 'time'),\n",
       "   (0.005143147, 'flight')],\n",
       "  -1.6514235853055401),\n",
       " ([(0.021958634, 'not'),\n",
       "   (0.021418056, 'god'),\n",
       "   (0.017552536, 'do'),\n",
       "   (0.014741828, 'people'),\n",
       "   (0.011937079, 'argument'),\n",
       "   (0.0113763, 'atheist'),\n",
       "   (0.009907505, 'article'),\n",
       "   (0.007874088, 'thing'),\n",
       "   (0.0072623566, 'religion'),\n",
       "   (0.007114652, 'true'),\n",
       "   (0.0068466114, 'time'),\n",
       "   (0.0061029624, 'post'),\n",
       "   (0.006034848, 'exist'),\n",
       "   (0.005759047, 'bible'),\n",
       "   (0.005688219, 'atheism'),\n",
       "   (0.0054405476, 'islam'),\n",
       "   (0.005419698, 'good'),\n",
       "   (0.0052859876, 'evidence'),\n",
       "   (0.0051090163, 'claim'),\n",
       "   (0.004916048, 'conclusion')],\n",
       "  -1.7960968824629568),\n",
       " ([(0.024828963, 'file'),\n",
       "   (0.017290121, 'bit'),\n",
       "   (0.01705557, 'image'),\n",
       "   (0.013865712, 'program'),\n",
       "   (0.011947334, 'do'),\n",
       "   (0.011289296, 'color'),\n",
       "   (0.011094179, 'sale'),\n",
       "   (0.010789725, 'not'),\n",
       "   (0.010538311, 'include'),\n",
       "   (0.01050532, 'disk'),\n",
       "   (0.01032911, 'display'),\n",
       "   (0.009529876, 'university'),\n",
       "   (0.009067331, 'version'),\n",
       "   (0.007891424, 'software'),\n",
       "   (0.0074076895, 'card'),\n",
       "   (0.0073007257, 'work'),\n",
       "   (0.0069696996, 'screen'),\n",
       "   (0.00682257, 'read'),\n",
       "   (0.0067344815, 'problem'),\n",
       "   (0.006446676, 'price')],\n",
       "  -1.8344942662431207),\n",
       " ([(0.018752422, 'appear'),\n",
       "   (0.0147214895, 'art'),\n",
       "   (0.014609673, 'university'),\n",
       "   (0.011805555, 'sale'),\n",
       "   (0.009433763, 'cover'),\n",
       "   (0.00841883, 'black'),\n",
       "   (0.008386672, 'book'),\n",
       "   (0.008076538, 'email'),\n",
       "   (0.007668017, 'david'),\n",
       "   (0.007620243, 'power'),\n",
       "   (0.0076059373, 'good'),\n",
       "   (0.0075343605, 'usa'),\n",
       "   (0.0074041034, 'offer'),\n",
       "   (0.006292545, 'not'),\n",
       "   (0.006135928, 'center'),\n",
       "   (0.006060526, 'work'),\n",
       "   (0.0058425604, 'mark'),\n",
       "   (0.00581007, 'do'),\n",
       "   (0.0057745026, 'pat'),\n",
       "   (0.0055312742, 'man')],\n",
       "  -1.8513066231693616),\n",
       " ([(0.01181374, 'point'),\n",
       "   (0.0115439035, 'list'),\n",
       "   (0.010909371, 'image'),\n",
       "   (0.010702863, 'email'),\n",
       "   (0.010426565, 'computer'),\n",
       "   (0.010383581, 'university'),\n",
       "   (0.010307913, 'post'),\n",
       "   (0.008853123, 'software'),\n",
       "   (0.008240417, 'model'),\n",
       "   (0.008173641, 'graphic'),\n",
       "   (0.007786352, 'fax'),\n",
       "   (0.0075877397, 'ftp'),\n",
       "   (0.007033196, 'datum'),\n",
       "   (0.0068476135, 'address'),\n",
       "   (0.0067607528, 'search'),\n",
       "   (0.006721038, 'edge'),\n",
       "   (0.005832151, 'space'),\n",
       "   (0.0058233757, 'article'),\n",
       "   (0.0057746475, 'data'),\n",
       "   (0.0056173103, 'send')],\n",
       "  -1.9851818967327362),\n",
       " ([(0.82642895, '_'),\n",
       "   (0.0033900042, 'ron'),\n",
       "   (0.003369124, 'jet'),\n",
       "   (0.0033199033, 'baalke'),\n",
       "   (0.002847608, 'university'),\n",
       "   (0.0027996816, 'magellan'),\n",
       "   (0.0027105042, 'propulsion'),\n",
       "   (0.0025921138, 'file'),\n",
       "   (0.002306802, 'jeff'),\n",
       "   (0.0022297103, 'animation'),\n",
       "   (0.002048159, 'unix'),\n",
       "   (0.001992135, 'pasadena'),\n",
       "   (0.0018076943, 'brain'),\n",
       "   (0.0017730996, 'data'),\n",
       "   (0.0017160632, 'msdos'),\n",
       "   (0.0016577619, 'image'),\n",
       "   (0.0015196033, 'kelvinjplnasagov'),\n",
       "   (0.0014575757, 'dept'),\n",
       "   (0.0014198184, 'keywords'),\n",
       "   (0.0014097084, 'lab')],\n",
       "  -3.137414444825032)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim import models\n",
    "\n",
    "split_corpus = [doc.split() for doc in corpus.data]\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(split_corpus)\n",
    "\n",
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.5)\n",
    "\n",
    "c = [dictionary.doc2bow(doc) for doc in split_corpus]\n",
    "# tfidf = models.TfidfModel(c)\n",
    "# c = tfidf[c]\n",
    "\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 6\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "model = LdaModel(\n",
    "    corpus=c,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")\n",
    "\n",
    "model.top_topics(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1819221110738981843368747820\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1819221110738981843368747820_data = {\"mdsDat\": {\"x\": [0.11153959191260508, 0.10745841440241778, 0.06628728419469035, 0.07416647768093998, 0.08439950090171323, -0.44385126909236633], \"y\": [-0.16324927185440913, -0.10361598547887245, 0.1947605082903024, 0.10464373923424511, -0.01092380449492971, -0.02161518569633619], \"topics\": [1, 2, 3, 4, 5, 6], \"cluster\": [1, 1, 1, 1, 1, 1], \"Freq\": [27.300962448120117, 20.268749237060547, 16.997085571289062, 15.871935844421387, 11.786956787109375, 7.774313449859619]}, \"tinfo\": {\"Term\": [\"_\", \"god\", \"space\", \"file\", \"bit\", \"appear\", \"image\", \"argument\", \"launch\", \"sale\", \"atheist\", \"orbit\", \"art\", \"nasa\", \"color\", \"email\", \"disk\", \"program\", \"display\", \"religion\", \"moon\", \"software\", \"graphic\", \"list\", \"people\", \"satellite\", \"point\", \"cover\", \"book\", \"offer\", \"god\", \"argument\", \"atheist\", \"religion\", \"bible\", \"atheism\", \"islam\", \"moral\", \"morality\", \"islamic\", \"belief\", \"law\", \"religious\", \"jesus\", \"kill\", \"false\", \"christian\", \"rushdie\", \"argue\", \"muslim\", \"innocent\", \"christianity\", \"existence\", \"truth\", \"commit\", \"believe\", \"imply\", \"schneider\", \"gregg\", \"muslims\", \"conclusion\", \"evidence\", \"valid\", \"people\", \"true\", \"claim\", \"keith\", \"exist\", \"fact\", \"not\", \"human\", \"do\", \"thing\", \"event\", \"article\", \"time\", \"life\", \"post\", \"good\", \"question\", \"bad\", \"point\", \"orbit\", \"henry\", \"rocket\", \"mission\", \"spencer\", \"toronto\", \"zoology\", \"fuel\", \"vehicle\", \"atmosphere\", \"russian\", \"mars\", \"redesign\", \"probe\", \"payload\", \"utzoohenry\", \"billboard\", \"kipling\", \"jupiter\", \"gas\", \"japanese\", \"titan\", \"saturn\", \"pad\", \"launch\", \"acadalaskaedu\", \"orbiter\", \"fairbank\", \"contract\", \"altitude\", \"astronaut\", \"budget\", \"nasa\", \"dcx\", \"moon\", \"satellite\", \"space\", \"shuttle\", \"landing\", \"flight\", \"station\", \"gun\", \"spacecraft\", \"cost\", \"solar\", \"earth\", \"billion\", \"orbital\", \"high\", \"project\", \"commercial\", \"year\", \"article\", \"lunar\", \"work\", \"not\", \"large\", \"do\", \"time\", \"program\", \"university\", \"long\", \"color\", \"jpeg\", \"cview\", \"driver\", \"floppy\", \"mb\", \"polygon\", \"compatible\", \"vesa\", \"meg\", \"windows\", \"port\", \"modem\", \"ram\", \"hp\", \"bug\", \"keyboard\", \"amiga\", \"svga\", \"microsoft\", \"processor\", \"rgb\", \"cpu\", \"baud\", \"printer\", \"ibm\", \"adapter\", \"vga\", \"pin\", \"window\", \"screen\", \"disk\", \"routine\", \"file\", \"bit\", \"display\", \"video\", \"dos\", \"manual\", \"memory\", \"card\", \"image\", \"mode\", \"drive\", \"program\", \"version\", \"sale\", \"include\", \"price\", \"software\", \"format\", \"do\", \"read\", \"problem\", \"university\", \"not\", \"offer\", \"work\", \"graphic\", \"mailing\", \"plot\", \"bbs\", \"park\", \"drawing\", \"scan\", \"removal\", \"virtual\", \"imaging\", \"telephone\", \"operator\", \"archive\", \"calculation\", \"search\", \"link\", \"edge\", \"sphere\", \"database\", \"tel\", \"request\", \"medical\", \"raytrace\", \"dec\", \"ftp\", \"curve\", \"circle\", \"aid\", \"scanner\", \"maryland\", \"fax\", \"lab\", \"anonymous\", \"list\", \"site\", \"model\", \"address\", \"datum\", \"application\", \"tool\", \"mail\", \"network\", \"faq\", \"point\", \"news\", \"graphic\", \"surface\", \"email\", \"computer\", \"software\", \"object\", \"image\", \"data\", \"post\", \"university\", \"code\", \"send\", \"number\", \"format\", \"user\", \"source\", \"include\", \"article\", \"space\", \"time\", \"galaxy\", \"mile\", \"wright\", \"edition\", \"speaker\", \"ball\", \"accessdigexnet\", \"davis\", \"scsi\", \"southern\", \"art\", \"genesis\", \"cassette\", \"sony\", \"gold\", \"deck\", \"poison\", \"florida\", \"boy\", \"foundation\", \"brown\", \"obo\", \"joe\", \"angeles\", \"berkeley\", \"alive\", \"pair\", \"appear\", \"channel\", \"van\", \"black\", \"city\", \"miller\", \"rob\", \"pat\", \"sign\", \"trade\", \"cover\", \"motion\", \"cable\", \"star\", \"david\", \"lee\", \"story\", \"sale\", \"origin\", \"usa\", \"book\", \"power\", \"offer\", \"america\", \"mark\", \"university\", \"condition\", \"green\", \"center\", \"sell\", \"email\", \"good\", \"state\", \"man\", \"ill\", \"pay\", \"price\", \"work\", \"send\", \"thing\", \"not\", \"do\", \"year\", \"_\", \"kelvinjplnasagov\", \"telos\", \"magellan\", \"jet\", \"baalke\", \"brain\", \"cod\", \"msdos\", \"propulsion\", \"vaxvms\", \"jeff\", \"cheer\", \"ron\", \"zealand\", \"vnews\", \"vaxvm\", \"newssoftware\", \"collect\", \"animation\", \"credit\", \"ontario\", \"pasadena\", \"purdue\", \"july\", \"storage\", \"totally\", \"buyer\", \"fine\", \"ignore\", \"jpl\", \"unix\", \"lab\", \"dept\", \"keywords\", \"data\", \"file\", \"university\", \"ftp\", \"gravity\", \"box\", \"image\", \"format\", \"science\"], \"Freq\": [9760.0, 889.0, 1349.0, 750.0, 516.0, 391.0, 744.0, 495.0, 416.0, 503.0, 472.0, 370.0, 275.0, 397.0, 292.0, 547.0, 306.0, 633.0, 312.0, 301.0, 318.0, 444.0, 359.0, 378.0, 813.0, 275.0, 550.0, 258.0, 333.0, 307.0, 888.2233276367188, 495.0398864746094, 471.7839660644531, 301.175537109375, 238.83212280273438, 235.89483642578125, 225.62371826171875, 176.90817260742188, 152.51580810546875, 147.13442993164062, 146.59103393554688, 144.85292053222656, 143.18374633789062, 137.60302734375, 130.76010131835938, 127.94905853271484, 170.63722229003906, 122.64114379882812, 115.92501831054688, 113.4068374633789, 104.04890441894531, 102.74069213867188, 99.40755462646484, 93.08477783203125, 91.12010955810547, 98.96466064453125, 84.27214050292969, 82.91585540771484, 77.65555572509766, 77.13729858398438, 203.872314453125, 219.2139892578125, 103.00141143798828, 611.35498046875, 295.05010986328125, 211.87486267089844, 182.00466918945312, 250.26980590820312, 169.62258911132812, 910.6415405273438, 200.8013458251953, 727.917236328125, 326.5445251464844, 156.47265625, 410.87188720703125, 283.93426513671875, 164.3894500732422, 253.09457397460938, 224.75906372070312, 195.85031127929688, 166.3358917236328, 175.47402954101562, 369.0266418457031, 154.03004455566406, 146.5326385498047, 187.600830078125, 134.81454467773438, 119.9155044555664, 107.36266326904297, 98.58924102783203, 109.6243896484375, 82.40072631835938, 78.51680755615234, 102.27510833740234, 73.46617126464844, 73.00920867919922, 65.35578918457031, 56.46308517456055, 53.74913024902344, 53.4337043762207, 62.49384307861328, 51.22051239013672, 51.18373107910156, 46.301578521728516, 43.110172271728516, 41.09257125854492, 408.66766357421875, 38.760345458984375, 37.87528610229492, 37.245609283447266, 38.18550491333008, 35.888004302978516, 55.5408821105957, 57.26520538330078, 370.6109313964844, 117.59489440917969, 285.0274963378906, 244.97567749023438, 1082.324462890625, 178.62075805664062, 82.735107421875, 158.3507080078125, 194.35665893554688, 132.63912963867188, 116.25723266601562, 253.3701629638672, 112.68453979492188, 221.69747924804688, 117.3314437866211, 102.59862518310547, 200.5358123779297, 149.9554901123047, 116.56785583496094, 232.9818115234375, 350.5649108886719, 178.55316162109375, 255.9947509765625, 352.6282958984375, 148.70655822753906, 245.6894989013672, 167.70677185058594, 157.55569458007812, 156.78506469726562, 132.07693481445312, 291.477783203125, 144.60662841796875, 142.07223510742188, 139.17098999023438, 113.47183990478516, 97.156005859375, 160.00401306152344, 82.5115966796875, 78.51211547851562, 78.5117416381836, 72.71273040771484, 69.7226791381836, 65.24017333984375, 65.09220886230469, 62.69847106933594, 59.59307861328125, 44.83185577392578, 58.73300552368164, 40.68040466308594, 29.827316284179688, 38.719825744628906, 23.764780044555664, 20.896453857421875, 18.17461585998535, 139.3153533935547, 148.064208984375, 22.47795867919922, 101.7735595703125, 29.488920211791992, 108.25102996826172, 179.95034790039062, 271.2363586425781, 72.089599609375, 641.057861328125, 446.4128112792969, 266.6867980957031, 154.17526245117188, 96.18020629882812, 116.5442123413086, 128.69363403320312, 191.2587890625, 440.35693359375, 120.98422241210938, 165.10801696777344, 357.9981689453125, 234.1090087890625, 286.4400939941406, 272.0881652832031, 166.44642639160156, 203.74830627441406, 162.49893188476562, 308.4676513671875, 176.15162658691406, 173.87725830078125, 246.05140686035156, 278.57940673828125, 150.43118286132812, 188.49710083007812, 156.74868774414062, 84.09577178955078, 58.0318489074707, 41.90996551513672, 39.9668083190918, 34.55097579956055, 31.739917755126953, 24.4954776763916, 69.63008117675781, 46.64585876464844, 19.38222312927246, 34.155967712402344, 93.17526245117188, 20.12462615966797, 163.00057983398438, 33.94199752807617, 162.04306030273438, 49.220149993896484, 58.584964752197266, 30.95353889465332, 93.19837188720703, 28.0102596282959, 16.92106056213379, 44.5416145324707, 182.9390869140625, 43.81755828857422, 35.274513244628906, 27.54134178161621, 22.242877960205078, 39.29098129272461, 187.72760009765625, 87.81969451904297, 71.01837158203125, 278.3215026855469, 128.64596557617188, 198.67501831054688, 165.0947723388672, 169.56912231445312, 95.1808853149414, 94.22836303710938, 120.43779754638672, 107.59305572509766, 119.50653076171875, 284.82720947265625, 130.8480224609375, 197.0650634765625, 106.67884826660156, 258.044189453125, 251.38267517089844, 213.44725036621094, 109.88214874267578, 263.0230407714844, 139.2257537841797, 248.52198791503906, 250.34632873535156, 115.73112487792969, 135.432373046875, 128.99501037597656, 128.48553466796875, 114.50592041015625, 109.68260192871094, 131.6077880859375, 140.40057373046875, 140.61215209960938, 115.06897735595703, 57.82266616821289, 45.674434661865234, 37.44440841674805, 57.36722946166992, 35.12972640991211, 36.02200698852539, 31.92690086364746, 28.118432998657227, 24.126821517944336, 23.20999526977539, 263.5831298828125, 16.63705825805664, 16.005197525024414, 29.282739639282227, 18.543685913085938, 16.015764236450195, 17.581653594970703, 33.73126220703125, 34.545047760009766, 22.454599380493164, 13.76330280303955, 36.72959518432617, 29.665510177612305, 20.551992416381836, 24.129905700683594, 32.509979248046875, 40.6688232421875, 335.75555419921875, 30.209774017333984, 37.23993682861328, 150.7362060546875, 80.1077880859375, 43.702598571777344, 80.46875762939453, 103.39044952392578, 51.95530319213867, 65.41498565673828, 168.90823364257812, 56.08959197998047, 59.69152069091797, 90.54789733886719, 137.2931671142578, 44.521244049072266, 67.905029296875, 211.37432861328125, 54.047271728515625, 134.90008544921875, 150.16041564941406, 136.4377899169922, 132.56788635253906, 59.39513397216797, 104.60900115966797, 261.5810852050781, 93.19158172607422, 63.320613861083984, 109.86164855957031, 92.18235778808594, 144.6075897216797, 136.18165588378906, 97.5889892578125, 99.03553009033203, 79.60179901123047, 73.06563568115234, 84.16722869873047, 108.5115966796875, 84.87171936035156, 95.5526123046875, 112.66581726074219, 104.02726745605469, 87.18988800048828, 9759.59375, 17.945537567138672, 13.23338794708252, 33.06243896484375, 39.78718566894531, 39.2059211730957, 21.347705841064453, 14.282645225524902, 20.265602111816406, 32.00931167602539, 8.14824390411377, 27.241846084594727, 6.418379783630371, 40.03376770019531, 10.859838485717773, 15.38499641418457, 8.933432579040527, 15.41016960144043, 7.457234859466553, 26.331443786621094, 6.192885875701904, 5.977673053741455, 23.525833129882812, 7.900452136993408, 5.343629837036133, 4.864322185516357, 5.04529333114624, 9.646769523620605, 15.52713394165039, 9.96241283416748, 14.999813079833984, 24.18743896484375, 16.647748947143555, 17.213031768798828, 16.767141342163086, 20.939165115356445, 30.611196517944336, 33.62841796875, 15.79344367980957, 11.200075149536133, 14.704185485839844, 19.57710075378418, 15.807696342468262, 14.882913589477539], \"Total\": [9760.0, 889.0, 1349.0, 750.0, 516.0, 391.0, 744.0, 495.0, 416.0, 503.0, 472.0, 370.0, 275.0, 397.0, 292.0, 547.0, 306.0, 633.0, 312.0, 301.0, 318.0, 444.0, 359.0, 378.0, 813.0, 275.0, 550.0, 258.0, 333.0, 307.0, 889.0426635742188, 495.85009765625, 472.5946044921875, 301.9857177734375, 239.6424560546875, 236.7050323486328, 226.433837890625, 177.7198944091797, 153.32693481445312, 147.94451904296875, 147.40133666992188, 145.67144775390625, 143.99391174316406, 138.41387939453125, 131.57281494140625, 128.7589569091797, 171.7331085205078, 123.45123291015625, 116.73516082763672, 114.21710968017578, 104.85919952392578, 103.55069732666016, 100.2179946899414, 93.8961410522461, 91.93852996826172, 99.8563232421875, 85.08235931396484, 83.7257308959961, 78.46601867675781, 77.9474868774414, 211.17811584472656, 235.8422393798828, 105.78791809082031, 813.7590942382812, 353.56536865234375, 243.71734619140625, 213.22543334960938, 321.59783935546875, 197.4250946044922, 1739.0836181640625, 253.6942901611328, 1453.985107421875, 589.5796508789062, 189.468505859375, 1111.058837890625, 713.7294921875, 218.5460968017578, 719.1013793945312, 551.2094116210938, 433.25958251953125, 248.54078674316406, 550.9127807617188, 370.8251953125, 154.80355834960938, 147.32386779785156, 188.6565399169922, 135.5878448486328, 120.74505615234375, 108.13511657714844, 99.36211395263672, 110.57658386230469, 83.17378234863281, 79.29087829589844, 103.32992553710938, 74.24213409423828, 73.82733154296875, 66.1315689086914, 57.23553466796875, 54.5218505859375, 54.20610809326172, 63.4084358215332, 51.99460983276367, 51.971954345703125, 47.07463073730469, 43.88616943359375, 41.866355895996094, 416.45086669921875, 39.53286361694336, 38.64874267578125, 38.01811599731445, 38.98353958129883, 36.66092300415039, 56.80508041381836, 58.931941986083984, 397.5513916015625, 125.60049438476562, 318.73724365234375, 275.3522644042969, 1349.0391845703125, 199.72410583496094, 88.00690460205078, 183.57623291015625, 235.1673583984375, 154.81045532226562, 136.0992431640625, 354.02069091796875, 134.56442260742188, 350.2301330566406, 148.91162109375, 124.28678894042969, 348.9151611328125, 228.3118133544922, 154.06280517578125, 516.3827514648438, 1111.058837890625, 336.29351806640625, 707.8134155273438, 1739.0836181640625, 288.7109375, 1453.985107421875, 713.7294921875, 633.807373046875, 1095.368896484375, 335.7200622558594, 292.2658996582031, 145.3958740234375, 142.8538360595703, 139.9537353515625, 114.2550048828125, 97.9392318725586, 161.4148712158203, 83.2944107055664, 79.29376983642578, 79.29357147216797, 73.49571990966797, 70.50602722167969, 66.0237808227539, 65.8748779296875, 63.483192443847656, 60.46091079711914, 45.61442947387695, 59.78620529174805, 41.462154388427734, 30.611480712890625, 39.98228073120117, 24.547208786010742, 21.67867088317871, 18.957996368408203, 145.86415100097656, 155.1248321533203, 23.573022842407227, 107.28067016601562, 31.214052200317383, 114.90906524658203, 192.27989196777344, 306.676513671875, 78.27407836914062, 750.24609375, 516.2776489257812, 312.7144775390625, 175.9674072265625, 106.48413848876953, 132.2194366455078, 149.05575561523438, 245.6983642578125, 744.0220947265625, 147.3524932861328, 222.1778106689453, 633.807373046875, 373.7543029785156, 503.916015625, 545.1498413085938, 269.6513366699219, 444.4364013671875, 307.2556457519531, 1453.985107421875, 403.7279052734375, 399.1613464355469, 1095.368896484375, 1739.0836181640625, 307.0325622558594, 707.8134155273438, 359.998291015625, 84.8808364868164, 58.83817672729492, 42.69060134887695, 40.7470817565918, 35.32860565185547, 32.52098846435547, 25.276744842529297, 71.98531341552734, 48.508827209472656, 20.164501190185547, 35.83635330200195, 98.7609634399414, 21.36383628845215, 176.0422821044922, 36.802337646484375, 176.6439208984375, 53.77589797973633, 64.12364196777344, 34.070919036865234, 104.01136016845703, 31.38045310974121, 18.98314666748047, 50.09584426879883, 208.55746459960938, 50.144386291503906, 40.828670501708984, 32.25938034057617, 26.166810989379883, 46.50748062133789, 222.2373809814453, 109.48934173583984, 88.28736877441406, 378.872802734375, 171.6978759765625, 289.2423095703125, 246.75830078125, 259.78411865234375, 132.5653839111328, 131.0150909423828, 180.14694213867188, 157.56346130371094, 180.62437438964844, 550.9127807617188, 207.4507598876953, 359.998291015625, 158.87559509277344, 547.4422607421875, 547.1332397460938, 444.4364013671875, 174.28298950195312, 744.0220947265625, 268.4646301269531, 719.1013793945312, 1095.368896484375, 217.6852264404297, 324.9132385253906, 295.1287841796875, 307.2556457519531, 239.75987243652344, 201.62945556640625, 545.1498413085938, 1111.058837890625, 1349.0391845703125, 713.7294921875, 58.75167465209961, 46.476707458496094, 38.23939895629883, 58.599647521972656, 35.92320251464844, 36.860965728759766, 32.7179069519043, 28.909574508666992, 24.923749923706055, 24.00910758972168, 275.9310607910156, 17.42795753479004, 16.832157135009766, 30.920066833496094, 19.58075523376465, 16.979074478149414, 18.8845157623291, 36.253990173339844, 37.91673278808594, 24.83583641052246, 15.323741912841797, 41.44181823730469, 33.72125244140625, 23.380075454711914, 27.73137092590332, 37.38930892944336, 47.28178787231445, 391.4831237792969, 35.29874038696289, 43.886173248291016, 187.38482666015625, 97.97830963134766, 52.161617279052734, 103.029296875, 138.7961883544922, 64.24079132080078, 85.48968505859375, 258.91949462890625, 72.6613540649414, 79.8840103149414, 138.26512145996094, 245.90025329589844, 56.80830001831055, 102.84616088867188, 503.916015625, 75.2212905883789, 284.0699462890625, 333.6077880859375, 311.1950378417969, 307.0325622558594, 88.09535217285156, 229.11422729492188, 1095.368896484375, 191.12037658691406, 100.81671905517578, 291.62158203125, 218.2539520263672, 547.4422607421875, 551.2094116210938, 315.81512451171875, 344.58709716796875, 194.04644775390625, 164.7562255859375, 269.6513366699219, 707.8134155273438, 324.9132385253906, 589.5796508789062, 1739.0836181640625, 1453.985107421875, 516.3827514648438, 9760.3935546875, 18.74050521850586, 14.028668403625488, 50.53470993041992, 62.52039337158203, 71.0066909790039, 38.943763732910156, 31.177642822265625, 48.36930465698242, 79.78069305419922, 20.767555236816406, 71.41603088378906, 17.40822982788086, 118.3409652709961, 33.143280029296875, 48.71135711669922, 29.791229248046875, 53.96879577636719, 26.558349609375, 95.7672119140625, 23.02521324157715, 23.142959594726562, 91.41510772705078, 30.753517150878906, 22.271631240844727, 22.707597732543945, 23.712888717651367, 45.853233337402344, 75.50863647460938, 48.50525665283203, 78.63827514648438, 138.03570556640625, 109.48934173583984, 140.6337890625, 166.4976806640625, 268.4646301269531, 750.24609375, 1095.368896484375, 208.55746459960938, 74.60678100585938, 208.30615234375, 744.0220947265625, 307.2556457519531, 357.9515075683594], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.8434998989105225, -4.428100109100342, -4.476200103759766, -4.925099849700928, -5.1570000648498535, -5.169400215148926, -5.213900089263916, -5.457099914550781, -5.605500221252441, -5.64139986038208, -5.645100116729736, -5.6570000648498535, -5.668600082397461, -5.708399772644043, -5.759399890899658, -5.781099796295166, -5.493199825286865, -5.823500156402588, -5.879799842834473, -5.901800155639648, -5.9878997802734375, -6.000500202178955, -6.0335001945495605, -6.0991997718811035, -6.12060022354126, -6.038000106811523, -6.198699951171875, -6.214900016784668, -6.2804999351501465, -6.287199974060059, -5.315299987792969, -5.242700099945068, -5.998000144958496, -4.217100143432617, -4.9456000328063965, -5.276700019836426, -5.428699970245361, -5.110199928283691, -5.499199867248535, -3.8185999393463135, -5.330399990081787, -4.042600154876709, -4.844200134277344, -5.579899787902832, -4.614500045776367, -4.984000205993652, -5.5304999351501465, -5.098999977111816, -5.217700004577637, -5.355400085449219, -5.518700122833252, -5.4653000831604, -4.423999786376953, -5.297800064086914, -5.347700119018555, -5.100599765777588, -5.431000232696533, -5.548099994659424, -5.658699989318848, -5.743899822235107, -5.637800216674805, -5.923299789428711, -5.97160005569458, -5.707200050354004, -6.038099765777588, -6.044300079345703, -6.155099868774414, -6.301300048828125, -6.350599765777588, -6.356500148773193, -6.19980001449585, -6.398799896240234, -6.399499893188477, -6.49970006942749, -6.571100234985352, -6.619100093841553, -4.322000026702881, -6.677499771118164, -6.7006001472473145, -6.717400074005127, -6.692399978637695, -6.754499912261963, -6.317800045013428, -6.287199974060059, -4.4197001457214355, -5.567699909210205, -4.682300090789795, -4.833700180053711, -3.3480000495910645, -5.149600028991699, -5.919300079345703, -5.270100116729736, -5.065199851989746, -5.447299957275391, -5.579100131988525, -4.800099849700928, -5.610300064086914, -4.933599948883057, -5.569900035858154, -5.704100131988525, -5.033899784088135, -5.3246002197265625, -5.576399803161621, -4.883900165557861, -4.475399971008301, -5.150000095367432, -4.789700031280518, -4.4695000648498535, -5.332900047302246, -4.8308000564575195, -5.212699890136719, -5.275100231170654, -5.28000020980835, -5.451499938964844, -4.48390007019043, -5.184800148010254, -5.202499866485596, -5.223199844360352, -5.427299976348877, -5.582499980926514, -5.083700180053711, -5.7459001541137695, -5.795599937438965, -5.795599937438965, -5.872300148010254, -5.914299964904785, -5.980800151824951, -5.983099937438965, -6.020500183105469, -6.071300029754639, -6.355899810791016, -6.085899829864502, -6.453100204467773, -6.763400077819824, -6.502500057220459, -6.990699768066406, -7.11929988861084, -7.258800029754639, -5.222099781036377, -5.161200046539307, -7.046299934387207, -5.536099910736084, -6.774799823760986, -5.474400043487549, -4.96619987487793, -4.5559000968933105, -5.88100004196167, -3.69569993019104, -4.057600021362305, -4.572800159454346, -5.120800018310547, -5.592599868774414, -5.400599956512451, -5.301400184631348, -4.905200004577637, -4.071300029754639, -5.3632001876831055, -5.052299976348877, -4.278299808502197, -4.703100204467773, -4.501299858093262, -4.552700042724609, -5.0441999435424805, -4.8420000076293945, -5.06820011138916, -4.427199840545654, -4.987500190734863, -5.000500202178955, -4.653299808502197, -4.529200077056885, -5.145400047302246, -4.9197998046875, -5.1041998863220215, -5.658400058746338, -6.029399871826172, -6.354899883270264, -6.402299880981445, -6.547900199890137, -6.632800102233887, -6.891900062561035, -5.8471999168396, -6.247799873352051, -7.125999927520752, -6.5594000816345215, -5.5559000968933105, -7.088399887084961, -4.996600151062012, -6.565700054168701, -5.002500057220459, -6.1940999031066895, -6.019899845123291, -6.657899856567383, -5.555600166320801, -6.757800102233887, -7.2617998123168945, -6.294000148773193, -4.881199836730957, -6.310299873352051, -6.527200222015381, -6.774700164794922, -6.988399982452393, -6.419400215148926, -4.855400085449219, -5.615099906921387, -5.827400207519531, -4.461599826812744, -5.23330020904541, -4.798699855804443, -4.98390007019043, -4.957099914550781, -5.534599781036377, -5.5447001457214355, -5.299200057983398, -5.4120001792907715, -5.307000160217285, -4.438499927520752, -5.216300010681152, -4.80679988861084, -5.420599937438965, -4.537199974060059, -4.563399791717529, -4.7270002365112305, -5.390999794006348, -4.518099784851074, -5.154300212860107, -4.57480001449585, -4.567500114440918, -5.339099884033203, -5.1819000244140625, -5.230599880218506, -5.234600067138672, -5.349699974060059, -5.3927998542785645, -5.2104997634887695, -5.145899772644043, -5.144400119781494, -5.344799995422363, -5.735400199890137, -5.97130012512207, -6.170000076293945, -5.743299961090088, -6.233799934387207, -6.208700180053711, -6.329400062561035, -6.456399917602539, -6.609499931335449, -6.648200035095215, -4.218400001525879, -6.981200218200684, -7.019899845123291, -6.415800094604492, -6.872700214385986, -7.019199848175049, -6.926000118255615, -6.274400234222412, -6.2505998611450195, -6.681300163269043, -7.17080020904541, -6.189199924468994, -6.4028000831604, -6.769899845123291, -6.609399795532227, -6.311299800872803, -6.087399959564209, -3.9763998985290527, -6.384699821472168, -6.1753997802734375, -4.777299880981445, -5.40939998626709, -6.015399932861328, -5.404900074005127, -5.154300212860107, -5.842400074005127, -5.612100124359131, -4.66349983215332, -5.765900135040283, -5.70359992980957, -5.286900043487549, -4.870699882507324, -5.996799945831299, -5.574699878692627, -4.439199924468994, -5.802999973297119, -4.888299942016602, -4.781099796295166, -4.8769001960754395, -4.905700206756592, -5.708600044250488, -5.142600059509277, -4.226099967956543, -5.258200168609619, -5.644599914550781, -5.093599796295166, -5.269000053405762, -4.81879997253418, -4.878799915313721, -5.212100028991699, -5.197299957275391, -5.415800094604492, -5.501500129699707, -5.360000133514404, -5.105999946594238, -5.3516998291015625, -5.233099937438965, -5.068399906158447, -5.148200035095215, -5.324699878692627, -0.19059999287128448, -6.489299774169922, -6.793900012969971, -5.878200054168701, -5.6930999755859375, -5.707799911499023, -6.315700054168701, -6.717599868774414, -6.367700099945068, -5.910600185394287, -7.278800010681152, -6.071899890899658, -7.517499923706055, -5.6869001388549805, -6.991600036621094, -6.6433000564575195, -7.186800003051758, -6.641600131988525, -7.367499828338623, -6.105899810791016, -7.553199768066406, -7.588600158691406, -6.218500137329102, -7.309700012207031, -7.700699806213379, -7.7947001457214355, -7.758200168609619, -7.110000133514404, -6.634099960327148, -7.0777997970581055, -6.668600082397461, -6.190800189971924, -6.5644001960754395, -6.531000137329102, -6.557199954986572, -6.335000038146973, -5.9552998542785645, -5.861299991607666, -6.617099761962891, -6.960700035095215, -6.688499927520752, -6.402299880981445, -6.616199970245361, -6.676400184631348], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.2972999811172485, 1.2965999841690063, 1.2964999675750732, 1.2956000566482544, 1.2948999404907227, 1.294800043106079, 1.294700026512146, 1.2936999797821045, 1.2928999662399292, 1.292799949645996, 1.2927000522613525, 1.2926000356674194, 1.2926000356674194, 1.2924000024795532, 1.292099952697754, 1.2919000387191772, 1.2918000221252441, 1.291700005531311, 1.2913000583648682, 1.291100025177002, 1.2905000448226929, 1.2904000282287598, 1.2900999784469604, 1.2896000146865845, 1.2892999649047852, 1.2892999649047852, 1.288699984550476, 1.2884999513626099, 1.2878999710083008, 1.2877999544143677, 1.2630000114440918, 1.225100040435791, 1.2716000080108643, 1.0123000144958496, 1.117300033569336, 1.1582000255584717, 1.1398999691009521, 1.0475000143051147, 1.1464999914169312, 0.6513000130653381, 1.0643999576568604, 0.6064000129699707, 0.7074000239372253, 1.1068999767303467, 0.3034999966621399, 0.3765000104904175, 1.0134999752044678, 0.2540000081062317, 0.40119999647140503, 0.5042999982833862, 0.8967000246047974, 0.1542000025510788, 1.5911999940872192, 1.5910999774932861, 1.5907000303268433, 1.590499997138977, 1.590399980545044, 1.5892000198364258, 1.5888999700546265, 1.5882999897003174, 1.587399959564209, 1.5867999792099, 1.586300015449524, 1.585800051689148, 1.5856000185012817, 1.5849000215530396, 1.5843000411987305, 1.5824999809265137, 1.5817999839782715, 1.5816999673843384, 1.5815999507904053, 1.5810999870300293, 1.5808000564575195, 1.5794999599456787, 1.5781999826431274, 1.5773999691009521, 1.5772000551223755, 1.5764000415802002, 1.5758999586105347, 1.575600028038025, 1.5753999948501587, 1.5748000144958496, 1.5736000537872314, 1.5673999786376953, 1.5259000062942505, 1.5302000045776367, 1.4843000173568726, 1.479200005531311, 1.3758000135421753, 1.4844000339508057, 1.5342999696731567, 1.4483000040054321, 1.405500054359436, 1.441499948501587, 1.4385000467300415, 1.2616000175476074, 1.4185999631881714, 1.138800024986267, 1.357699990272522, 1.4042999744415283, 1.0422999858856201, 1.1756999492645264, 1.317199945449829, 0.8001999855041504, 0.4426000118255615, 0.9629999995231628, 0.5791000127792358, 0.00039999998989515007, 0.9326000213623047, -0.1818999946117401, 0.1477999985218048, 0.20409999787807465, -0.34790000319480896, 0.6632000207901001, 1.7694000005722046, 1.766700029373169, 1.7666000127792358, 1.7664999961853027, 1.7653000354766846, 1.7640999555587769, 1.7632999420166016, 1.7626999616622925, 1.7621999979019165, 1.7621999979019165, 1.7613999843597412, 1.7610000371932983, 1.760200023651123, 1.760200023651123, 1.7596999406814575, 1.757699966430664, 1.7547999620437622, 1.7544000148773193, 1.753100037574768, 1.7461999654769897, 1.7400000095367432, 1.7396999597549438, 1.7353999614715576, 1.7299000024795532, 1.726199984550476, 1.7254999876022339, 1.7245999574661255, 1.7194000482559204, 1.7152999639511108, 1.712399959564209, 1.705899953842163, 1.6492999792099, 1.6898000240325928, 1.614799976348877, 1.6267000436782837, 1.6129000186920166, 1.6398999691009521, 1.6704000234603882, 1.645900011062622, 1.6252000331878662, 1.5217000246047974, 1.2475999593734741, 1.5750000476837158, 1.4752999544143677, 1.2008999586105347, 1.3042999505996704, 1.207200050354004, 1.0772000551223755, 1.2897000312805176, 0.9922000169754028, 1.13510000705719, 0.22169999778270721, 0.9427000284194946, 0.941100001335144, 0.27880001068115234, -0.059300001710653305, 1.0586999654769897, 0.4490000009536743, 0.9406999945640564, 1.8313000202178955, 1.826799988746643, 1.8221999406814575, 1.8213000297546387, 1.8184000253677368, 1.8163000345230103, 1.8092000484466553, 1.8073999881744385, 1.8014999628067017, 1.8011000156402588, 1.7926000356674194, 1.7824000120162964, 1.780900001525879, 1.7635999917984009, 1.7596999406814575, 1.7542999982833862, 1.7520999908447266, 1.7503000497817993, 1.7446999549865723, 1.7308000326156616, 1.7269999980926514, 1.725600004196167, 1.723099946975708, 1.7095999717712402, 1.7057000398635864, 1.6943999528884888, 1.6825000047683716, 1.6780999898910522, 1.6720000505447388, 1.6719000339508057, 1.6201000213623047, 1.6230000257492065, 1.5321999788284302, 1.551900029182434, 1.465000033378601, 1.4386999607086182, 1.4140000343322754, 1.5092999935150146, 1.5110000371932983, 1.437999963760376, 1.4591000080108643, 1.4276000261306763, 1.180899977684021, 1.3797999620437622, 1.2381000518798828, 1.4422999620437622, 1.0885000228881836, 1.0628999471664429, 1.107200026512146, 1.3792999982833862, 0.8008000254631042, 1.184000015258789, 0.7781000137329102, 0.3646000027656555, 1.208799958229065, 0.965499997138977, 1.0130000114440918, 0.9688000082969666, 1.1016000509262085, 1.2317999601364136, 0.41940000653266907, -0.2280000001192093, -0.4205000102519989, 0.015599999576807022, 2.1222000122070312, 2.120800018310547, 2.1171998977661133, 2.1168999671936035, 2.115799903869629, 2.1152000427246094, 2.1136999130249023, 2.1103999614715576, 2.1057000160217285, 2.104300022125244, 2.092400074005127, 2.0917000770568848, 2.0878000259399414, 2.0838000774383545, 2.0838000774383545, 2.0797998905181885, 2.066699981689453, 2.0660998821258545, 2.0450000762939453, 2.037400007247925, 2.0308001041412354, 2.0174999237060547, 2.009999990463257, 2.0092999935150146, 1.9990999698638916, 1.9982999563217163, 1.9874999523162842, 1.9845999479293823, 1.9824999570846558, 1.9739999771118164, 1.9205000400543213, 1.9368000030517578, 1.9611999988555908, 1.8910000324249268, 1.8437000513076782, 1.9258999824523926, 1.8704999685287476, 1.7109999656677246, 1.8792999982833862, 1.8467999696731567, 1.714900016784668, 1.555400013923645, 1.8945000171661377, 1.723099946975708, 1.2694000005722046, 1.8076000213623047, 1.3934999704360962, 1.339900016784668, 1.313599944114685, 1.29830002784729, 1.74399995803833, 1.354200005531311, 0.7060999870300293, 1.4198999404907227, 1.6730999946594238, 1.1619000434875488, 1.2762999534606934, 0.8069000244140625, 0.7401000261306763, 0.9638000130653381, 0.8913000226020813, 1.2470999956130981, 1.3250999450683594, 0.9739000201225281, 0.2628999948501587, 0.795799970626831, 0.31839999556541443, -0.5985000133514404, -0.4991999864578247, 0.3594000041484833, 2.55430006980896, 2.510999917984009, 2.496000051498413, 2.1301000118255615, 2.102400064468384, 1.9603999853134155, 1.9531999826431274, 1.7736999988555908, 1.684399962425232, 1.6411000490188599, 1.6188000440597534, 1.5906000137329102, 1.5565999746322632, 1.4704999923706055, 1.438599944114685, 1.4018000364303589, 1.3499000072479248, 1.3009999990463257, 1.2841999530792236, 1.263200044631958, 1.2411999702453613, 1.200700044631958, 1.1970000267028809, 1.1952999830245972, 1.1268999576568604, 1.0135999917984009, 1.0068000555038452, 0.9955000281333923, 0.9726999998092651, 0.9714999794960022, 0.8974999785423279, 0.8126999735832214, 0.670799970626831, 0.453900009393692, 0.2587999999523163, 0.0031999999191612005, -0.6446999907493591, -0.929099977016449, -0.02630000002682209, 0.6579999923706055, -0.09650000184774399, -1.083400011062622, -0.41280001401901245, -0.6258000135421753]}, \"token.table\": {\"Topic\": [6, 2, 5, 3, 1, 3, 4, 5, 2, 4, 5, 1, 2, 5, 2, 1, 5, 3, 4, 5, 3, 4, 6, 2, 3, 4, 6, 1, 4, 5, 6, 2, 3, 4, 5, 4, 6, 1, 1, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 5, 1, 1, 2, 2, 4, 5, 6, 1, 2, 3, 4, 5, 5, 3, 4, 1, 1, 4, 5, 1, 2, 1, 2, 5, 1, 2, 3, 1, 3, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 3, 5, 1, 4, 5, 6, 1, 5, 2, 6, 3, 3, 5, 6, 3, 5, 1, 4, 3, 5, 6, 5, 2, 3, 4, 5, 6, 4, 5, 1, 3, 6, 1, 1, 4, 6, 2, 3, 4, 5, 1, 2, 3, 5, 3, 6, 1, 2, 3, 4, 2, 4, 6, 3, 2, 3, 4, 1, 3, 1, 2, 3, 4, 5, 6, 1, 4, 1, 2, 3, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 5, 6, 1, 4, 6, 3, 2, 3, 4, 6, 3, 4, 2, 3, 4, 6, 1, 2, 3, 4, 5, 5, 2, 5, 3, 4, 5, 1, 3, 4, 5, 6, 3, 5, 2, 3, 4, 1, 2, 3, 4, 5, 6, 3, 6, 4, 1, 2, 3, 5, 6, 3, 1, 2, 4, 5, 3, 4, 4, 5, 1, 2, 3, 4, 5, 6, 1, 4, 1, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 2, 1, 1, 4, 3, 4, 5, 6, 1, 3, 4, 6, 1, 3, 4, 6, 2, 5, 3, 2, 5, 3, 4, 6, 1, 5, 3, 4, 6, 2, 5, 2, 5, 1, 5, 1, 2, 3, 4, 5, 6, 3, 4, 6, 2, 4, 5, 6, 2, 3, 5, 1, 1, 2, 2, 1, 2, 3, 5, 3, 1, 2, 3, 4, 5, 3, 5, 1, 5, 6, 1, 2, 3, 4, 5, 2, 3, 4, 5, 6, 2, 4, 1, 1, 2, 3, 4, 5, 6, 1, 1, 1, 2, 1, 4, 5, 6, 1, 3, 5, 6, 4, 5, 3, 2, 4, 5, 6, 2, 4, 5, 6, 2, 1, 3, 5, 6, 3, 1, 3, 4, 5, 6, 1, 2, 2, 4, 6, 1, 2, 1, 2, 3, 4, 5, 2, 3, 1, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 2, 4, 5, 2, 4, 6, 3, 4, 5, 6, 4, 1, 2, 4, 5, 3, 5, 1, 2, 3, 4, 5, 2, 2, 4, 5, 3, 1, 4, 3, 1, 2, 3, 3, 5, 1, 5, 2, 2, 3, 4, 1, 2, 3, 4, 5, 6, 3, 1, 2, 4, 5, 1, 1, 1, 4, 5, 3, 4, 6, 1, 1, 2, 4, 2, 3, 4, 5, 1, 2, 4, 5, 2, 3, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 4, 6, 3, 5, 1, 3, 4, 5, 6, 2, 3, 4, 6, 2, 4, 2, 5, 2, 4, 2, 1, 2, 5, 2, 1, 5, 4, 1, 5, 6, 2, 5, 1, 2, 3, 4, 5, 6, 2, 1, 2, 3, 4, 5, 1, 3, 4, 1, 2, 3, 4, 5, 6, 1, 5, 3, 6, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 5, 6, 3, 4, 2, 1, 2, 3, 4, 5, 6, 3, 6, 2, 3, 4, 5, 2, 4, 5, 2, 4, 6, 3, 5, 6, 1, 2, 3, 4, 5, 3, 3, 4, 1, 2, 3, 4, 5, 6, 2, 1, 1, 4, 1, 2, 3, 4, 5, 3, 1, 3, 4, 5, 2, 2, 4, 5, 6, 1, 3, 1, 2, 1, 2, 3, 5, 2, 5, 2, 4, 3, 4, 1, 1, 2, 3, 4, 5, 6, 3, 4, 6, 5, 3, 4, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 2, 4, 1, 2, 5, 2, 3, 4, 6, 1, 3, 4, 5, 6, 2, 5, 3, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 6, 2, 5, 5, 2, 4, 5, 2, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 3, 6, 1, 2, 4, 5, 2, 3, 4, 6, 3, 2, 3, 4, 5, 4, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 1, 2, 3, 4, 2, 1, 2, 5, 6, 1, 3, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 6, 1, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 1, 4, 1, 4, 5, 5, 6, 1, 2, 6, 2, 1, 2, 3, 4, 5, 6, 3, 3, 6, 1, 2, 3, 4, 6, 4, 6, 2, 5, 6, 3, 4, 6, 3, 1, 2, 3, 4, 5, 6, 5, 1, 2, 3, 4, 5, 3, 4, 6, 2], \"Freq\": [0.9999597072601318, 0.9865210056304932, 0.9780576825141907, 0.9332702159881592, 0.03647293895483017, 0.17831213772296906, 0.6686705350875854, 0.11347135901451111, 0.06199746951460838, 0.8679645657539368, 0.06199746951460838, 0.026745613664388657, 0.08023683726787567, 0.882605254650116, 0.9819719791412354, 0.3178374171257019, 0.6697288751602173, 0.9868497252464294, 0.08554292470216751, 0.8982006907463074, 0.4385634660720825, 0.28193366527557373, 0.271491676568985, 0.01132664829492569, 0.06795988976955414, 0.804192066192627, 0.1132664829492569, 0.10983870923519135, 0.017880719155073166, 0.858274519443512, 0.012771942652761936, 0.16595584154129028, 0.0075434474274516106, 0.7166274785995483, 0.11315171420574188, 0.9416676163673401, 0.050627291202545166, 0.9937022924423218, 0.9982855916023254, 0.03261684253811836, 0.9567607045173645, 0.0072481874376535416, 0.3699173927307129, 0.3159148693084717, 0.11880558729171753, 0.12600593268871307, 0.0684032216668129, 0.0009000423597171903, 0.9858273267745972, 0.017604058608412743, 0.997021496295929, 0.9987418055534363, 0.9858875870704651, 0.35207951068878174, 0.014083179645240307, 0.08449907600879669, 0.5492439866065979, 0.667898416519165, 0.10461059957742691, 0.008046968840062618, 0.08046969026327133, 0.14082196354866028, 0.976642906665802, 0.9494674205780029, 0.9838231205940247, 0.9972772598266602, 0.9914244413375854, 0.10818073153495789, 0.8654458522796631, 0.9973191022872925, 0.990428626537323, 0.09401549398899078, 0.7857009172439575, 0.12087706476449966, 0.06779298186302185, 0.06585603952407837, 0.863876223564148, 0.11206883937120438, 0.08004917204380035, 0.805828332901001, 0.3986717462539673, 0.005995064042508602, 0.14388152956962585, 0.4496297836303711, 0.09601252526044846, 0.10081315040588379, 0.3792494833469391, 0.23043006658554077, 0.12001565843820572, 0.07200939208269119, 0.02637358009815216, 0.05274716019630432, 0.9230753183364868, 0.20542441308498383, 0.051356103271245956, 0.20542441308498383, 0.5392391085624695, 0.0652582123875618, 0.9136149883270264, 0.9672173857688904, 0.016968727111816406, 0.9923766851425171, 0.26170456409454346, 0.5234091281890869, 0.2180871218442917, 0.25036299228668213, 0.7510889768600464, 0.04680807143449783, 0.936161458492279, 0.7773759365081787, 0.19943152368068695, 0.020350156351923943, 0.9505614638328552, 0.2949027419090271, 0.10287304222583771, 0.22289159893989563, 0.3772011697292328, 0.0034291015472263098, 0.11331848800182343, 0.8498886823654175, 0.5169968605041504, 0.11488819122314453, 0.3446645736694336, 0.9957311153411865, 0.9946818351745605, 0.8572407364845276, 0.12246296554803848, 0.09185706824064255, 0.010206340812146664, 0.07144438475370407, 0.8165072202682495, 0.8698601126670837, 0.036928024142980576, 0.06154670566320419, 0.032824911177158356, 0.5131882429122925, 0.4490397274494171, 0.16997019946575165, 0.027562733739614487, 0.27103355526924133, 0.5328795313835144, 0.56479412317276, 0.11295882612466812, 0.2635706067085266, 0.9956686496734619, 0.7594305276870728, 0.18823492527008057, 0.0519268736243248, 0.989791750907898, 0.9964654445648193, 0.040209583938121796, 0.10417937487363815, 0.25405147671699524, 0.4587548077106476, 0.12062875181436539, 0.02193249948322773, 0.9660091996192932, 0.03314737230539322, 0.06278765201568604, 0.03662613034248352, 0.40811973810195923, 0.4866043031215668, 0.9747703671455383, 0.028246937319636345, 0.7146474719047546, 0.09039019793272018, 0.07909142225980759, 0.08756550401449203, 0.07724408805370331, 0.09655510634183884, 0.003862204262986779, 0.16993698477745056, 0.6527125239372253, 0.9686940908432007, 0.6948904395103455, 0.04343065246939659, 0.26058390736579895, 0.0997120589017868, 0.8774661421775818, 0.01994241215288639, 0.9940230250358582, 0.2197682410478592, 0.18251939117908478, 0.5177590847015381, 0.0782225951552391, 0.0779743641614914, 0.9200974702835083, 0.14627529680728912, 0.19631685316562653, 0.654389500617981, 0.0038493499159812927, 0.1260673701763153, 0.036600206047296524, 0.056933652609586716, 0.2236679345369339, 0.5571364760398865, 0.9685372710227966, 0.9394867420196533, 0.05573226511478424, 0.09980867803096771, 0.8982781171798706, 0.94233638048172, 0.014221332967281342, 0.27731600403785706, 0.191988006234169, 0.3910866677761078, 0.1208813339471817, 0.8836672902107239, 0.1141267716884613, 0.025582442060112953, 0.8538140058517456, 0.12151660025119781, 0.5006929039955139, 0.1691901832818985, 0.21183159947395325, 0.03851483762264252, 0.07152755558490753, 0.008253179490566254, 0.9015427231788635, 0.09391070157289505, 0.9906985759735107, 0.09001798927783966, 0.07201439142227173, 0.7426484227180481, 0.06751349568367004, 0.022504497319459915, 0.9931853413581848, 0.13990800082683563, 0.633868932723999, 0.07994743436574936, 0.1484737992286682, 0.07925548404455185, 0.9170992374420166, 0.017064949497580528, 0.9727020859718323, 0.01096006017178297, 0.0018266766564920545, 0.24660134315490723, 0.47128257155418396, 0.2648681104183197, 0.005480030085891485, 0.8233558535575867, 0.168893501162529, 0.9285868406295776, 0.06784196197986603, 0.777368426322937, 0.06840842217206955, 0.027985261753201485, 0.06218947097659111, 0.06529894471168518, 0.9878465533256531, 0.8610860705375671, 0.030391274020075798, 0.0050652120262384415, 0.10130424052476883, 0.9732202291488647, 0.9941055774688721, 0.33218109607696533, 0.6643621921539307, 0.013499079272150993, 0.8459423184394836, 0.10349293798208237, 0.04049723595380783, 0.05598163232207298, 0.8543863296508789, 0.047984253615140915, 0.04131977632641792, 0.18540924787521362, 0.503253698348999, 0.10594814270734787, 0.21189628541469574, 0.8606778383255005, 0.13618320226669312, 0.9890157580375671, 0.0551663413643837, 0.9378278255462646, 0.5272482633590698, 0.41659119725227356, 0.052073899656534195, 0.08052879571914673, 0.885816752910614, 0.04315357282757759, 0.87745600938797, 0.07671746611595154, 0.9963555932044983, 0.9872059226036072, 0.9808709025382996, 0.9754441976547241, 0.9988272190093994, 0.9703404903411865, 0.40819332003593445, 0.08163866400718689, 0.21770310401916504, 0.03446965664625168, 0.24673017859458923, 0.010885154828429222, 0.436113178730011, 0.5472248196601868, 0.016666745766997337, 0.482529878616333, 0.12063246965408325, 0.2412649393081665, 0.14743968844413757, 0.30748867988586426, 0.059513937681913376, 0.6248963475227356, 0.9940608739852905, 0.14210925996303558, 0.8591151237487793, 0.9948091506958008, 0.08311475813388824, 0.5760712623596191, 0.16049747169017792, 0.1805596500635147, 0.9923886656761169, 0.7922921776771545, 0.047301024198532104, 0.003941752016544342, 0.04335927218198776, 0.11431080847978592, 0.9540703296661377, 0.038678526878356934, 0.618489682674408, 0.1649305820465088, 0.206163227558136, 0.29889750480651855, 0.01546021644026041, 0.15975557267665863, 0.11337491869926453, 0.4122724235057831, 0.016128553077578545, 0.5913802981376648, 0.3534841239452362, 0.012096415273845196, 0.02688092179596424, 0.020614804700016975, 0.9688957929611206, 0.9872786998748779, 0.11923327296972275, 0.10822712630033493, 0.4989453852176666, 0.24213525652885437, 0.027515370398759842, 0.003668716177344322, 0.991806149482727, 0.9980840682983398, 0.9936157464981079, 0.9812985062599182, 0.02800491638481617, 0.22403933107852936, 0.36406391859054565, 0.37806639075279236, 0.997009813785553, 0.1279582530260086, 0.22392693161964417, 0.6397912502288818, 0.08896466344594955, 0.8896466493606567, 0.9972772598266602, 0.41964298486709595, 0.1780303567647934, 0.2161797136068344, 0.19074681401252747, 0.4939018487930298, 0.17960067093372345, 0.08980033546686172, 0.2245008498430252, 0.9777878522872925, 0.8535566926002502, 0.028139231726527214, 0.11724679917097092, 0.9604863524436951, 0.9865299463272095, 0.06606698781251907, 0.3063105642795563, 0.21021313965320587, 0.3183227479457855, 0.10210352391004562, 0.9956464171409607, 0.9777495861053467, 0.04566654562950134, 0.8037312030792236, 0.15526625514030457, 0.05681372433900833, 0.9431078433990479, 0.0796644538640976, 0.5160871148109436, 0.23206602036952972, 0.07620078325271606, 0.09351914376020432, 0.9821086525917053, 0.016808705404400826, 0.9953906536102295, 0.21123674511909485, 0.7921377420425415, 0.7504137754440308, 0.03660554811358452, 0.06863540410995483, 0.050332631915807724, 0.09151387214660645, 0.027172187343239784, 0.05434437468647957, 0.9238543510437012, 0.10293692350387573, 0.0026394082233309746, 0.07126402109861374, 0.7337554693222046, 0.07390343397855759, 0.015836449339985847, 0.40509942173957825, 0.39318472146987915, 0.03276539221405983, 0.10723219811916351, 0.06255211681127548, 0.5322731137275696, 0.3211480379104614, 0.14570604264736176, 0.1583070307970047, 0.17809541523456573, 0.6530165076255798, 0.13322457671165466, 0.6661228537559509, 0.18318378925323486, 0.016653072088956833, 0.9896226525306702, 0.42079347372055054, 0.2814963161945343, 0.011608095839619637, 0.28730037808418274, 0.8848925828933716, 0.11344777047634125, 0.12657441198825836, 0.12220977991819382, 0.08292806893587112, 0.20950248837471008, 0.45828667283058167, 0.9871293306350708, 0.08600766956806183, 0.8385747671127319, 0.06450574845075607, 0.9904100298881531, 0.0956009104847908, 0.8922752141952515, 0.9962976574897766, 0.09392458200454712, 0.04025339335203171, 0.8654479384422302, 0.9800244569778442, 0.9897431135177612, 0.1533694714307785, 0.843532145023346, 0.996519923210144, 0.13572895526885986, 0.8211601972579956, 0.0407186858355999, 0.017286544665694237, 0.031115779653191566, 0.06568887084722519, 0.6880044341087341, 0.18323737382888794, 0.017286544665694237, 0.9844937324523926, 0.01568690314888954, 0.8941534161567688, 0.003137380350381136, 0.08784665167331696, 0.9959492683410645, 0.9978677034378052, 0.027524948120117188, 0.2064371109008789, 0.7706985473632812, 0.35146257281303406, 0.20674268901348114, 0.4134853780269623, 0.9893438816070557, 0.9878445267677307, 0.9332126975059509, 0.06540034711360931, 0.15231958031654358, 0.0825064405798912, 0.6854380965232849, 0.08885309100151062, 0.05784505233168602, 0.3036865293979645, 0.6314751505851746, 0.0048204208724200726, 0.333526074886322, 0.05558767542243004, 0.3149968385696411, 0.2779383957386017, 0.5238391160964966, 0.20298045873641968, 0.16042931377887726, 0.04197613149881363, 0.0649767518043518, 0.006900185719132423, 0.30495160818099976, 0.013553405180573463, 0.2270195335149765, 0.43709731101989746, 0.016941756010055542, 0.16065825521945953, 0.14918266236782074, 0.631157398223877, 0.06311573833227158, 0.09652086347341537, 0.8928179740905762, 0.02279888466000557, 0.48854753375053406, 0.03582681715488434, 0.4331788122653961, 0.019541900604963303, 0.04320968687534332, 0.08641937375068665, 0.6049355864524841, 0.25925812125205994, 0.027904624119400978, 0.9487572312355042, 0.9950780272483826, 0.002696688286960125, 0.828728437423706, 0.16896405816078186, 0.9832143783569336, 0.10635286569595337, 0.17282341420650482, 0.7178818583488464, 0.9793066382408142, 0.12689875066280365, 0.8671414852142334, 0.9816653728485107, 0.5907120108604431, 0.15314754843711853, 0.2625386714935303, 0.25216829776763916, 0.7420952916145325, 0.03034786693751812, 0.20029592514038086, 0.15780891478061676, 0.09711317718029022, 0.4430788457393646, 0.07283487915992737, 0.9828891158103943, 0.7508364915847778, 0.146234929561615, 0.020890703424811363, 0.06758756935596466, 0.013517513871192932, 0.03203685209155083, 0.9290687441825867, 0.9857545495033264, 0.31765463948249817, 0.09075846523046494, 0.018151693046092987, 0.5173232555389404, 0.05445507913827896, 0.0018151693511754274, 0.052953436970710754, 0.9531618356704712, 0.991234540939331, 0.0061952159740030766, 0.9928229451179504, 0.351828008890152, 0.11681246012449265, 0.1474061906337738, 0.3462654948234558, 0.038937486708164215, 0.1188964992761612, 0.3341955542564392, 0.06748179346323013, 0.02570735104382038, 0.43702495098114014, 0.019280513748526573, 0.037084925919771194, 0.011125477962195873, 0.6156097650527954, 0.31151339411735535, 0.022250955924391747, 0.9529414772987366, 0.04113416373729706, 0.988793671131134, 0.2730725407600403, 0.2104412168264389, 0.43591395020484924, 0.0701470747590065, 0.010021010413765907, 0.002505252603441477, 0.9754320979118347, 0.025011079385876656, 0.24928709864616394, 0.5648403763771057, 0.11359918117523193, 0.07257725298404694, 0.6569962501525879, 0.2715584337711334, 0.07007959485054016, 0.5640462636947632, 0.025068722665309906, 0.4010995626449585, 0.2601328492164612, 0.4877490997314453, 0.2601328492164612, 0.45238468050956726, 0.20080339908599854, 0.15694978833198547, 0.14540936052799225, 0.0461617037653923, 0.9867190718650818, 0.05267830565571785, 0.895531177520752, 0.3418143689632416, 0.13870728015899658, 0.43593716621398926, 0.059445977210998535, 0.009907662868499756, 0.014861494302749634, 0.9832691550254822, 0.9967358708381653, 0.9930975437164307, 0.9494893550872803, 0.04807167127728462, 0.028843002393841743, 0.01922866888344288, 0.8941330909729004, 0.00961433444172144, 0.9777079224586487, 0.09705977141857147, 0.058235861361026764, 0.058235861361026764, 0.7764781713485718, 0.997801661491394, 0.2957555651664734, 0.05070095509290695, 0.31265589594841003, 0.3380063772201538, 0.06387810409069061, 0.9198447465896606, 0.9963448643684387, 0.996331512928009, 0.007937830872833729, 0.001984457718208432, 0.5675548911094666, 0.4187205731868744, 0.8897693157196045, 0.10895134508609772, 0.9798075556755066, 0.9839799404144287, 0.11464904993772507, 0.8407596945762634, 0.9913320541381836, 0.31289154291152954, 0.24584335088729858, 0.05866716429591179, 0.2765737771987915, 0.06704818457365036, 0.04190511628985405, 0.9361353516578674, 0.03640526160597801, 0.02600375935435295, 0.9629369378089905, 0.06816544383764267, 0.92591392993927, 0.15120001137256622, 0.3802909255027771, 0.045818183571100235, 0.42152729630470276, 0.006155489478260279, 0.04001067951321602, 0.23698633909225464, 0.41549554467201233, 0.2616083025932312, 0.04001067951321602, 0.8962363600730896, 0.10013813525438309, 0.1556643396615982, 0.015566433779895306, 0.8094545602798462, 0.08153857290744781, 0.10483530908823013, 0.7513197064399719, 0.06406602263450623, 0.011250203475356102, 0.4590083062648773, 0.4792586863040924, 0.022500406950712204, 0.027000488713383675, 0.8397464752197266, 0.15605908632278442, 0.03234145790338516, 0.9379022121429443, 0.09423226118087769, 0.024797964841127396, 0.10415145009756088, 0.5455552339553833, 0.23310086131095886, 0.9579697847366333, 0.012601560913026333, 0.8020523190498352, 0.060784000903367996, 0.1045188307762146, 0.015566634945571423, 0.004447609651833773, 0.8523192405700684, 0.13960400223731995, 0.9743006825447083, 0.9956644773483276, 0.9111889004707336, 0.07438276708126068, 0.07955729961395264, 0.26036936044692993, 0.6581558585166931, 0.3704698979854584, 0.10132510215044022, 0.15198765695095062, 0.06649459898471832, 0.3103081285953522, 0.0031664094422012568, 0.025513745844364166, 0.8249444365501404, 0.025513745844364166, 0.07228894531726837, 0.05102749168872833, 0.7486481070518494, 0.2201906144618988, 0.17501868307590485, 0.15557216107845306, 0.009723260067403316, 0.6611816883087158, 0.27065202593803406, 0.03776539862155914, 0.6734828948974609, 0.01888269931077957, 0.9888535737991333, 0.02935054339468479, 0.02935054339468479, 0.9098668694496155, 0.02935054339468479, 0.9422499537467957, 0.9266738295555115, 0.5546324253082275, 0.1696123629808426, 0.07293331623077393, 0.030530225485563278, 0.16282787919044495, 0.01187286525964737, 0.39790984988212585, 0.2353833019733429, 0.14151018857955933, 0.16112546622753143, 0.05604364350438118, 0.008406545966863632, 0.977171778678894, 0.06106166914105415, 0.05342895910143852, 0.16028687357902527, 0.7174745798110962, 0.9938294887542725, 0.6747385263442993, 0.04217115789651871, 0.08434231579303741, 0.21085579693317413, 0.058486588299274445, 0.17545975744724274, 0.7603256702423096, 0.834357738494873, 0.04525329917669296, 0.04525329917669296, 0.0650516226887703, 0.008484994061291218, 0.9904560446739197, 0.13420136272907257, 0.14333070814609528, 0.22458186745643616, 0.22823360562324524, 0.23918882012367249, 0.0310397706925869, 0.21009056270122528, 0.29702460765838623, 0.26080209016799927, 0.057956017553806305, 0.1738680601119995, 0.10208753496408463, 0.08096597343683243, 0.1689724624156952, 0.13376986980438232, 0.47523507475852966, 0.03872285783290863, 0.11261267215013504, 0.004170839674770832, 0.3294963240623474, 0.47964656352996826, 0.05422091484069824, 0.020854199305176735, 0.9784131646156311, 0.9736461639404297, 0.018905751407146454, 0.09114488214254379, 0.045572441071271896, 0.8430901169776917, 0.6713384985923767, 0.30210232734680176, 0.09630406647920609, 0.529672384262085, 0.38521626591682434, 0.9947856664657593, 0.2300976812839508, 0.04815997928380966, 0.6260797381401062, 0.05351109057664871, 0.008026663213968277, 0.03210665285587311, 0.996295154094696, 0.9507770538330078, 0.04660671949386597, 0.022731482982635498, 0.08524306118488312, 0.8751620650291443, 0.011365741491317749, 0.0056828707456588745, 0.9724205732345581, 0.02778344415128231, 0.24634912610054016, 0.4105818569660187, 0.3079364001750946, 0.9398736357688904, 0.008702533319592476, 0.04351266846060753, 0.9932551383972168, 0.06781448423862457, 0.36167722940444946, 0.26560673117637634, 0.13986736536026, 0.15399537980556488, 0.011302413418889046, 0.9675884246826172, 0.19171825051307678, 0.4512156844139099, 0.03292131796479225, 0.15492384135723114, 0.16847968101501465, 0.42240840196609497, 0.24137623608112335, 0.33189231157302856, 0.9895027875900269], \"Term\": [\"_\", \"acadalaskaedu\", \"accessdigexnet\", \"adapter\", \"address\", \"address\", \"address\", \"address\", \"aid\", \"aid\", \"aid\", \"alive\", \"alive\", \"alive\", \"altitude\", \"america\", \"america\", \"amiga\", \"angeles\", \"angeles\", \"animation\", \"animation\", \"animation\", \"anonymous\", \"anonymous\", \"anonymous\", \"anonymous\", \"appear\", \"appear\", \"appear\", \"appear\", \"application\", \"application\", \"application\", \"application\", \"archive\", \"archive\", \"argue\", \"argument\", \"art\", \"art\", \"art\", \"article\", \"article\", \"article\", \"article\", \"article\", \"article\", \"astronaut\", \"astronaut\", \"atheism\", \"atheist\", \"atmosphere\", \"baalke\", \"baalke\", \"baalke\", \"baalke\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"ball\", \"baud\", \"bbs\", \"belief\", \"believe\", \"berkeley\", \"berkeley\", \"bible\", \"billboard\", \"billion\", \"billion\", \"billion\", \"bit\", \"bit\", \"bit\", \"black\", \"black\", \"black\", \"book\", \"book\", \"book\", \"book\", \"box\", \"box\", \"box\", \"box\", \"box\", \"box\", \"boy\", \"boy\", \"boy\", \"brain\", \"brain\", \"brain\", \"brain\", \"brown\", \"brown\", \"budget\", \"budget\", \"bug\", \"buyer\", \"buyer\", \"buyer\", \"cable\", \"cable\", \"calculation\", \"calculation\", \"card\", \"card\", \"card\", \"cassette\", \"center\", \"center\", \"center\", \"center\", \"center\", \"channel\", \"channel\", \"cheer\", \"cheer\", \"cheer\", \"christian\", \"christianity\", \"circle\", \"circle\", \"city\", \"city\", \"city\", \"city\", \"claim\", \"claim\", \"claim\", \"claim\", \"cod\", \"cod\", \"code\", \"code\", \"code\", \"code\", \"collect\", \"collect\", \"collect\", \"color\", \"commercial\", \"commercial\", \"commercial\", \"commit\", \"compatible\", \"computer\", \"computer\", \"computer\", \"computer\", \"computer\", \"computer\", \"conclusion\", \"conclusion\", \"condition\", \"condition\", \"condition\", \"condition\", \"contract\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cover\", \"cover\", \"cover\", \"cover\", \"cover\", \"cpu\", \"credit\", \"credit\", \"credit\", \"curve\", \"curve\", \"curve\", \"cview\", \"data\", \"data\", \"data\", \"data\", \"database\", \"database\", \"datum\", \"datum\", \"datum\", \"datum\", \"david\", \"david\", \"david\", \"david\", \"david\", \"davis\", \"dcx\", \"dcx\", \"dec\", \"dec\", \"deck\", \"dept\", \"dept\", \"dept\", \"dept\", \"dept\", \"disk\", \"disk\", \"display\", \"display\", \"display\", \"do\", \"do\", \"do\", \"do\", \"do\", \"do\", \"dos\", \"dos\", \"drawing\", \"drive\", \"drive\", \"drive\", \"drive\", \"drive\", \"driver\", \"earth\", \"earth\", \"earth\", \"earth\", \"edge\", \"edge\", \"edition\", \"edition\", \"email\", \"email\", \"email\", \"email\", \"email\", \"email\", \"event\", \"event\", \"evidence\", \"evidence\", \"exist\", \"exist\", \"exist\", \"exist\", \"exist\", \"existence\", \"fact\", \"fact\", \"fact\", \"fact\", \"fairbank\", \"false\", \"faq\", \"faq\", \"fax\", \"fax\", \"fax\", \"fax\", \"file\", \"file\", \"file\", \"file\", \"fine\", \"fine\", \"fine\", \"fine\", \"flight\", \"flight\", \"floppy\", \"florida\", \"florida\", \"format\", \"format\", \"format\", \"foundation\", \"foundation\", \"ftp\", \"ftp\", \"ftp\", \"fuel\", \"galaxy\", \"gas\", \"genesis\", \"god\", \"gold\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"graphic\", \"graphic\", \"graphic\", \"gravity\", \"gravity\", \"gravity\", \"gravity\", \"green\", \"green\", \"green\", \"gregg\", \"gun\", \"gun\", \"henry\", \"high\", \"high\", \"high\", \"high\", \"hp\", \"human\", \"human\", \"human\", \"human\", \"human\", \"ibm\", \"ibm\", \"ignore\", \"ignore\", \"ignore\", \"ill\", \"ill\", \"ill\", \"ill\", \"ill\", \"image\", \"image\", \"image\", \"image\", \"image\", \"imaging\", \"imaging\", \"imply\", \"include\", \"include\", \"include\", \"include\", \"include\", \"include\", \"innocent\", \"islam\", \"islamic\", \"japanese\", \"jeff\", \"jeff\", \"jeff\", \"jeff\", \"jesus\", \"jet\", \"jet\", \"jet\", \"joe\", \"joe\", \"jpeg\", \"jpl\", \"jpl\", \"jpl\", \"jpl\", \"july\", \"july\", \"july\", \"july\", \"jupiter\", \"keith\", \"keith\", \"keith\", \"kelvinjplnasagov\", \"keyboard\", \"keywords\", \"keywords\", \"keywords\", \"keywords\", \"keywords\", \"kill\", \"kipling\", \"lab\", \"lab\", \"lab\", \"landing\", \"landing\", \"large\", \"large\", \"large\", \"large\", \"large\", \"launch\", \"launch\", \"law\", \"lee\", \"lee\", \"life\", \"life\", \"life\", \"life\", \"life\", \"link\", \"link\", \"link\", \"list\", \"list\", \"list\", \"list\", \"list\", \"list\", \"long\", \"long\", \"long\", \"long\", \"long\", \"lunar\", \"lunar\", \"lunar\", \"magellan\", \"magellan\", \"magellan\", \"mail\", \"mail\", \"mail\", \"mail\", \"mailing\", \"man\", \"man\", \"man\", \"man\", \"manual\", \"manual\", \"mark\", \"mark\", \"mark\", \"mark\", \"mark\", \"mars\", \"maryland\", \"maryland\", \"maryland\", \"mb\", \"medical\", \"medical\", \"meg\", \"memory\", \"memory\", \"memory\", \"microsoft\", \"mile\", \"miller\", \"miller\", \"mission\", \"mode\", \"mode\", \"mode\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"modem\", \"moon\", \"moon\", \"moon\", \"moon\", \"moral\", \"morality\", \"motion\", \"motion\", \"motion\", \"msdos\", \"msdos\", \"msdos\", \"muslim\", \"muslims\", \"nasa\", \"nasa\", \"network\", \"network\", \"network\", \"network\", \"news\", \"news\", \"news\", \"news\", \"newssoftware\", \"newssoftware\", \"newssoftware\", \"newssoftware\", \"not\", \"not\", \"not\", \"not\", \"not\", \"not\", \"number\", \"number\", \"number\", \"number\", \"number\", \"object\", \"object\", \"object\", \"object\", \"obo\", \"obo\", \"offer\", \"offer\", \"offer\", \"offer\", \"offer\", \"ontario\", \"ontario\", \"ontario\", \"ontario\", \"operator\", \"operator\", \"orbit\", \"orbit\", \"orbital\", \"orbital\", \"orbiter\", \"origin\", \"origin\", \"origin\", \"pad\", \"pair\", \"pair\", \"park\", \"pasadena\", \"pasadena\", \"pasadena\", \"pat\", \"pat\", \"pay\", \"pay\", \"pay\", \"pay\", \"pay\", \"pay\", \"payload\", \"people\", \"people\", \"people\", \"people\", \"people\", \"pin\", \"pin\", \"plot\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"poison\", \"poison\", \"polygon\", \"polygon\", \"port\", \"post\", \"post\", \"post\", \"post\", \"post\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"price\", \"price\", \"price\", \"price\", \"price\", \"printer\", \"printer\", \"probe\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"processor\", \"processor\", \"program\", \"program\", \"program\", \"program\", \"project\", \"project\", \"project\", \"propulsion\", \"propulsion\", \"propulsion\", \"purdue\", \"purdue\", \"purdue\", \"question\", \"question\", \"question\", \"question\", \"question\", \"ram\", \"raytrace\", \"raytrace\", \"read\", \"read\", \"read\", \"read\", \"read\", \"read\", \"redesign\", \"religion\", \"religious\", \"removal\", \"request\", \"request\", \"request\", \"request\", \"request\", \"rgb\", \"rob\", \"rob\", \"rob\", \"rob\", \"rocket\", \"ron\", \"ron\", \"ron\", \"ron\", \"routine\", \"routine\", \"rushdie\", \"russian\", \"sale\", \"sale\", \"sale\", \"sale\", \"satellite\", \"satellite\", \"saturn\", \"scan\", \"scanner\", \"scanner\", \"schneider\", \"science\", \"science\", \"science\", \"science\", \"science\", \"science\", \"screen\", \"screen\", \"screen\", \"scsi\", \"search\", \"search\", \"sell\", \"sell\", \"sell\", \"sell\", \"send\", \"send\", \"send\", \"send\", \"send\", \"send\", \"shuttle\", \"shuttle\", \"sign\", \"sign\", \"sign\", \"site\", \"site\", \"site\", \"site\", \"software\", \"software\", \"software\", \"software\", \"software\", \"solar\", \"solar\", \"sony\", \"sony\", \"source\", \"source\", \"source\", \"source\", \"source\", \"southern\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"spacecraft\", \"spacecraft\", \"speaker\", \"spencer\", \"sphere\", \"sphere\", \"star\", \"star\", \"star\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"station\", \"station\", \"station\", \"station\", \"station\", \"storage\", \"storage\", \"story\", \"story\", \"story\", \"story\", \"surface\", \"surface\", \"surface\", \"surface\", \"svga\", \"tel\", \"tel\", \"tel\", \"tel\", \"telephone\", \"telos\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"titan\", \"tool\", \"tool\", \"tool\", \"tool\", \"toronto\", \"totally\", \"totally\", \"totally\", \"totally\", \"trade\", \"trade\", \"trade\", \"true\", \"true\", \"true\", \"true\", \"true\", \"truth\", \"university\", \"university\", \"university\", \"university\", \"university\", \"university\", \"unix\", \"unix\", \"unix\", \"unix\", \"unix\", \"usa\", \"usa\", \"usa\", \"usa\", \"usa\", \"usa\", \"user\", \"user\", \"user\", \"user\", \"user\", \"user\", \"utzoohenry\", \"valid\", \"valid\", \"van\", \"van\", \"van\", \"vaxvm\", \"vaxvm\", \"vaxvms\", \"vaxvms\", \"vaxvms\", \"vehicle\", \"version\", \"version\", \"version\", \"version\", \"version\", \"version\", \"vesa\", \"vga\", \"vga\", \"video\", \"video\", \"video\", \"video\", \"video\", \"virtual\", \"virtual\", \"vnews\", \"vnews\", \"vnews\", \"window\", \"window\", \"window\", \"windows\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"wright\", \"year\", \"year\", \"year\", \"year\", \"year\", \"zealand\", \"zealand\", \"zealand\", \"zoology\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 1, 5, 6, 3, 4]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1819221110738981843368747820\", ldavis_el1819221110738981843368747820_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1819221110738981843368747820\", ldavis_el1819221110738981843368747820_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1819221110738981843368747820\", ldavis_el1819221110738981843368747820_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "1      0.111540 -0.163249       1        1  27.300962\n",
       "0      0.107458 -0.103616       2        1  20.268749\n",
       "4      0.066287  0.194761       3        1  16.997086\n",
       "5      0.074166  0.104644       4        1  15.871936\n",
       "2      0.084400 -0.010924       5        1  11.786957\n",
       "3     -0.443851 -0.021615       6        1   7.774313, topic_info=        Term         Freq        Total Category  logprob  loglift\n",
       "156        _  9760.000000  9760.000000  Default  30.0000  30.0000\n",
       "230      god   889.000000   889.000000  Default  29.0000  29.0000\n",
       "744    space  1349.000000  1349.000000  Default  28.0000  28.0000\n",
       "422     file   750.000000   750.000000  Default  27.0000  27.0000\n",
       "458      bit   516.000000   516.000000  Default  26.0000  26.0000\n",
       "..       ...          ...          ...      ...      ...      ...\n",
       "660  gravity    11.200075    74.606781   Topic6  -6.9607   0.6580\n",
       "97       box    14.704185   208.306152   Topic6  -6.6885  -0.0965\n",
       "25     image    19.577101   744.022095   Topic6  -6.4023  -1.0834\n",
       "727   format    15.807696   307.255646   Topic6  -6.6162  -0.4128\n",
       "591  science    14.882914   357.951508   Topic6  -6.6764  -0.6258\n",
       "\n",
       "[381 rows x 6 columns], token_table=      Topic      Freq            Term\n",
       "term                                 \n",
       "156       6  0.999960               _\n",
       "869       2  0.986521   acadalaskaedu\n",
       "602       5  0.978058  accessdigexnet\n",
       "0         3  0.933270         adapter\n",
       "92        1  0.036473         address\n",
       "...     ...       ...             ...\n",
       "254       5  0.168480            year\n",
       "687       3  0.422408         zealand\n",
       "687       4  0.241376         zealand\n",
       "687       6  0.331892         zealand\n",
       "543       2  0.989503         zoology\n",
       "\n",
       "[843 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 1, 5, 6, 3, 4])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.gensim.prepare(model, c, dictionary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
